<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.105.0">
<link rel="canonical" type="text/html" href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v2/">
<link rel="alternate" type="application/rss&#43;xml" href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v2/index.xml">
<meta name="robots" content="noindex, nofollow">

<script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "WebSite",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/gkcalat.github.io\/kubeflow-docs"
      },
      "articleSection" : "docs",
      "name" : "v2",
      "headline" : "v2",
      "description" : "Kubeflow Pipelines v2 Documentation",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "0001",
      "datePublished": "0001-01-01 00:00:00 \u002b0000 UTC",
      "dateModified" : "0001-01-01 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/gkcalat.github.io\/kubeflow-docs\/docs\/components\/pipelines\/v2\/",
      "wordCount" : "42",
      "keywords" : [ "Kubeflow" ]
  }
  </script>

<link rel="shortcut icon" href="/kubeflow-docs/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/kubeflow-docs/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-32x32.png" sizes="32x32">
<link rel="manifest" href="/kubeflow-docs/favicons/manifest.json">
<meta name="msapplication-config" content="/kubeflow-docs/favicons/browserconfig.xml" />
<meta name="msapplication-TileColor" content="#4279f4">
<meta name="theme-color" content="#4279f4">

<title>v2 | Kubeflow on Google Cloud Platform</title>
<meta name="description" content="Kubeflow Pipelines v2 Documentation">
<meta property="og:title" content="v2" />
<meta property="og:description" content="Kubeflow Pipelines v2 Documentation" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v2/" /><meta property="og:site_name" content="Kubeflow on Google Cloud Platform" />

<meta itemprop="name" content="v2">
<meta itemprop="description" content="Kubeflow Pipelines v2 Documentation"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="v2"/>
<meta name="twitter:description" content="Kubeflow Pipelines v2 Documentation"/>




<link rel="preload" href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" as="style">
<link href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-GK9XL47N6S"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-GK9XL47N6S', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand-md navbar-dark  td-navbar">
        <a class="navbar-brand" href="/kubeflow-docs/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 276.93 274.55"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M95.9 62.15l4.1 102.1 73.75-94.12a6.79 6.79.0 019.6-1.11l46 36.92-15-65.61z" fill="#4279f4"/><path fill="#0028aa" d="M102.55 182.98h65.42l-40.17-32.23-25.25 32.23z"/><path fill="#014bd1" d="M180.18 83.92l-44 56.14 46.88 37.61 44.47-55.76-47.35-37.99z"/><path fill="#bedcff" d="M83.56 52.3l.01-.01 38.69-48.52-62.39 30.05-15.41 67.51 39.1-49.03z"/><path fill="#6ca1ff" d="M45.32 122.05l41.44 51.96-3.95-98.98-37.49 47.02z"/><path fill="#a1c3ff" d="M202.31 28.73 142.65.0l-37.13 46.56 96.79-17.83z"/><path d="M1.6 272v-44.78h5.74v23.41l20.48-23.41h6.4l-17.39 19.7 19 25.07H29.1l-15.92-20.8-5.84 6.65V272zm40.02-9.79V240h5.43v22.39a4.67 4.67.0 002.35 4.19 11 11 0 0011 0 4.69 4.69.0 002.33-4.19V240h5.43v22.19a9.08 9.08.0 01-4.1 7.87 16.2 16.2.0 01-18.37.0 9.07 9.07.0 01-4.07-7.85zM77.46 272v-48h5.43v16.81a29.29 29.29.0 019.32-1.73 13.1 13.1.0 016.2 1.41 10.71 10.71.0 014.18 3.74 18.07 18.07.0 012.23 5.06 21.26 21.26.0 01.73 5.58q0 8.43-4.38 12.79T87.35 272zm5.43-4.87h4.55q6.77.0 9.72-2.95t3-9.51a14.21 14.21.0 00-2-7.52 6.55 6.55.0 00-6-3.22 24.73 24.73.0 00-9.25 1.54zm29.47-11.19q0-7.71 4.09-12.3a13.75 13.75.0 0110.8-4.59q13.35.0 13.36 18.86h-22.82a12.3 12.3.0 002.9 7.07q2.59 3.11 7.9 3.1a24.92 24.92.0 0010.55-2v5a27.74 27.74.0 01-9.86 1.87 19.83 19.83.0 01-7.7-1.37 13.31 13.31.0 01-5.28-3.76 16.21 16.21.0 01-3-5.38 20.84 20.84.0 01-.94-6.5zm5.62-2.12h17.26a14.91 14.91.0 00-2.37-7.12 6.44 6.44.0 00-5.62-2.78 8.2 8.2.0 00-6.21 2.72 12.07 12.07.0 00-3.04 7.18z" fill="#4279f4" stroke="#4279f4" stroke-miterlimit="10" stroke-width="3.2"/><path d="M147.32 244.89V240h5v-7.59a8.14 8.14.0 012.31-6.05 7.79 7.79.0 015.69-2.28h7.86V229h-5c-2.21.0-3.67.45-4.37 1.34s-1.06 2.55-1.06 5V240h8.46v4.87h-8.46V272h-5.44v-27.1zM175.26 272v-48h5.43v48zm19.15-3.95a17.86 17.86.0 1112.33 4.9 16.57 16.57.0 01-12.33-4.9zm3.84-20.65a13.16 13.16.0 000 17.2 12.07 12.07.0 0017 0 13.09 13.09.0 000-17.2 12.07 12.07.0 00-17 0zm30.2-7.4h5.75l7.3 25.32 7.43-25.32h5.36l7.34 25.34L269 240h5.74l-10.04 32h-6.12l-6.83-24.58L245 272h-6.47z" fill="#0028aa" stroke="#0028aa" stroke-miterlimit="10" stroke-width="3.2"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Kubeflow on Google Cloud Platform</span>
	</a>
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main_navbar" aria-controls="main_navbar" aria-expanded="false" aria-label="Toggle navigation">
		<span class="navbar-toggler-icon"></span>
	</button>
	<div class="collapse navbar-collapse ml-md-auto" id="main_navbar">
		<ul class="navbar-nav ml-auto pt-4 pt-md-0 my-2 my-md-1">
			
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/docs/" ><span>Docs</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/news/" ><span>News</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" target="_blank" ><i class='fa-brands fa-github pr-2'></i><span>Source</span></a>
			</li>
			
			
			<li class="nav-item dropdown mt-1 mt-lg-0 mr-2">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Releases
</a>
<div class="dropdown-menu dropdown-menu-md-right dropdown-menu-lg-left" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">latest</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">v1.6</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.5-release/docs">v1.5</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.4-release/docs">v1.4</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/main/docs">dev</a>
	
</div>

			</li>
			
			
		</ul>
	</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/kubeflow-docs/docs/components/pipelines/v2/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">v2</h1>
<div class="lead">Kubeflow Pipelines v2 Documentation</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-491d81fa84033751ec5e23d040fe3b20">Introduction</a></li>


    
  
    
    
	
<li>2: <a href="#pg-40b7d37854add4a8b5bab284800cd2e8">Installation</a></li>


    
  
    
    
	
<li>3: <a href="#pg-50b1788ca8945aadd369ed873937651f">Quickstart</a></li>


    
  
    
    
	
<li>4: <a href="#pg-71d14ac04c3b2a201568806e101af25a">Author a Pipeline</a></li>


    
    <ul>
        
  
  
  
  

  
    
    
	
<li>4.1: <a href="#pg-8399b7eb477a6311c212af1521456bad">Components</a></li>


    
  
    
    
	
<li>4.2: <a href="#pg-6434584f19aa221c1b86bb04ddc1aebe">Tasks</a></li>


    
  
    
    
	
<li>4.3: <a href="#pg-6afd16685922f350ab1b27a4d4e79d0c">Pipelines</a></li>


    
  
    
    
	
<li>4.4: <a href="#pg-4cdabdf4d68974491ee69accb5f7080d">Component I/O</a></li>


    
  

    </ul>
    
  
    
    
	
<li>5: <a href="#pg-949036519b58594da97d168aa118d46d">Compile a Pipeline</a></li>


    
  
    
    
	
<li>6: <a href="#pg-a68b69ed119639161f8aa77ca8cb9aa9">Run a Pipeline</a></li>


    
  
    
    
	
<li>7: <a href="#pg-417e76f1404dfae7c66273efdc10e05b">Command Line Interface</a></li>


    
  
    
    
	
<li>8: <a href="#pg-0aa565b096b841bd6171b56fe09e39c8">Community and Support</a></li>


    
  
    
    
	
<li>9: <a href="#pg-f0fb094d1c5469ccf9ae7e2c40cfebca">Reference</a></li>


    
  

    </ul>


<div class="content">
      <p><strong>Note:</strong> Kubeflow Pipelines v2 is in pre-release stage and is not yet stable. The v2 docs being are continually developed and links to v2 documentation are also not yet stable.</p>
<p>Please see <a href="/docs/components/pipelines/v1">v1 documentation</a> for documentation on the latest stable KFP release.</p>

</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-491d81fa84033751ec5e23d040fe3b20">1 - Introduction</h1>
    <div class="lead">What is Kubeflow Pipelines?</div>
	<p>Kubeflow Pipelines (KFP) is a platform for building and deploying portable and
scalable machine learning (ML) workflows by using Docker containers.</p>
<p>KFP is available as a core component of Kubeflow or as a standalone installation. To quickly get started with a KFP deployment and usage example, see the <a href="/docs/components/pipelines/v2/quickstart">Quickstart</a> guide.</p>
<!-- TODO: Include these links once the topic is available -->
<!-- [Learn more about installing Kubeflow][Installation]
[Learn more about installing Kubeflow Pipelines standalone][Installation] -->
<h2 id="objectives">Objectives</h2>
<p>The primary objectives of Kubeflow Pipelines are to enable the following:</p>
<ul>
<li>End-to-end orchestration of ML workflows</li>
<li>Pipeline composability through reusable components and pipelines</li>
<li>Easy management, tracking, and visualization of pipeline definitions, pipeline runs, experiments, and ML artifacts</li>
<li>Efficient use of compute resources by eliminating redundant executions through <a href="/docs/components/pipelines/v2/author-a-pipeline/tasks/#caching">caching</a></li>
<li>Cross-platform pipeline portability through a platform-neutral <a href="/docs/components/pipelines/v2/compile-a-pipeline/#ir-yaml">IR YAML pipeline definition</a></li>
</ul>
<h2 id="what-is-a-pipeline">What is a pipeline?</h2>
<p>A <a href="/docs/components/pipelines/v2/author-a-pipeline/pipelines"><em>pipeline</em></a> is the definition of a workflow with one or more steps called <a href="/docs/components/pipelines/v2/author-a-pipeline/tasks"><em>tasks</em></a>. A task is defined by a single container execution and includes output parameters. Each task in a pipeline might also include input parameters. By specifying the output of one task as the input of another task, a pipeline author can form a computed acyclic graph (DAG) of tasks.</p>
<p>Pipelines are written in Python for an easy authoring experience, compiled to YAML for portability, and executed on Kubernetes for scalability.</p>
<h2 id="what-does-using-kfp-look-like">What does using KFP look like?</h2>
<p>At a high level, using KFP consists of the following steps:</p>
<ol>
<li><a href="/docs/components/pipelines/v2/author-a-pipeline">Author a pipeline</a> with one or more components using the <strong>Python KFP SDK</strong>&rsquo;s domain-specific language (DSL). You can <a href="/docs/components/pipelines/v2/author-a-pipeline/components">author your own components</a> or use prebuilt components provided by other authors.</li>
<li><a href="/docs/components/pipelines/v2/compile-a-pipeline">Compile the pipeline</a> into a static representation (YAML) by using the <strong>KFP SDK&rsquo;s DSL compiler</strong>.</li>
<li>Submit the pipeline to run on the <strong>KFP backend</strong>. The KFP backend orchestrates the Kubernetes Pod creation and data passes, which are required to execute your workflow.</li>
<li>View your runs, experiments, and ML artifacts on the <strong>KFP Dashboard</strong>.</li>
</ol>
<h2 id="next-steps">Next steps</h2>
<ul>
<li>Follow the
<a href="/docs/components/pipelines/v2/quickstart">pipelines quickstart guide</a> guide to
deploy Kubeflow Pipelines and run your first pipeline</li>
</ul>
<!-- TODO: Uncomment these links once the topic is created -->
<!-- * Learn more about the [different ways to install KFP][installation] -->
<ul>
<li>Learn more about <a href="/docs/components/pipelines/v2/author-a-pipeline">authoring pipelines</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-40b7d37854add4a8b5bab284800cd2e8">2 - Installation</h1>
    <div class="lead">Options to install Kubeflow Pipelines</div>
	<p>This page will be available soon. For similar information, see <a href="/docs/components/pipelines/v1/installation/">KFP v1 installation documentation</a>.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-50b1788ca8945aadd369ed873937651f">3 - Quickstart</h1>
    <div class="lead">Get started with Kubeflow Pipelines</div>
	<style type="text/css">
summary::marker {
    font-size: 1.5rem;
}
summary {
    margin-bottom: 1.5rem;
}
</style>
<!-- TODO: add UI screenshots for final pipeline -->
<p>This tutorial helps you get started with KFP.</p>
<p>Before you begin, you need the following prerequisites:</p>
<ul>
<li>
<p><strong>An existing Kubernetes cluster</strong>: If you don&rsquo;t have a Kubernetes cluster, see <a href="/docs/components/pipelines/v2/installation/">Installation</a> for instructions about how to get one.</p>
</li>
<li>
<p><strong>The <a href="https://kubernetes.io/docs/tasks/tools/">kubectl</a> command-line tool</strong>: Install and configure your <a href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/">kubectl context</a> to connect with your cluster.</p>
</li>
<li>
<p>Run the following script to install the KFP SDK:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">pip install kfp --pre
</span></span></code></pre></div><p><strong>Note:</strong> This command installs KFP v2, which is in pre-release stage and is not yet stable. The v2 documentation is being developed continually and some of the links to the v2 documentation might be unavailable.</p>
</li>
</ul>
<p>After you complete the prerequisites, click each step to view the instructions:</p>
<details>
  <summary><a name="kfp_qs_step1"></a><h2 style="display:inline;">Step 1: Deploy a KFP standalone instance into your cluster</h2></summary>
  <hr/>
  This step shows how to deploy a KFP standalone instance into an existing Kubernetes cluster.
<p>Run the following script after replacing <code>PIPELINE_VERSION</code> with the desired version of KFP:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">PIPELINE_VERSION</span><span class="o">=</span><span class="s2">&#34;2.0.0-alpha.4&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl apply -k <span class="s2">&#34;github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=</span><span class="nv">$PIPELINE_VERSION</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">kubectl <span class="nb">wait</span> --for <span class="nv">condition</span><span class="o">=</span>established --timeout<span class="o">=</span>60s crd/applications.app.k8s.io
</span></span><span class="line"><span class="cl">kubectl apply -k <span class="s2">&#34;github.com/kubeflow/pipelines/manifests/kustomize/env/dev?ref=</span><span class="nv">$PIPELINE_VERSION</span><span class="s2">&#34;</span>
</span></span></code></pre></div><p>After you deploy Kubernetes, obtain your KFP endpoint by following <a href="/docs/components/pipelines/v2/installation/">these instructions</a>.</p>
  <!-- TODO: add more precise section link and descriptive link text (with more context) when available -->
</details>
<details>
  <summary><a name="kfp_qs_step2"></a><h2 style="display:inline;">Step 2: Create and run a simple pipeline using the KFP SDK</h2></summary>
  <hr/>
This step shows how to use the KFP SDK to compose a pipeline and submit it for execution by KFP.
<p>The following simple pipeline adds two integers, and then adds another integer to the result to come up with a final sum.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">client</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">num1</span> <span class="o">+</span> <span class="n">num2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;addition-pipeline&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_task_1</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_task_2</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">add_task_1</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">endpoint</span> <span class="o">=</span> <span class="s1">&#39;&lt;KFP_ENDPOINT&gt;&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">kfp_client</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">endpoint</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">run</span> <span class="o">=</span> <span class="n">kfp_client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">arguments</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">endpoint</span><span class="si">}</span><span class="s1">/#/runs/details/</span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">run_id</span><span class="si">}</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span></code></pre></div><p>The above code consists of the following parts:</p>
<ul>
<li>
<p>In the first part, the following lines create a <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#1-lighweight-python-function-based-components">lightweight Python component</a> by using the <code>@dsl.component</code> decorator:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">num1</span> <span class="o">+</span> <span class="n">num2</span>
</span></span></code></pre></div><p>The <code>@dsl.component</code> decorator transforms a Python function into a component, which can be used within a pipeline. You are required to specify the type annotations on the parameters as well as the return value, as these inform the KFP executor how to serialize and deserialize the data passed between components. The type annotations and return value also enable the KFP compiler to type check any data that is passed between pipeline tasks.</p>
</li>
<li>
<p>In the second part, the following lines <a href="/docs/components/pipelines/v2/author-a-pipeline/pipelines">create a pipeline</a> by using the <code>@dsl.pipeline</code> decorator:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;addition-pipeline&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="o">...</span>
</span></span></code></pre></div><p>Like the component decorator, the <code>@dsl.pipeline</code> decorator transforms a Python function into a pipeline that can be executed by the KFP backend. The pipeline can have arguments. These arguments also require type annotations. In this example, the argument <code>c</code> has a default value of <code>10</code>.</p>
</li>
<li>
<p>In the third part, the following lines connect the components together to form a computational directed acyclic graph (DAG) within the body of the pipeline function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">add_task_1</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">add_task_2</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">add_task_1</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</span></span></code></pre></div><p>This example instantiates two different addition tasks from the same component named <code>addition_component</code>, by passing different arguments to the component function for each task, as follows:</p>
<ul>
<li>The first task accepts pipeline parameters <code>a</code> and <code>b</code> as input arguments.</li>
<li>The second task accepts <code>add_task_1.output</code>, which is the output from <code>add_task_1</code>, as the first input argument. The pipeline parameter <code>c</code> is the second input argument.</li>
</ul>
<p>You must always pass component arguments as keyword arguments.</p>
</li>
<li>
<p>In the fourth part, the following lines instantiate a KFP client using the endpoint obtained in <a href="#kfp_qs_step1">step 1</a> and submit the pipeline to the KFP backend with the required pipeline arguments:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">endpoint</span> <span class="o">=</span> <span class="s1">&#39;&lt;KFP_ENDPOINT&gt;&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">kfp_client</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">endpoint</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">run</span> <span class="o">=</span> <span class="n">kfp_client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">my_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">arguments</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">  <span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">endpoint</span><span class="si">}</span><span class="s1">/#/runs/details/</span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">run_id</span><span class="si">}</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span></code></pre></div><p>In this example, replace <code>endpoint</code> with the KFP endpoint URL you obtained in the from <a href="#kfp_qs_step1">step 1</a>.</p>
<p>Alternatively, you can compile the pipeline to <a href="/docs/components/pipelines/v2/compile-a-pipeline/#ir-yaml">IR YAML</a> for use at another time:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">compiler</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pipeline_func</span><span class="o">=</span><span class="n">my_pipeline</span><span class="p">,</span> <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;pipeline.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div></li>
</ul>
</details>
<details>
  <summary><a name="kfp_qs_step3"></a><h2 style="display:inline;">Step 3: View the pipeline in the KFP Dashboard</h2></summary>
  <hr/>
<p>This step shows how to view the pipeline run on the KFP Dashboard. To do this, go to the URL printed from <a href="#kfp_qs_step_2">step 2</a>.</p>
<p>To view the details of each task, including input and output, click the appropriate task node.</p>
<!-- TODO: add logs to this list when available in v2 -->
<p><img src="/docs/images/pipelines/addition_pipeline_ui.png" 
alt="Pipelines Dashboard"
class="mt-3 mb-3 border border-info rounded"></p>
</details>
<details>
  <summary><a name="kfp_qs_step4"></a><h2 style="display:inline;">Step 4: Build a more advanced ML pipeline</h2></summary>
  <hr/>
This step shows how to build a more advanced machine learning (ML) pipeline that demonstrates additional KFP pipeline composition features.
<p>The following ML pipeline creates a dataset, normalizes the features of the dataset as a preprocessing step, and trains a simple ML model on the data using different hyperparameters:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">client</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Dataset</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Input</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Output</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span><span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pandas==1.3.5&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">iris_dataset</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">csv_url</span> <span class="o">=</span> <span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;Sepal_Length&#39;</span><span class="p">,</span> <span class="s1">&#39;Sepal_Width&#39;</span><span class="p">,</span> <span class="s1">&#39;Petal_Length&#39;</span><span class="p">,</span> <span class="s1">&#39;Petal_Width&#39;</span><span class="p">,</span> <span class="s1">&#39;Labels&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_url</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">iris_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span><span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pandas==1.3.5&#39;</span><span class="p">,</span> <span class="s1">&#39;scikit-learn==1.0.2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">normalize_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_iris_dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">normalized_iris_dataset</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">standard_scaler</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">min_max_scaler</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">standard_scaler</span> <span class="ow">is</span> <span class="n">min_max_scaler</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;Exactly one of standard_scaler or min_max_scaler must be True.&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_iris_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Labels&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">standard_scaler</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">min_max_scaler</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">normalized_iris_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span><span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pandas==1.3.5&#39;</span><span class="p">,</span> <span class="s1">&#39;scikit-learn==1.0.2&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">normalized_iris_dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_neighbors</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">normalized_iris_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Labels&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;iris-training-pipeline&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">standard_scaler</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">min_max_scaler</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">neighbors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">create_dataset_task</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">normalize_dataset_task</span> <span class="o">=</span> <span class="n">normalize_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">input_iris_dataset</span><span class="o">=</span><span class="n">create_dataset_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;iris_dataset&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">standard_scaler</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">min_max_scaler</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ParallelFor</span><span class="p">(</span><span class="n">neighbors</span><span class="p">)</span> <span class="k">as</span> <span class="n">n_neighbors</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">normalized_iris_dataset</span><span class="o">=</span><span class="n">normalize_dataset_task</span>
</span></span><span class="line"><span class="cl">            <span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;normalized_iris_dataset&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">endpoint</span> <span class="o">=</span> <span class="s1">&#39;&lt;KFP_UI_URL&gt;&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">kfp_client</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">endpoint</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">run</span> <span class="o">=</span> <span class="n">kfp_client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">arguments</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;min_max_scaler&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;standard_scaler&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">endpoint</span><span class="si">}</span><span class="s1">/#/runs/details/</span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">run_id</span><span class="si">}</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span></code></pre></div><p>This example introduces the following new features in the pipeline:</p>
<ul>
<li>
<p>Some Python <strong>packages to install</strong> are added at component runtime, using the <code>packages_to_install</code> argument on the <code>@dsl.component</code> decorator, as follows:</p>
<p><code>@dsl.component(packages_to_install=['pandas==1.3.5'])</code></p>
<p>To use a library after installing it, you must include its import statements within the scope of the component function, so that the library is imported at component runtime.</p>
</li>
<li>
<p><strong>Input and output artifacts</strong> of types <code>Dataset</code> and <code>Model</code> are introduced in the component signature to describe the input and output artifacts of the components. This is done using the type annotation generics <code>Input[]</code> and <code>Output[]</code> for input and output artifacts respectively.</p>
<p>Within the scope of a component, artifacts can be read (for inputs) and written (for outputs) via the <code>.path</code> attribute. The KFP backend ensures that <em>input</em> artifact files are copied <em>to</em> the executing pod local file system from the remote storage at runtime, so that the component function can read input artifacts from the local file system. By comparison, <em>output</em> artifact files are copied <em>from</em> the local file system of the pod to remote storage, when the component finishes running. This way, the output artifacts persist outside the pod. In both cases, the component author needs to interact with the local file system only to create persistent artifacts.</p>
<p>The arguments for the parameters annotated with <code>Output[]</code> are not passed to components by the pipeline author. The KFP backend passes this artifact during component runtime, so that component authors don&rsquo;t need to be concerned about the path to which the output artifacts are written. After an output artifact is written, the backend executing the component recognizes the KFP artifact types (<code>Dataset</code> or <code>Model</code>), and organizes them on the Dashboard.</p>
<p>An output artifact can be passed as an input to a downstream component using <code>.outputs</code> attribute of the source task and the output artifact parameter name, as follows:</p>
<p><code>create_dataset_task.outputs['iris_dataset']</code></p>
</li>
<li>
<p>One of the <strong>DSL control flow features</strong>, <code>dsl.ParallelFor</code>, is used. It is a context manager that lets pipeline authors create tasks. These tasks execute in parallel in a loop. Using <code>dsl.ParallelFor</code> to iterate over the <code>neighbors</code> pipeline argument lets you execute the  <code>train_model</code> component with different arguments and test multiple hyperparameters in one pipeline run. Other control flow features include <code>dsl.Condition</code> and <code>dsl.ExitHandler</code>.</p>
</li>
</ul>
</details>
<p>Congratulations! You now have a KFP deployment, an end-to-end ML pipeline, and an introduction to the UI. That&rsquo;s just the beginning of KFP pipeline and Dashboard features.</p>
<!TODO: Add some more content to direct the user to what comes next. -->
<h2 id="next-steps">Next steps</h2>
<ul>
<li>See <a href="/docs/components/pipelines/v2/installation/">Installation</a> for additional ways to deploy KFP</li>
<li>See <a href="/docs/components/pipelines/v2/author-a-pipeline/">Author a Pipeline</a> to learn more about feautres available when authoring pipelines</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-71d14ac04c3b2a201568806e101af25a">4 - Author a Pipeline</h1>
    <div class="lead">Concepts and objects for authoring pipelines</div>
	
</div>



    
      
  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-8399b7eb477a6311c212af1521456bad">4.1 - Components</h1>
    <div class="lead">Author KFP components</div>
	<h2 id="summary">Summary</h2>
<p>A <em>component</em> is the basic unit of execution logic in KFP. A component is a named template for how to run a container using an image, a command, and arguments. Components may also have inputs and outputs, making a component a computational template, analogous to a function.</p>
<p>Component inputs are dynamic data used in either the container commands or arguments.</p>
<p>Component outputs may be machine learning artifacts or other JSON-serializable data.</p>
<h2 id="author-a-component">Author a component</h2>
<p>At the lowest level of execution, all components define their execution logic via a container image, command, and arguments. An importer component is a special case and the only exception to this.</p>
<p>The KFP SDK exposes three ways of authoring components with these three properties.</p>
<h3 id="1-lighweight-python-function-based-components">1. Lighweight Python function-based components</h3>
<p>The most simple way to author a component is via a lightweight Python function-based component (also known as a lightweight component).</p>
<p>Lightweight components provides a fully Pythonic approach to creating a component that executes a single Python function within a container at runtime.</p>
<p>To create a lightweight component, you must:</p>
<ol>
<li>
<p>Define a standalone function.</p>
<p>A standalone Python function is a function that does not reference any symbols defined outside of its scope. This means the function must define all objects it uses within the scope of the function and must include all import statements within the function body.</p>
</li>
<li>
<p>Include type annotations for the function parameters and return values.</p>
<p>Type annotations indicate what the component inputs and outputs are and tells the KFP lightweight component executor how to serialize and deserialize the data as it is passed within a pipeline. This also (optionally) allows the KFP DSL compiler to type check your pipeline.</p>
<p>Valid parameter annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, <code>list</code>, <code>OutputPath</code>, <code>InputPath</code>, <code>Input[&lt;Artifact&gt;]</code>, and <code>Output[&lt;Artifact&gt;]</code>.</p>
<p>Valid return annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, and <code>list</code>. You may also specify multiple return values by using these annotations within a <code>typing.NamedTuple</code>.</p>
<p>For detailed discussion on type annotations and runtime behavior, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io">Data Passing</a>.</p>
</li>
<li>
<p>Decorate your function with the <code>@kfp.dsl.component</code> decorator.
This decorator transforms a Python function into a component that can be used within a pipeline.</p>
<p>For a comprehensive list of <code>@kfp.dsl.component</code> decorator arguments, see the DSL <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html">reference documentation</a>.</p>
</li>
</ol>
<p>The following is an example of a lightweight component that trains a model on an existing input <code>Dataset</code> artifact for <code>num_epochs</code> epochs, then saves the output <code>Model</code> artifact.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">base_image</span><span class="o">=</span><span class="s1">&#39;python:3.7&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensorflow==2.9.1&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># load and process the Dataset artifact</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="o">...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer1&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer2&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer2&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer3&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># train for num_epochs</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># save the Model artifact</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</span></span></code></pre></div><p>Notice the <code>base_image</code> argument to the <code>@kfp.dsl.component</code> decorator. Despite not having the word &ldquo;container&rdquo; in its name, lightweight components are still executed as a container at runtime. The <code>@kfp.dsl.component</code> decorator mereley provides a convient Pythonic interface to defining this container image, command, and arguments. <a href="https://hub.docker.com/_/python"><code>python:3.7</code></a> is the default image, but can be changed to any image accessible to the executing backend, as long as the image has a Python interpreter available as <code>python3</code>. Packages in <code>packages_to_install</code> will be pip installed at container runtime.</p>
<p><strong>When to use?</strong> Lightweight components should be used if your component implementation can be written as a standalone Python function and does not require an abundance of source code. This is the preferred authoring approach for quick demos and when authoring components in a noteebok.</p>
<p>For more involved components and for production usage, prefer containerized components and custom container components for their increased flexibility.</p>
<p>Note: This authoring approach replaces <code>kfp.components.create_component_from_func</code> in KFP v1.</p>
<h3 id="2-containerized-python-components">2. Containerized Python components</h3>
<p>Containerized Python components extend lightweight components by allowing users to package and build their Python function-based components into containers.</p>
<p>Unlike lightweight components, containerized Python components allow authors to use additional source code outside of the component&rsquo;s Python function definition, including source code across multiple files. This is the preferred approach for authoring Python components that require more source code than can cleanly be included in the body of a standalone function or in cases where you wish to reuse the same source code in multiple components.</p>
<p>To create a containerized component, you must:</p>
<ol>
<li>
<p>Define a component using the <code>@kfp.dsl.component</code> decorator.</p>
<p>A containerized Python component definition is very similar to a lightweight component definition, but with a few key differences:</p>
<p>a) The <code>@kfp.dsl.component</code> decorator is given a <code>target_image</code>. This is the name of containerized component image that will be created from the <code>base_image</code> in Step 2 below.</p>
<p>b) The <code>tensorflow</code> import is included outside of the <code>train_model</code> function. This is possible because the entire module will be executed at component runtime, not only the Python function as in a lightweight component.</p>
<p>c) The component uses functions defined in <code>my_helper_module</code> imported via a <a href="https://docs.python.org/3/reference/import.html#package-relative-imports">relative import</a>. This is possible because <code>my_helper_module.py</code> will be included in the container image created in Step 2 below. This is unlike a lighweight component, which only uses the source code included in the Python function definition. This helper code could have also been defined within the same module outside of the <code>train_model</code> function.</p>
<p>The following containerized component adapts the lightweight component in the previous section to a containerized component. Notice that most of the logic is extracted into helper functions in <code>my_helper_module</code>, permitting a cleaner, modular component function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># my_component.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">.my_helper_module</span> <span class="kn">import</span> <span class="n">compile_and_train</span><span class="p">,</span> <span class="n">get_model</span><span class="p">,</span> <span class="n">split_dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">base_image</span><span class="o">=</span><span class="s1">&#39;python:3.7&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">target_image</span><span class="o">=</span><span class="s1">&#39;gcr.io/my-project/my-component:v1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># load and process the Dataset artifact</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">untrained_model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># train for num_epochs</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">compile_and_train</span><span class="p">(</span><span class="n">untrained_model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># save the Model artifact</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>my_component.py</code> module, the <code>my_helper_module.py</code> module, and any other source code files you wish to include in the container image should be grouped together in a directory. When you build the component in Step 2 below, this directory will by <a href="https://docs.docker.com/engine/reference/builder/#copy">COPY</a>&rsquo;d into the image:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">src/
</span></span><span class="line"><span class="cl">├── my_component.py
</span></span><span class="line"><span class="cl">└── my_helper_module.py
</span></span><span class="line"><span class="cl">└── another_module.py
</span></span></code></pre></div></li>
<li>
<p>Build the component.</p>
<p>Once you&rsquo;ve written a component and associated source code files and put them in a standalone directory, you can use the KFP CLI to build your component. This command to do this takes the form:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp component build <span class="o">[</span>OPTIONS<span class="o">]</span> COMPONENTS_DIRECTORY <span class="o">[</span>ARGS<span class="o">]</span>...
</span></span></code></pre></div><p>When you run this command, KFP will build an image with all the source code found in <code>COMPONENTS_DIRECTORY</code>. KFP will find your component definition in <code>src/</code> and execute the component function you defined at component runtime. Include the <code>--push-image</code> flag to push your image to a remote registry from which the executing backend can pull your image at runtime. For example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp component build src/ --push-image
</span></span></code></pre></div><p>For detailed information about all arguments/flags, see <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/cli.html#kfp-component-build">CLI reference documentation</a>.</p>
</li>
</ol>
<p><strong>When to use?</strong> Containerized Python components should be used any time your component is implemented as Python code, but cannot be written as a standalone Python function or you wish to organize source code outside of the component Python function definition.</p>
<h3 id="3-custom-container-components">3. Custom container components</h3>
<p>Custom container components allow you to specify a container to execute as your component. The <code>dsl.ContainerSpec</code> object allows you to specify a container via an image, command, and args.</p>
<p>To define a custom container component, you must:</p>
<ol>
<li>
<p>Write your component’s code as a Python function that returns a <code>dsl.ContainerSpec</code> object to specify the container image and the commands to be run in the container and wrap the function into a <code>@container_component</code> decorator. The function should do nothing other than returning a <code>dsl.ContainerSpec</code> object, with the following parameters:</p>
<ul>
<li><code>image</code>: The image that the container will run. You can use <code>command</code> and <code>args</code> to control the entrypoint.</li>
<li><code>command</code> (optional): The command to be executed.</li>
<li><code>args</code> (optional): The arguments of the command. It’s recommended to place the input of the components in the args section instead of the command section.</li>
</ul>
<p>The decorator will then compose a component using the <code>ContainerSpec</code>, which can be used the same as a Python component. (Learn more about <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html">ContainerSpec</a> in documentation.)</p>
</li>
<li>
<p>Specify your function&rsquo;s inputs and outputs in the function&rsquo;s signature <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io">Learn more about passing data between components</a>. Specifically for custom container components, your function&rsquo;s inputs and outputs must meet the following requirements:</p>
<ul>
<li>All your function&rsquo;s arguments must have data type annotations.</li>
<li>Different from a Python component, your return type annotation for the function
must either be <code>dsl.ContainerSpec</code> or omitted.</li>
<li>If the function accepts or returns large amounts of data or complex
data types, you must annotate that argument as an <em>artifact</em>. Note that in the function you defined, you can only access artifacts via its <code>.url</code>, <code>.path</code>, or <code>.metadata</code> attribute. Accessing any other attribute or the artifact variable by itself is not allowed.</li>
</ul>
</li>
</ol>
<p>Below is an example that authors a pipelines from two custom container components. Just as using with a Python component, you can access the outputs of a <code>container_component</code> for downstream tasks as demonstrated in the pipeline:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">container_component</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">ContainerSpec</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">Input</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">Output</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_gcs</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;sh&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;-c&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;mkdir --parents $(dirname &#34;$1&#34;) &amp;&amp; echo &#34;$0&#34; &gt; &#34;$1&#34;&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">text</span><span class="p">,</span> <span class="n">output_gcs</span><span class="o">.</span><span class="n">path</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_dataset</span><span class="p">(</span><span class="n">input_gcs</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ContainerSpec</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span> <span class="n">command</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">input_gcs</span><span class="o">.</span><span class="n">path</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">two_step_pipeline_containerized</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">create_dataset_task</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_dataset_task</span> <span class="o">=</span> <span class="n">print_dataset</span><span class="p">(</span><span class="n">input_gcs</span><span class="o">=</span><span class="n">create_dataset_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_gcs&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>In the above example, the <code>create_dataset</code> component takes in a text and output it to a path as an artifact. Then, the <code>print_dataset</code> component retrieves the artifact output by the <code>create_dataset</code> component and prints it out.</p>
<h2 id="special-case-importer-components">Special case: Importer components</h2>
<p>Unlike the previous three authoring approaches, an importer component not a general authoring style but a pre-baked component for a specific use case: loading a machine learning artifact from remote storage to machine learning metadata (MLMD).</p>
<p><strong>Before you continue:</strong> Understand how KFP <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io">Artifacts</a> work.</p>
<p>Typically, the input artifact to a task is an output from an upstream task. In this case, the artifact can be easily accessed from the upstream task using <code>my_task.outputs['artifact_name']</code>. The artifact is also registered in MLMD when it is created by the upstream task.</p>
<p>If you wish to use an existing artifact that is not generated by a task in the current pipeline <em>or</em> wish to use as an artifact an external file that was not generated by a pipeline at all, you can use an importer component to load an artifact from its URI.</p>
<p>You do not need to write an importer component; it can be imported from the <code>dsl</code> module and used directly:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">get_date_string</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">importer_task</span> <span class="o">=</span> <span class="n">dsl</span><span class="o">.</span><span class="n">importer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">artifact_uri</span><span class="o">=</span><span class="s1">&#39;gs://ml-pipeline-playground/shakespeare1.txt&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">artifact_class</span><span class="o">=</span><span class="n">dsl</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">reimport</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">task</span><span class="o">.</span><span class="n">output</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">    <span class="n">other_component</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">importer_task</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><p>In addition to the <code>artifact_uri</code>, you must provide an <code>artifact_class</code>, indicating the type of the artifact.</p>
<p>The <code>importer</code> component permits setting artifact metadata via the <code>metadata</code> argument. Metadata can be constructed with outputs from upstream tasks, as is done for the <code>'date'</code> value in the example pipeline.</p>
<p>You may also specify a boolean <code>reimport</code> argument. If <code>reimport</code> is <code>False</code>, KFP will use an existing MLMD artifact if it already exists from an earlier importer execution. If <code>reimport</code> is <code>True</code>, KFP will reimport the artifact as a new artifact, irrespective of whether it was previously imported.</p>
<h2 id="compile-save-a-component">Compile (save) a component</h2>
<p>Once you&rsquo;ve written a component, you may wish to write the component definition to YAML for future use or submission for execution. This can be done via the KFP SDK DSL compiler:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">compiler</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pipeline_func</span><span class="o">=</span><span class="n">addition_component</span><span class="p">,</span> <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;addition_component.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="load-a-component">Load a component</h2>
<p>You can load saved components via the <code>kfp.components</code> module. This is helpful for integrating existing components stored as YAML into a larger pipeline definition:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">components</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">addition_component</span> <span class="o">=</span> <span class="n">components</span><span class="o">.</span><span class="n">load_component_from_file</span><span class="p">(</span><span class="s1">&#39;addition_component.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>Once loaded, you can use the component in a pipeline just as you would a component defined in Python:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">addition_task</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>components</code> module also includes <code>.load_component_from_text</code> and <code>.load_component_from_url</code> for loading YAML from different sources.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6434584f19aa221c1b86bb04ddc1aebe">4.2 - Tasks</h1>
    <div class="lead">Understand and use KFP tasks</div>
	<h2 id="summary">Summary</h2>
<p>A <em>task</em> is an execution of a <a href="/docs/components/pipelines/v2/author-a-pipeline/components">component</a> with a set of inputs. It can be thought of as an instantiation of a component template. A pipeline is composed of individual tasks that may or may not pass data betwen one another.</p>
<p>One component can be used to instantiate multiple tasks within a single pipeline. Tasks can also be created and executed dynamically using pipeline control flow features such as loops, conditions, and exit handlers.</p>
<p>Because tasks represent a runtime execution of a component, you may set additional runtime configuration on a task, such as environment variables, hardware resource requirements, and various other task-level configurations.</p>
<h2 id="task-dependencies">Task dependencies</h2>
<h3 id="independent-tasks">Independent tasks</h3>
<p>Tasks may or may not depend on one another. Two tasks are independent of one another if no outputs of one are inputs to the other and neither task calls <code>.after()</code> on the other. When two tasks are independent, they execute concurrently at pipeline runtime. In the following example, <code>my_task1</code> and <code>my_task2</code> have no dependency and will execute at the same time.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task1</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hello, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task2</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hi, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;universe&#39;</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="implicitly-dependent-tasks">Implicitly dependent tasks</h3>
<p>When the output of one task is the input to another, an implicit dependency is created between the two tasks. When this is the case, the upstream task will execute first so that its output can be passed to the downstream task. In the following example, the argument to the <code>prefix</code> parameter on <code>my_tasks2</code> is the output from <code>my_task1</code>. This means <code>my_task2</code> implicitly depends and will execute after <code>my_task1</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task1</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hello, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task2</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="n">my_task1</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;!&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>For more information on passing inputs and outputs between components, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io-passing-data-between-tasks/#passing-data-between-tasks">Component I/O: Passing data between tasks</a>.</p>
<h3 id="explicitly-dependent-tasks">Explicitly dependent tasks</h3>
<p>Sometimes you want to order execution of two tasks but not pass data between the tasks. When this is the case, you can call the intended second task&rsquo;s <code>.after()</code> on the intended first task create an explicit dependency. In the following example, <code>my_task2</code> explicitly depends on <code>my_task1</code>, so <code>my_task1</code> will execute before <code>my_task2</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task1</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hello, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task2</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hi, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;universe&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">after</span><span class="p">(</span><span class="n">my_task1</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="task-level-configurations">Task-level configurations</h2>
<p>The KFP SDK exposes several platform-agnostic task-level configurations for use during authoring. Platform-agnostic configurations are those that are expected to exhibit similar execution behavior on all KFP-conformant backends, such as the open source KFP backend or the Vertex Pipelines backend. The remainder of this section refers only to platform-agnostic task-level configurations.</p>
<p>All task-level configurations are set using a method on the task. Take the following environment variable example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_env_var</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;MY_ENV_VAR&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">print_env_var</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span><span class="o">.</span><span class="n">set_env_variable</span><span class="p">(</span><span class="s1">&#39;MY_ENV_VAR&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>When executed, the <code>print_env_var</code> component should print <code>'hello'</code>.</p>
<p>Task-level configuration methods can also be chained:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">print_env_var</span><span class="p">()</span><span class="o">.</span><span class="n">set_env_variable</span><span class="p">(</span><span class="s1">&#39;MY_ENV_VAR&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_env_variable</span><span class="p">(</span><span class="s1">&#39;OTHER_VAR&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>The KFP SDK provides the following task methods for setting task-level configurations:</p>
<ul>
<li><code>.add_node_selector_constraint</code></li>
<li><code>.set_caching_options</code></li>
<li><code>.set_cpu_limit</code></li>
<li><code>.set_display_name</code></li>
<li><code>.set_env_variable</code></li>
<li><code>.set_gpu_limit</code></li>
<li><code>.set_memory_limit</code></li>
<li><code>.set_retry</code></li>
</ul>
<p>For detailed information on how to use the above methods, see the <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>kfp.dsl.PipelineTask</code> reference documentation</a>.</p>
<h3 id="caching">Caching</h3>
<p>KFP provides task-level output caching to reduce redundant computation by skipping the execution of tasks that were completed in a previous pipeline run. Caching is enabled by default, but can be disabled by calling <code>.set_caching_options(False)</code> on a task.</p>
<p>The cache key is determined by the task&rsquo;s component specification (image, command, arguments, input/output interface) and the task&rsquo;s provided inputs (the name and URI of artifacts and the name and value of parameters). Cache hit status is not determined until task runtime since input values may be unknown until pipeline runtime.</p>
<p>When a task&rsquo;s cache hits and its execution is skipped, it will be displayed on the KFP UI:</p>
<!-- TODO: add photo of cache on UI -->

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6afd16685922f350ab1b27a4d4e79d0c">4.3 - Pipelines</h1>
    <div class="lead">Create a pipeline</div>
	<p>A <em>pipeline</em> is a description of a multi-task workflow, including how tasks relate to each other to form an computational graph. Pipelines may have inputs which can be passed to tasks within the pipeline.</p>
<h2 id="author-a-pipeline">Author a pipeline</h2>
<p>Unlike components which have three authoring approaches, pipelines have one authoring approach: they are defined using Python pipeline functions decorated with <code>@dsl.pipeline</code>. For example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task</span> <span class="o">=</span> <span class="n">my_component</span><span class="p">(</span><span class="n">arg1</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>@dsl.pipeline</code> decorator takes three optional arguments.</p>
<ul>
<li><code>name</code> is the name of your pipeline. If not provided, the name defaults to a sanitized version of the pipeline function name.</li>
<li><code>description</code> is a description of the pipeline.</li>
<li><code>pipeline_root</code> is the remote storage root path from which your pipeline will write and read artifacts (e.g., <code>gs://my/path</code>).</li>
</ul>
<p>A pipeline function is a function that may have inputs, instantiates components as tasks and uses them to form a computational graph, and only uses the KFP domain-specific language objects and syntax within the function scope. Let&rsquo;s walk through each of these parts one-by-one.</p>
<p>First, like a component, a pipeline function may have inputs and outputs. This allows your pipeline to serve as a computational template that can be executed with different input parameters to create a specified set of outputs. See <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io/#pipeline-io">Component I/O: Pipeline I/O</a> for how to use type annotations in a pipeline.</p>
<p>Second, a pipeline function instantiates components as tasks and uses them to form a computational graph. For information on how to instatiate components as tasks and pass data between them, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io#passing-data-between-tasks">Component I/O: Passing data between tasks</a>. For information on task dependencies, see <a href="/docs/components/pipelines/v2/author-a-pipeline/tasks">Tasks</a>.</p>
<p>Third, a pipeline function only uses domain-specific language (DSL) objects and syntax within the function scope. Because the body of a Python pipeline function must ultimately be compiled to IR YAML, pipeline functions only support a very narrow set of Python language features, as specified by the KFP DSL. In addition to instantiation and data passing between tasks, the only three other features permitted are <code>dsl.Condition</code>, <code>dsl.ParallelFor</code> and <code>dsl.ExitHandler</code>. Use of these three features is covered in the next section. Use of classes, list comprehensions, lambda functions, and other arbitrary Python language features are not permitted within the scope of a Python pipeline function.</p>
<h2 id="dsl-control-flow-features">DSL control flow features</h2>
<p>A critical difference between components and pipelines is how control flow is authored and executed. Within a Python component, control flow is authored using arbitrary Python language features and the raw Python code is executed at component runtime. Within the scope of a pipeline, control flow acts on tasks, is authored using DSL features, and is executed by the KFP backend through the creation of Kubernetes Pods to execute those tasks.  <code>dsl.Condition</code>, <code>dsl.ParallelFor</code> and <code>dsl.ExitHandler</code> can be used to orchestrate the completion of tasks within a pipeline function body. Each is implemented as a Python context manager.</p>
<h3 id="dslcondition">dsl.Condition</h3>
<p>The <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>dsl.Condition</code></a> context manager allows conditional execution of tasks within its scope based on the output of an upstream task. The context manager takes two arguments: a required <code>condition</code> and an optional <code>name</code>. The <code>condition</code> is a comparative expression where at least one of the two operands is an output from an upstream task.</p>
<p>In the following pipeline, <code>conditional_task</code> only executes if <code>coin_flip_task</code> has the output <code>'heads'</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">coin_flip_task</span> <span class="o">=</span> <span class="n">flip_coin</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">Condition</span><span class="p">(</span><span class="n">coin_flip_task</span><span class="o">.</span><span class="n">output</span> <span class="o">==</span> <span class="s1">&#39;heads&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">conditional_task</span> <span class="o">=</span> <span class="n">my_comp</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="dslparallelfor">dsl.ParallelFor</h3>
<p>The <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>dsl.ParallelFor</code></a> context manager allows parallelized execution of tasks over a static set of items. The context manager takes two arguments: a required <code>items</code>, an optional <code>parallelism</code>, and an optional <code>name</code>. <code>items</code> is the static set of items to loop over, while <code>parallelism</code> is the maximum number of concurrent iterations permitted while executing the <code>dsl.ParallelFor</code> group. <code>parallelism=0</code> indicates unconstrained parallelism.</p>
<p>In the following pipeline, <code>train_model</code> will train a model for 1, 5, 10, and 25 epochs, with no more than two training tasks running at one time:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ParallelFor</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">items</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">parallelism</span><span class="o">=</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="k">as</span> <span class="n">epochs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_model</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="dslexithandler">dsl.ExitHandler</h3>
<p>The <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>dsl.ExitHandler</code></a> context manager allows pipeline authors to specify an &ldquo;exit handler&rdquo; task which will run after the tasks within its scope finish execution or one of them fails. This is analogous to using <code>try:</code> followed by <code>finally:</code> in normal Python. The context manager takes two arguments: a required <code>exit_task</code> and an optional <code>name</code>. The <code>exit_task</code> is the &ldquo;exit handler&rdquo; task and must be instantiated before the <code>dsl.ExitHandler</code> context manager is entered.</p>
<p>In the following pipeline, <code>clean_up_task</code> will execute after either both <code>create_dataset</code> and <code>train_and_save_models</code> finish or one of them fails:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">clean_up_task</span> <span class="o">=</span> <span class="n">clean_up_resources</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ExitHandler</span><span class="p">(</span><span class="n">exit_task</span><span class="o">=</span><span class="n">clean_up_task</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset_task</span> <span class="o">=</span> <span class="n">create_datasets</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_task</span> <span class="o">=</span> <span class="n">train_and_save_models</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset_task</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><p>The task you use as an exit task may use a special backend-provided input that provides access to pipeline and task status metadata, including pipeline failure or success status. You can use this special input by annotating your exit task with the <code>dsl.PipelineTaskFinalStatus</code> annotation. You should not provide any input to this annotation when you instantiate your exit task.</p>
<p>The following pipeline uses <code>PipelineTaskFinalStatus</code> to obtain information about the pipeline and task failure, even after <code>fail_op</code> fails:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">PipelineTaskFinalStatus</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">exit_op</span><span class="p">(</span><span class="n">user_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">status</span><span class="p">:</span> <span class="n">PipelineTaskFinalStatus</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Prints pipeline run status.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">user_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pipeline status: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Job resource name: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">pipeline_job_resource_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pipeline task name: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">pipeline_task_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error code: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">error_code</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error message: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">error_message</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fail_op</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">sys</span>
</span></span><span class="line"><span class="cl">    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_op</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_status_task</span> <span class="o">=</span> <span class="n">exit_op</span><span class="p">(</span><span class="n">user_input</span><span class="o">=</span><span class="s1">&#39;Task execution status:&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ExitHandler</span><span class="p">(</span><span class="n">exit_task</span><span class="o">=</span><span class="n">print_status_task</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">fail_op</span><span class="p">()</span>
</span></span></code></pre></div><!-- TODO: make this reference more precise throughout -->

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-4cdabdf4d68974491ee69accb5f7080d">4.4 - Component I/O</h1>
    <div class="lead">Use parameter/artifact inputs and outputs</div>
	<p>Components may accept inputs and create outputs. Inputs and outputs can be one of two types: parameters or artifacts. The following matrix describes possible component inputs and outputs:</p>
<table>
<thead>
<tr>
<th></th>
<th>Parameter</th>
<th>Artifact</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input</td>
<td>Input Parameter</td>
<td>Input Artifact</td>
</tr>
<tr>
<td>Output</td>
<td>Output Parameter</td>
<td>Output Artifact</td>
</tr>
</tbody>
</table>
<p>Throughout the remainder of this section, we will use the following example dataset creation pipeline to understand the behavior and usage of input and output parameters and artifacts:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Output</span><span class="p">,</span> <span class="n">Dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">initial_text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">output_dataset</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Create a dataset containing the string `initial_text`.&#34;&#34;&#34;</span> 
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sh&#39;</span><span class="p">,</span> <span class="s1">&#39;-c&#39;</span><span class="p">,</span> <span class="s1">&#39;mkdir --parents $(dirname &#34;$1&#34;) &amp;&amp; echo &#34;$0&#34; &gt; &#34;$1&#34;&#39;</span><span class="p">,],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">initial_text</span><span class="p">,</span> <span class="n">output_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">augment_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">existing_dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">resulting_dataset</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Append `text` `num` times to an existing dataset, then write it as a new dataset.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">additional_data</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">existing_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">existing_dataset_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">resulting_dataset_text</span> <span class="o">=</span> <span class="n">existing_dataset_text</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">additional_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">resulting_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">resulting_dataset_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">resulting_dataset_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">initial_text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;initial dataset text&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">create_task</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">initial_text</span><span class="o">=</span><span class="n">initial_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">augment_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">existing_dataset</span><span class="o">=</span><span class="n">create_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_dataset&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">text</span><span class="o">=</span><span class="s1">&#39;additional text&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>This pipeline uses a <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container component</a> <code>create_dataset</code> to construct an initial <code>Dataset</code> artifact containing <code>initial_text</code>. Then, the downstream <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#1-lighweight-python-function-based-components">lightweight Python component</a> <code>augment_dataset</code> appends <code>text</code> repeated <code>num</code> times to the dataset and saves it as a new dataset.</p>
<h2 id="inputs">Inputs</h2>
<p>Component inputs are specified by the component function&rsquo;s signature. This applies for all authoring approaches: <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#1-lighweight-python-function-based-components">lightweight Python components</a>, <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#2-containerized-python-components">containerized Python components</a>, and <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container components</a>.</p>
<p>Ultimately, each authoring style creates a component definitied by an <code>image</code>, <code>command</code>, and <code>args</code>. When you use an input, it is represented as a placeholder in the <code>command</code> or <code>args</code> and is interpolated at component runtime.</p>
<p>There is one additional type of input, the struct <code>PipelineTaskFinalStatus</code>, which allows access to the metadata of one task from within another via a system-provided value at runtime. This input is a special case, as it is neither a typical parameter nor an artifact and it is only usable in <code>dsl.ExitHandler</code> exit tasks. Use of this input is covered in <a href="/docs/components/pipelines/v2/author-a-pipeline/pipelines">Authoring: Pipelines</a>.</p>
<h3 id="input-parameters">Input parameters</h3>
<p>Input parameters are declared when you use a <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code> or <code>list</code> type annotation. The data passed to parameters typed with <code>dict</code> or <code>list</code> may only container JSON-serializable Python primitives. <code>Union</code> types are not permitted.</p>
<p>In the example <code>create_dataset</code> component, <code>initial_text</code> is an input parameter. In <code>augment_dataset</code>, <code>text</code> and <code>num</code> are input parameters.</p>
<p>Input parameters may have default values. For example, <code>augment_dataset</code>&rsquo;s <code>num</code> parameter has a default value of <code>10</code>.</p>
<p>Within a component function body, use input parameters just as you would in a normal Python function.</p>
<h3 id="input-artifacts">Input artifacts</h3>
<p>Input artifacts are defined when you use an <code>Input[&lt;ArtifactClass&gt;]</code> annotation. For more information about artifacts, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io/">Component I/O</a>.</p>
<p>At component runtime, input artifacts are copied to the local filesystem by the executing backend. This abstracts away the need for the component author to know where artifacts are stored in remote storage and allows component authors to only interact with the local filesystem when implementing a component that uses an artifact. All artifacts implement a <code>.path</code> method, which can be used to access the local path where the artifact file has been copied.</p>
<p>Let&rsquo;s see how this works in practice. In our example pipeline, <code>augment_dataset</code> specifies the input <code>existing_dataset: Input[Dataset]</code>. In the pipeline definition, we pass the output dataset from <code>create_dataset</code> to this parameter. When the <code>augument_dataset</code> component runs, the executing backend copies the <code>output_dataset</code> artifact file to the container filesystem and passes in an instance of <code>Dataset</code> as an argument to <code>existing_dataset</code>. The <code>Dataset</code> instance has a <code>.path</code> handle to its location in the container filesystem, allowing the component to read it:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">existing_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">existing_dataset_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span></code></pre></div><h2 id="outputs">Outputs</h2>
<p>Like inputs, component outputs are also specified by the component function&rsquo;s signature. Depending on the component authoring approach and the type of output (parameter or artifact), outputs may be specified by the function return type annotation (e.g., <code>-&gt; int</code>), the type annotation generic <code>Output[]</code>, or the type annotation class <code>OutputPath</code>. Uses for each are explained in the sections to follow.</p>
<p>For all output types and authoring styles, outputs from a component are persisted to a remote file store, such as <a href="https://min.io/">Minio</a>, <a href="https://cloud.google.com/storage">Google Cloud Storage</a>, or <a href="https://aws.amazon.com/s3/">AWS S3</a>, that way they outlast the ephemeral container that creates them and can be picked up for use by a downstream task.</p>
<h3 id="output-parameters">Output parameters</h3>
<p>Output parameters are declared in different ways depending on the authoring approach.</p>
<h4 id="python-components">Python components</h4>
<p>For lightweight Python components and containerized Python components, output parameters are declared by the Python component function return type annotation (e.g., <code>-&gt; int</code>). Like parameter inputs, return type annotations may be <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code> or <code>list</code>.</p>
<p>In our example, <code>augment_dataset</code> has a one integer output.</p>
<p>You may also specify multiple output parameters by using these annotations within a <code>typing.NamedTuple</code> as follows:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_component</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]):</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">output</span><span class="p">(</span><span class="s1">&#39;my_dataset&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="custom-container-components">Custom container components</h4>
<p>For <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container components</a>, output parameters are declared via an <code>OutputPath</code> annotation, which is a class that takes a type as its only argument (e.g., <code>OutputPath(int)</code>). At runtime, the backend will pass a filepath string to parameters with this annotation. This string indicating where in the container filesystem the component should write this parameter output. The backend will copy the file specified by this path to remote storage after component execution.</p>
<p>While the lightweight component executor handles writing the output parameters to the correct local filepath, custom container component authors must implement this in the container logic.</p>
<p>For example, the following very simple <code>create_text_output_parameter</code> component creates the output parameter string <code>&quot;some text&quot;</code> by using an <code>OutputPath(str)</code> annotation and writing the parameter to the path in the variable <code>output_string_path</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">OutputPath</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_text_output_parameter</span><span class="p">(</span><span class="n">output_string_path</span><span class="p">:</span> <span class="n">OutputPath</span><span class="p">(</span><span class="nb">str</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;sh&#39;</span><span class="p">,</span> <span class="s1">&#39;-c&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;mkdir --parents $(dirname &#34;$0&#34;) &amp;&amp; echo &#34;some text&#34; &gt; &#34;$0&#34;&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">output_string</span><span class="p">])</span>
</span></span></code></pre></div><h3 id="output-artifacts">Output artifacts</h3>
<p>Output artifacts are declared when you use an <code>Output[&lt;ArtifactClass&gt;]</code> annotation. For more information about artifacts, see [Artifacts][artifacts].</p>
<p>Output artifacts are treated inversely to input artifacts at component runtime: instead of being <em>copied to the container</em> from remote storage, they are <em>copied to remote storage</em> from the <code>.path</code> location in the container&rsquo;s filesystem after the component executes. This abstracts away the need for the component author to know where artifacts are stored in remote storage and allows component authors to only interact with the local filesystem when implementing a component that creates an artifact. As with using an artifact input, component authors should write artifacts to <code>.path</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">resulting_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">resulting_dataset_text</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="pipeline-io">Pipeline I/O</h2>
<p>A pipeline may be used like a component by instantiating it as a task within another pipeline.</p>
<h3 id="inputs-1">Inputs</h3>
<p>All pipeline inputs must include type annotations. Valid input parameter annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, <code>list</code>. Input parameters may also have defaults. The only valid input artifact annotation is <code>Input[&lt;Artifact&gt;]</code> (where <code>&lt;Artifact&gt;</code> is any KFP-compatible artifact class). Input artifacts may not have defaults.</p>
<p>The following simple pipeline has a <code>str</code> parameter <code>text</code> and an <code>int</code> parameter <code>number</code>. <code>number</code> has a default value of <code>10</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">number</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span></code></pre></div><p>Ultimately, all inputs must be passed to an inner &ldquo;primitive&rdquo; component in order to perform computation on the input. See <a href="#from-a-pipeline-input">Passing data between tasks: From a pipeline input</a> for information about how to pass data from a pipeline input to a component within the pipeline.</p>
<h3 id="outputs-1">Outputs</h3>
<p>Pipelines may also have output parameters. All outputs are specified by a normal Python function return type annotation indicated by the <code>-&gt;</code> token (e.g., <code>-&gt; int</code>). Valid parameter type annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, and <code>list</code>. Valid artifact type return annotations include <code>&lt;Artifact&gt;</code> (where <code>&lt;Artifact&gt;</code> is a KFP-compatible artifact class). You may specify multiple outputs using a <code>typing.NamedTuple</code> return annotation (see <a href="#python-components">Python Components</a>) for more information on how to use named tuple return types.</p>
<p>Ultimately, all outputs must be created by an inner &ldquo;primitive&rdquo; component. Pipelines may return this output as its output.</p>
<p>For example, the following <code>double</code> pipeline returns the single <code>int</code> output of the <code>multiply</code> component:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">double</span><span class="p">(</span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">multiply</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">output</span>
</span></span></code></pre></div><p>In the following different example, the <code>training_workflow</code> pipeline returns a <code>Model</code> from the inner <code>train_model</code> component:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Output</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># do training</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span> <span class="o">=</span> <span class="o">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">training_workflow</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">get_dataset_op</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_model_op</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">get_dataset_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;dataset&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">train_model_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span>
</span></span></code></pre></div><h2 id="passing-data-between-tasks">Passing data between tasks</h2>
<p>To instantiate a component as a task, you must pass to it any required inputs. Required inputs include all input parameters without default values and all input artifacts.</p>
<p>Output parameters (e.g., <code>OutputPath</code>) and output artifacts (e.g., <code>Output[&lt;ArtifactClass&gt;]</code>) should not be passed explicitly by the pipeline author; they will be passed at component runtime by the executing backend. This allows component internals to know where output parameters and artifacts should be written in the container filesystem in order to be copied to remote storage by the backend.</p>
<p>Task inputs may come from one of three different places: a static variable, a pipeline parameter, or an upstream task output. Let&rsquo;s walk through each, using the following <code>identity</code> component to help illustrate each approach:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><h3 id="from-a-static-variable">From a static variable</h3>
<p>To provide static data as an input to a component, simply pass it as you would when using a normal function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><p>Note: Input artifacts cannot be passed as static variables; they must always be passed from an upstream task or an <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#special-case-importer-components"><code>importer</code> component</a>.</p>
<h3 id="from-a-pipeline-input">From a pipeline input</h3>
<p>To pass data from a pipeline input to an inner task, simply pass the variable name as you normally would when calling one function within another:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline_var_x</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">pipeline_var_x</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="from-a-task-output">From a task output</h3>
<p>Tasks provide references to their outputs in order to support passing data between tasks in a pipeline.</p>
<p>In nearly all cases, outputs are accessed via <code>.outputs['&lt;parameter&gt;']</code>, where <code>'&lt;parameter&gt;'</code> is the parameter name or named tuple field name from the task that produced the output which you wish to access. The <code>.outputs['&lt;parameter&gt;']</code> access pattern is used to access <code>Output[]</code> artifacts, <code>OutputPath</code> output parameters, and <code>NamedTuple</code> output parameters.</p>
<p>The only exception to this access pattern is when you wish to access a single return value from a lightweight Python component, which can be accessed through the task&rsquo;s <code>.output</code> attribute.</p>
<p>The following two subsections demonstrate this for parameters then artifacts.</p>
<h4 id="passing-parameters-from-task-to-task">Passing parameters from task to task</h4>
<p>Let&rsquo;s introduce two more components for sake of demonstrating passing parameters between components:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">named_tuple</span><span class="p">(</span><span class="n">an_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Lightweight Python component with a NamedTuple output.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">outputs</span><span class="p">(</span><span class="s1">&#39;my_dataset&#39;</span><span class="p">,</span> <span class="n">an_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">identity_container</span><span class="p">(</span><span class="n">integer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_int</span><span class="p">:</span> <span class="n">OutputPath</span><span class="p">(</span><span class="nb">int</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Custom container component that creates an integer output parameter.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;sh&#39;</span><span class="p">,</span> <span class="s1">&#39;-c&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;mkdir --parents $(dirname &#34;$0&#34;) &amp;&amp; echo &#34;$1&#34; &gt; &#34;$0&#34;&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">output_int</span><span class="p">,</span> <span class="n">integer</span><span class="p">])</span>
</span></span></code></pre></div><p>Using the new <code>named_tuple</code> and <code>identity_container</code> components with our original <code>identity</code> component, the following pipeline shows the full range of task-to-task data passing styles:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline_parameter_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">named_tuple_task</span> <span class="o">=</span> <span class="n">named_tuple</span><span class="p">(</span><span class="n">an_id</span><span class="o">=</span><span class="n">pipeline_parameter_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># access a named tuple parameter output via .outputs[&#39;&lt;parameter&gt;&#39;]</span>
</span></span><span class="line"><span class="cl">    <span class="n">identity_container_task</span> <span class="o">=</span> <span class="n">identity_container</span><span class="p">(</span><span class="n">integer</span><span class="o">=</span><span class="n">named_tuple_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># access an OutputPath parameter output via .outputs[&#39;&lt;parameter&gt;&#39;]</span>
</span></span><span class="line"><span class="cl">    <span class="n">identity_task_1</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">identity_container_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_int&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># access a lightweight component return value via .output</span>
</span></span><span class="line"><span class="cl">    <span class="n">identity_task_2</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">identity_task_1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="passing-artifacts-from-task-to-task">Passing artifacts from task to task</h4>
<p>Artifacts may only be annotated via <code>Input[&lt;ArtifactClass&gt;]</code>/<code>Output[&lt;ArtifactClass&gt;]</code> annotations and may only be accessed via the <code>.outputs['&lt;parameter&gt;']</code> syntax. This makes passing them between tasks somewhat simpler than for parameters.</p>
<p>The pipeline below demonstrates passing an artifact between tasks using an artifact producer and an artifact consumer:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Artifact</span><span class="p">,</span> <span class="n">Input</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">producer</span><span class="p">(</span><span class="n">output_artifact</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Artifact</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_artifact</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;my artifact&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">consumer</span><span class="p">(</span><span class="n">input_artifact</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Artifact</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_artifact</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">producer_task</span> <span class="o">=</span> <span class="n">producer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">consumer</span><span class="p">(</span><span class="n">input_artifact</span><span class="o">=</span><span class="n">producer_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_artifact&#39;</span><span class="p">])</span>
</span></span></code></pre></div><h2 id="special-input-values">Special input values</h2>
<p>There are a few special input values that may be used to access pipeline or task metadata within a component. These values can passed to input parameters typed with <code>str</code>. For example, the following <code>print_op</code> component can obtain the pipeline job name at component runtime by using the <code>dsl.PIPELINE_JOB_NAME_PLACEHOLDER</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_op</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">dsl</span><span class="o">.</span><span class="n">PIPELINE_JOB_NAME_PLACEHOLDER</span><span class="p">)</span>
</span></span></code></pre></div><p>There several placeholders that may be used in this style, including:</p>
<ul>
<li><code>dsl.PIPELINE_JOB_NAME_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_JOB_RESOURCE_NAME_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_JOB_ID_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_TASK_NAME_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_TASK_ID_PLACEHOLDER</code></li>
</ul>
<h2 id="placeholders">Placeholders</h2>
<p>In general, each of the three component authoring styles handle the injection of placeholders into your container <code>command</code> and <code>args</code>, allowing the component author to not have to worry about them. However, there are two types of placeholders you may wish to use directly: <code>ConcatPlaceholder</code> and <code>IfPresentPlaceholder</code>. These placeholders may only be used when authoring <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container components</a> via the <code>@dsl.container_component</code> decorator.</p>
<h3 id="concatplaceholder">ConcatPlaceholder</h3>
<p>When you provide a container <code>command</code> or container <code>args</code> as a list of strings, each element in the list is concatenated using a space separator, then issued to the container. Concatenating an one input to another string without a space separator requires special handling provided by the <code>ConcatPlaceholder</code>.</p>
<p><code>ConcatPlaceholder</code> takes one argument, <code>items</code> which may be a list of any combination of static strings, parameter inputs, or other instances of <code>ConcatPlaceholder</code> or <code>IfPresentPlaceholder</code>. At runtime, these strings will be concatenated together without a separator.</p>
<p>For example, you can use <code>ConcatPlaceholder</code> to concatenate a file path prefix, suffix, and extension:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">concatenator</span><span class="p">(</span><span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">suffix</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;my_program.sh&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--input&#39;</span><span class="p">,</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ConcatPlaceholder</span><span class="p">([</span><span class="n">prefix</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="s1">&#39;.txt&#39;</span><span class="p">])]</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><h3 id="ifpresentplaceholder">IfPresentPlaceholder</h3>
<p><code>IfPresentPlaceholder</code> is used to conditionally provide command line arguments. The <code>IfPresentPlaceholder</code> takes three arguments: <code>input_name</code>, <code>then</code>, and optionally <code>else_</code>. This placeholder is easiest to understand through an example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">hello_someone</span><span class="p">(</span><span class="n">optional_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;python:3.7&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;echo&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">dsl</span><span class="o">.</span><span class="n">IfPresentPlaceholder</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">input_name</span><span class="o">=</span><span class="s1">&#39;optional_name&#39;</span><span class="p">,</span> <span class="n">then</span><span class="o">=</span><span class="p">[</span><span class="n">optional_name</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="p">])</span>
</span></span></code></pre></div><p>If the <code>hello_someone</code> component is passed <code>'world'</code> as an argument for <code>optional_name</code>, the component will print <code>hello world</code>. If not, it will only print <code>hello</code>.</p>
<p>The third parameter <code>else_</code> can be used to provide a default value to fall back to if <code>input_name</code> is not provided.</p>
<p>Arguments to <code>then</code> and <code>else_</code> may be a list of any combination of static strings, parameter inputs, or other instances of <code>ConcatPlaceholder</code> or <code>IfPresentPlaceholder</code>.</p>
<h2 id="component-interfaces-and-type-checking">Component interfaces and type checking</h2>
<p>The KFP SDK compiler has the ability to use the type annotations you provide to type check your pipeline definition for mismatches between input and output types. The type checking logic is simple yet handy, particularly for complex pipelines. The type checking logic is:</p>
<ul>
<li>Parameter outputs may only be passed to parameter inputs. Artifact outputs may only be passed to artifact inputs.</li>
<li>A parameter output type (<code>int</code>, <code>str</code>, etc.) must match the annotation of the parameter input to which it is passed.</li>
<li>An artifact output type (<code>Dataset</code>, <code>Model</code>, etc.) must match the artifact input type to which it is passed <em>or</em> either of the two artifact annotations must use the generic KFP <code>Artifact</code> class.</li>
</ul>

</div>



    
	
  

    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-949036519b58594da97d168aa118d46d">5 - Compile a Pipeline</h1>
    <div class="lead">Compile a pipeline definition to YAML</div>
	<p>While pipelines and components are authored in Python, they can be compiled to intermediate representation (IR) YAML (<a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml">example</a>).</p>
<p>A YAML pipeline/component definition preserves a static representation of your pipeline/component. This YAML can be submitted to the KFP backend for execution or deserialized by the KFP SDK for integration into another pipeline.</p>
<h2 id="compiling">Compiling</h2>
<p>First let&rsquo;s define a very simple pipeline:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">compiler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">num1</span> <span class="o">+</span> <span class="n">num2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;addition-pipeline&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_task_1</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_task_2</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">add_task_1</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</span></span></code></pre></div><p>Now we can compile the pipeline to the file <code>my_pipeline.yaml</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cmplr</span> <span class="o">=</span> <span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">cmplr</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">,</span> <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;my_pipeline.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>Just as a pipeline is a template for a multi-step workflow, a component is a template for a single-step workflow. We can also compile the component <code>addition_component</code> directly:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cmplr</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">addition_component</span><span class="p">,</span> <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;addition_component.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>Compiler.compile</code> method accepts a few optional additional parameters:</p>
<p><strong><code>pipeline_name</code></strong> (<code>string</code>)</p>
<p>Sets the name of the pipeline (or component). This is written to IR as the  <code>pipelineInfo.name</code> field. Will override the <code>name</code> passed to the <code>@dsl.pipeline</code> decorator.</p>
<p>The pipeline name, whether set through the decorator or the compiler, names your pipeline template. When you upload your pipeline, a pipeline context by this name will be created. The pipeline context enables the backend and the Dashboard to associate artifacts and executions created from runs of the same pipeline template. This allows you, for example, to compare metrics artifacts from multiple runs of the same training pipeline to find the best model.</p>
<p><strong><code>pipeline_parameters</code></strong> (<code>Dict[str, Any]</code>)</p>
<p>A map of parameter names to argument values. This amounts to providing default values for pipeline or component parameters. These defaults can be overriden at pipeline submission time.</p>
<p><strong><code>type_check</code></strong> (<code>bool</code>)</p>
<p>Whether to enable static type checking during compilation. For more information about type checking, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io#component-interfaces-and-type-checking">Component I/O: Component interfaces and type checking</a>.</p>
<h2 id="ir-yaml">IR YAML</h2>
<p>When you compile a pipeline it is written to intermediate representation (IR) YAML. An IR YAML is an instance of the <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L50"><code>PipelineSpec</code></a> protocol buffer message type, a platform-agnostic pipeline representation protocol.</p>
<p>IR YAML is considered an intermediate representation because the KFP backend compiles <code>PipelineSpec</code> to <a href="https://argoproj.github.io/argo-workflows/">Argo Workflow</a> YAML as the final execution definition for execution on Kubernetes.</p>
<p>Unlike v1 component YAML, IR YAML is not intended to be written directly. For a KFP v2 authoring experience similar to the v1 component YAML authoring experience, see <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">Author a Pipeline: Custom Container Components</a>.</p>
<p>IR YAML contains 7 top-level fields:</p>
<p><strong>components</strong></p>
<p>The <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L74-L75"><code>components</code></a> section is a map of component name to <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L85-L96"><code>ComponentSpec</code></a> for all components used in the pipeline. <code>ComponentSpec</code> defines the interface (inputs and outputs) of a component. For primitive components, <code>ComponentSpec</code> contains a reference to the executor containing the component implementation. For pipelines used as components, <code>ComponentSpec</code> contains a <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L98-L105">DagSpec</a> which includes references to its underlying primitive components.</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L1-L21">Example</a></p>
<p><strong>deployment_spec</strong></p>
<p>The <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L56"><code>deployment_spec</code></a> section contains a map of executor name to <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L788-L803"><code>ExecutorSpec</code></a>. <code>ExecutorSpec</code> contains the implementation for a primitive component.</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L23-L49">Example</a></p>
<p><strong>root</strong><br>
<a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L77-L79"><code>root</code></a> defines the steps of the outermost (root) pipeline definition. It is itself a <a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L85-L96"><code>ComponentSpec</code></a>. This is the pipeline executed when the YAML is submitted.</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L52-L85">Example</a></p>
<p><strong>pipeline_info</strong><br>
<a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L51-L52"><code>pipeline_info</code></a> contains pipeline metadata, including the pipeline name.</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L50-L51">Example</a></p>
<p><strong>sdk_version</strong><br>
<a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L58-L59"><code>sdk_version</code></a> records which version of the KFP SDK compiled the pipeline.</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L87">Example</a></p>
<p><strong>schema_version</strong><br>
<a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L61-L62"><code>schema_version</code></a> records which version of the <code>PipelineSpec</code> schema is used for the IR YAML.</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L86">Example</a></p>
<p><strong>default_pipeline_root</strong><br>
<a href="https://github.com/kubeflow/pipelines/blob/41b69fd90da812005965f2209b64fd1278f1cdc9/api/v2alpha1/pipeline_spec.proto#L81-L82"><code>default_pipeline_root</code></a> is the remote storage root path where the pipeline outputs will be written, such as a Google Cloud Storage URI (<code>gcs://my/path</code>).</p>
<p><a href="https://github.com/kubeflow/pipelines/blob/984d8a039d2ff105ca6b21ab26be057b9552b51d/sdk/python/test_data/pipelines/two_step_pipeline.yaml#L22">Example</a></p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-a68b69ed119639161f8aa77ca8cb9aa9">6 - Run a Pipeline</h1>
    <div class="lead">Execute a pipeline on the KFP backend</div>
	<p>The KFP SDK offers three ways to run a pipeline.</p>
<h2 id="1-run-from-the-kfp-dashboard">1. Run from the KFP Dashboard</h2>
<p>The first and easiest way to run a pipeline is by submitting it via the KFP dashboard.</p>
<p>To submit a pipeline to the KFP Dashboard:</p>
<ol>
<li>
<p><a href="/docs/components/pipelines/v2/compile-a-pipeline/">Compile the pipeline</a> to IR YAML.</p>
</li>
<li>
<p>From the Dashboard, select &ldquo;+ Upload pipeline&rdquo;.</p>
</li>
</ol>
<p><img src="/docs/images/pipelines/submit-a-pipeline-on-dashboard.png" 
alt="Upload pipeline button"
class="mt-3 mb-3 border border-info rounded"></p>
<ol start="3">
<li>Upload the pipeline IR YAML to &ldquo;Upload a file&rdquo;, populate the upload pipeline form, and click &ldquo;Create&rdquo;.</li>
</ol>
<p><img src="/docs/images/pipelines/upload-a-pipeline.png" 
alt="Upload pipeline screen"
class="mt-3 mb-3 border border-info rounded"></p>
<ol start="4">
<li>From the Runs tab, select &ldquo;+ Create run&rdquo;:</li>
</ol>
<p><img src="/docs/images/pipelines/create-run.png" 
alt="Create run button"
class="mt-3 mb-3 border border-info rounded"></p>
<ol start="5">
<li>Choose the pipeline you uploaded, provide a name, any run parameters, and click &ldquo;Start&rdquo;.
<img src="/docs/images/pipelines/start-a-run.png" 
alt="Start a run screen"
class="mt-3 mb-3 border border-info rounded"></li>
</ol>
<h2 id="2-run-from-the-kfp-sdk-client">2. Run from the KFP SDK client</h2>
<p>You may also programatically submit pipeline runs from the KFP SDK client. The client supports two ways of submitting runs: from IR YAML or from a Python pipeline function. For either approach, start by instantiating a <code>Client</code> using the <code>host</code> URL of your KFP instance:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.client</span> <span class="kn">import</span> <span class="n">Client</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;&lt;YOUR_HOST_URL&gt;&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>To submit IR YAML for execution use the <code>.create_run_from_pipeline_package</code> method:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_package</span><span class="p">(</span><span class="s1">&#39;pipeline.yaml&#39;</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;param&#39;</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;other_param&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
</span></span></code></pre></div><p>To submit a Python pipeline function for execution use the <code>.create_run_from_pipeline_func</code> convenience method, which wraps compilation and run submission into one method:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span><span class="s1">&#39;pipeline.yaml&#39;</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;param&#39;</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;other_param&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
</span></span></code></pre></div><p>See the <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/client.html">KFP SDK Client reference documentation</a> for a detailed description of the <code>Client</code> constructor and method parameters.</p>
<h2 id="3-run-from-the-kfp-sdk-cli">3. Run from the KFP SDK CLI</h2>
<p>The <code>kfp run create</code> command allows you to submit a pipeline from the command line. <code>kfp run create --help</code> shows that this command takes the form:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp run create <span class="o">[</span>OPTIONS<span class="o">]</span> <span class="o">[</span>ARGS<span class="o">]</span>...
</span></span></code></pre></div><p>For example, the following command submits the <code>path/to/pipeline.yaml</code> IR YAML to the KFP backend:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp run create --experiment-name my-experiment --package-file path/to/pipeline.yaml
</span></span></code></pre></div><p>For more information about the <code>kfp run create</code> command, see the <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/cli.html#kfp-run-create">KFP Command Line Interface reference documentation</a>. For more information on the KFP CLI generally see <a href="/docs/components/pipelines/v2/cli/">Command Line Interface user docs</a>.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-417e76f1404dfae7c66273efdc10e05b">7 - Command Line Interface</h1>
    <div class="lead">Interact with KFP via the CLI</div>
	<!-- TODO: use /latest instead of /master when SDK goes GA -->
<p>This section provides a high-level summary of the KFP command line interface (CLI). For more detailed API documentation, see the <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/cli.html">KFP CLI reference</a>.</p>
<h2 id="usage">Usage</h2>
<p>The KFP CLI is installed with the KFP SDK as <code>kfp</code>.</p>
<p>You can check that the KFP CLI is installed in your environment by running:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp --version
</span></span></code></pre></div><p>All commands assume the general structure:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp <span class="o">[</span>OPTIONS<span class="o">]</span> COMMAND <span class="o">[</span>ARGS<span class="o">]</span>...
</span></span></code></pre></div><p>For example, to list all runs for a specific endpoint:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp --endpoint http://my_kfp_endpoint.com run list
</span></span></code></pre></div><p>You can get help for a particular command directly on the command line using <code>--help</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp run --help
</span></span></code></pre></div><p>The KFP CLI serves three main functions:</p>
<ol>
<li>Interacting with KFP resources</li>
<li>Compiling pipelines</li>
<li>Building Python-based containerized components</li>
</ol>
<h2 id="interact-with-kfp-resources">Interact with KFP resources</h2>
<p>The majority of the KFP CLI commands involve creating, reading, updating, or deleting KFP resources via the KFP backend. All of these commands take a common structure:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp &lt;resource_name&gt; &lt;action&gt;
</span></span></code></pre></div><p><code>&lt;resource_name&gt;</code> can be one of the following:</p>
<ul>
<li><code>run</code></li>
<li><code>recurring-run</code></li>
<li><code>pipeline</code></li>
<li><code>experiment</code></li>
</ul>
<p>All resources support the following actions:</p>
<ul>
<li><code>create</code></li>
<li><code>list</code></li>
<li><code>get</code></li>
<li><code>delete</code></li>
</ul>
<p>Some resources have resource-specific actions, including:</p>
<ul>
<li>
<p>For <code>run</code>:</p>
<ul>
<li><code>archive</code></li>
<li><code>unarchive</code></li>
</ul>
</li>
<li>
<p>For <code>recurring-run</code>:</p>
<ul>
<li><code>disable</code></li>
<li><code>enable</code></li>
</ul>
</li>
<li>
<p>For <code>experiment</code></p>
<ul>
<li><code>archive</code></li>
<li><code>unarchive</code></li>
</ul>
</li>
<li>
<p>For <code>pipeline</code>:</p>
<ul>
<li><code>create-version</code></li>
<li><code>list-versions</code></li>
<li><code>get-versions</code></li>
<li><code>delete-versions</code></li>
</ul>
</li>
</ul>
<h2 id="compile-pipelines">Compile pipelines</h2>
<p>The KFP supports compiling a pipeline defined in a Python file to YAML using the <code>kfp dsl compile</code> command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp dsl compile --py path/to/pipeline.py --output path/to/output.yaml
</span></span></code></pre></div><p>To compile a pipeline from a Python file containing multiple pipeline definitions or to compile a component, provide a <code>--function</code> argument:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp dsl compile --py path/to/pipeline.py --output path/to/output.yaml --function my_component
</span></span></code></pre></div><p>The CLI compiler also accepts a <code>--pipeline-parameters</code> argument as JSON:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp dsl compile --py path/to/pipeline.py --output path/to/output.yaml --pipeline-parameters <span class="s1">&#39;{&#34;param1&#34;: 2.0, &#34;param2&#34;: &#34;my_val&#34;}&#39;</span>
</span></span></code></pre></div><h2 id="build-kfp-containerized-python-components">Build KFP containerized Python components</h2>
<p>The KFP SDK support authoring <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#2-containerized-python-components">containerized Python components</a>, allowing the use of more and better-organized source code than does the simpler <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#1-lighweight-python-function-based-components">lightweight Python component</a> authoring experience.</p>
<p>The KFP CLI provides a convenience command for streamlining the process of building a containerized component:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp component build <span class="o">[</span>OPTIONS<span class="o">]</span> COMPONENTS_DIRECTORY <span class="o">[</span>ARGS<span class="o">]</span>...
</span></span></code></pre></div><p>This command builds an image with all the source code found in <code>COMPONENTS_DIRECTORY</code> and uses the component found in the directory as the component runtime entrypoint.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp component build src/ --component-filepattern my_component --push-image
</span></span></code></pre></div><p>For detailed information about all arguments/flags, see <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/cli.html#kfp-component-build">CLI reference documentation</a>. For information about creating containerized components, see [Authoring Python Containerized Components][/docs/components/pipelines/v2/author-a-pipeline/components/#2-containerized-python-components].</p>
<!-- TODO(GA): remove --pre -->
<p>Note: To use this command you&rsquo;ll need to install the KFP SDK with the additional Docker dependency: <code>pip install --pre kfp[all]</code>.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-0aa565b096b841bd6171b56fe09e39c8">8 - Community and Support</h1>
    <div class="lead">Where to get help, contribute, and learn more</div>
	<h2 id="help">Help</h2>
<p>There are several places to get help with KFP:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/tagged/kubeflow-pipelines">kubeflow-pipelines</a> on Stack Overflow</li>
<li>The #kubeflow-pipelines channel in the <a href="https://kubeflow.slack.com/">Kubeflow Slack Workspace</a></li>
<li>Via a GitHub Issue describing your problem in the <a href="https://github.com/kubeflow/pipelines/issues/new/choose">kubeflow/pipelines repository</a></li>
<li>In the Kubeflow Pipelines Community Meeting</li>
</ul>
<h2 id="kubeflow-pipelines-community-meeting">Kubeflow Pipelines Community Meeting</h2>
<p>There is a Kubeflow Pipelines Community meeting every other Wednesday. This is an opportunity to learn about changes to KFP developments, discuss feature requests, and ask questions. When making a feature request, it is best to include a <a href="https://github.com/kubeflow/pipelines/issues/new/choose">GitHub Issue</a> as a written accompaniment to your request.</p>
<p>To participate, join <a href="https://groups.google.com/g/kubeflow-discuss">kubeflow-discuss</a> on Google Groups.</p>
<h2 id="bugs-and-feature-requests">Bugs and Feature Requests</h2>
<p>Bugs and feature requests should be recorded as GitHub Issues in the <a href="https://github.com/kubeflow/pipelines/issues/new/choose">kubeflow/pipelines repository</a>.</p>
<h2 id="contributing">Contributing</h2>
<p>KFP is an open source project and welcomes community contribution. KFP has several components, each with its own contributing guidelines:</p>
<ul>
<li><a href="https://github.com/kubeflow/pipelines/blob/master/backend/README.md">Backend contributing guidelines</a></li>
<li><a href="https://github.com/kubeflow/pipelines/blob/master/frontend/README.md">Frontend contributing guidelines</a></li>
<li><a href="https://github.com/kubeflow/pipelines/blob/master/sdk/CONTRIBUTING.md">SDK contributing guidelines</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-f0fb094d1c5469ccf9ae7e2c40cfebca">9 - Reference</h1>
    <div class="lead">Reference docs for Kubeflow Pipelines</div>
	<h2 id="kfp-sdk">KFP SDK</h2>
<!-- TODO: switch this to /latest once GA -->
<p><a href="https://kubeflow-pipelines.readthedocs.io/en/master/">KFP SDK reference documentation</a></p>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark pt-3 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Kubeflow mailing list" aria-label="Kubeflow mailing list">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-mailing-list" aria-label="Kubeflow mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/kubeflow" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" rel="noopener" href="https://stackoverflow.com/questions/tagged/kubeflow" aria-label="Stack Overflow">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-slack" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-5 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022 Google | Documentation Distributed under CC BY 4.0</small>
        <p><small class="ml-1"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">Privacy Policy</a></small></p>
	
		<p class="mt-2"><a href="/kubeflow-docs/docs/about/">About</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="/kubeflow-docs/js/main.min.301c0110334bec1b4445867d27dc7dd69b2df859154ccf252005508bc860cc5a.js" integrity="sha256-MBwBEDNL7BtERYZ9J9x91pst&#43;FkVTM8lIAVQi8hgzFo=" crossorigin="anonymous"></script>
<script src='/kubeflow-docs/js/tabpane-persist.js'></script>

  </body>
</html>
