<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.105.0">
<link rel="canonical" type="text/html" href="https://gkcalat.github.io/kubeflow-docs/docs/external-add-ons/serving/">
<link rel="alternate" type="application/rss&#43;xml" href="https://gkcalat.github.io/kubeflow-docs/docs/external-add-ons/serving/index.xml">
<meta name="robots" content="noindex, nofollow">

<script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "WebSite",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/gkcalat.github.io\/kubeflow-docs"
      },
      "articleSection" : "docs",
      "name" : "Tools for Serving",
      "headline" : "Tools for Serving",
      "description" : "Serving of ML models in Kubeflow",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "0001",
      "datePublished": "0001-01-01 00:00:00 \u002b0000 UTC",
      "dateModified" : "0001-01-01 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/gkcalat.github.io\/kubeflow-docs\/docs\/external-add-ons\/serving\/",
      "wordCount" : "0",
      "keywords" : [ "Kubeflow" ]
  }
  </script>

<link rel="shortcut icon" href="/kubeflow-docs/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/kubeflow-docs/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-32x32.png" sizes="32x32">
<link rel="manifest" href="/kubeflow-docs/favicons/manifest.json">
<meta name="msapplication-config" content="/kubeflow-docs/favicons/browserconfig.xml" />
<meta name="msapplication-TileColor" content="#4279f4">
<meta name="theme-color" content="#4279f4">

<title>Tools for Serving | Kubeflow on Google Cloud Platform</title>
<meta name="description" content="Serving of ML models in Kubeflow">
<meta property="og:title" content="Tools for Serving" />
<meta property="og:description" content="Serving of ML models in Kubeflow" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gkcalat.github.io/kubeflow-docs/docs/external-add-ons/serving/" /><meta property="og:site_name" content="Kubeflow on Google Cloud Platform" />

<meta itemprop="name" content="Tools for Serving">
<meta itemprop="description" content="Serving of ML models in Kubeflow"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Tools for Serving"/>
<meta name="twitter:description" content="Serving of ML models in Kubeflow"/>




<link rel="preload" href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" as="style">
<link href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-GK9XL47N6S"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-GK9XL47N6S', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand-md navbar-dark  td-navbar">
        <a class="navbar-brand" href="/kubeflow-docs/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 276.93 274.55"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M95.9 62.15l4.1 102.1 73.75-94.12a6.79 6.79.0 019.6-1.11l46 36.92-15-65.61z" fill="#4279f4"/><path fill="#0028aa" d="M102.55 182.98h65.42l-40.17-32.23-25.25 32.23z"/><path fill="#014bd1" d="M180.18 83.92l-44 56.14 46.88 37.61 44.47-55.76-47.35-37.99z"/><path fill="#bedcff" d="M83.56 52.3l.01-.01 38.69-48.52-62.39 30.05-15.41 67.51 39.1-49.03z"/><path fill="#6ca1ff" d="M45.32 122.05l41.44 51.96-3.95-98.98-37.49 47.02z"/><path fill="#a1c3ff" d="M202.31 28.73 142.65.0l-37.13 46.56 96.79-17.83z"/><path d="M1.6 272v-44.78h5.74v23.41l20.48-23.41h6.4l-17.39 19.7 19 25.07H29.1l-15.92-20.8-5.84 6.65V272zm40.02-9.79V240h5.43v22.39a4.67 4.67.0 002.35 4.19 11 11 0 0011 0 4.69 4.69.0 002.33-4.19V240h5.43v22.19a9.08 9.08.0 01-4.1 7.87 16.2 16.2.0 01-18.37.0 9.07 9.07.0 01-4.07-7.85zM77.46 272v-48h5.43v16.81a29.29 29.29.0 019.32-1.73 13.1 13.1.0 016.2 1.41 10.71 10.71.0 014.18 3.74 18.07 18.07.0 012.23 5.06 21.26 21.26.0 01.73 5.58q0 8.43-4.38 12.79T87.35 272zm5.43-4.87h4.55q6.77.0 9.72-2.95t3-9.51a14.21 14.21.0 00-2-7.52 6.55 6.55.0 00-6-3.22 24.73 24.73.0 00-9.25 1.54zm29.47-11.19q0-7.71 4.09-12.3a13.75 13.75.0 0110.8-4.59q13.35.0 13.36 18.86h-22.82a12.3 12.3.0 002.9 7.07q2.59 3.11 7.9 3.1a24.92 24.92.0 0010.55-2v5a27.74 27.74.0 01-9.86 1.87 19.83 19.83.0 01-7.7-1.37 13.31 13.31.0 01-5.28-3.76 16.21 16.21.0 01-3-5.38 20.84 20.84.0 01-.94-6.5zm5.62-2.12h17.26a14.91 14.91.0 00-2.37-7.12 6.44 6.44.0 00-5.62-2.78 8.2 8.2.0 00-6.21 2.72 12.07 12.07.0 00-3.04 7.18z" fill="#4279f4" stroke="#4279f4" stroke-miterlimit="10" stroke-width="3.2"/><path d="M147.32 244.89V240h5v-7.59a8.14 8.14.0 012.31-6.05 7.79 7.79.0 015.69-2.28h7.86V229h-5c-2.21.0-3.67.45-4.37 1.34s-1.06 2.55-1.06 5V240h8.46v4.87h-8.46V272h-5.44v-27.1zM175.26 272v-48h5.43v48zm19.15-3.95a17.86 17.86.0 1112.33 4.9 16.57 16.57.0 01-12.33-4.9zm3.84-20.65a13.16 13.16.0 000 17.2 12.07 12.07.0 0017 0 13.09 13.09.0 000-17.2 12.07 12.07.0 00-17 0zm30.2-7.4h5.75l7.3 25.32 7.43-25.32h5.36l7.34 25.34L269 240h5.74l-10.04 32h-6.12l-6.83-24.58L245 272h-6.47z" fill="#0028aa" stroke="#0028aa" stroke-miterlimit="10" stroke-width="3.2"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Kubeflow on Google Cloud Platform</span>
	</a>
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main_navbar" aria-controls="main_navbar" aria-expanded="false" aria-label="Toggle navigation">
		<span class="navbar-toggler-icon"></span>
	</button>
	<div class="collapse navbar-collapse ml-md-auto" id="main_navbar">
		<ul class="navbar-nav ml-auto pt-4 pt-md-0 my-2 my-md-1">
			
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/docs/" ><span>Docs</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/news/" ><span>News</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" target="_blank" ><i class='fa-brands fa-github pr-2'></i><span>Source</span></a>
			</li>
			
			
			<li class="nav-item dropdown mt-1 mt-lg-0 mr-2">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Releases
</a>
<div class="dropdown-menu dropdown-menu-md-right dropdown-menu-lg-left" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">latest</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">v1.6</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.5-release/docs">v1.5</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.4-release/docs">v1.4</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/main/docs">dev</a>
	
</div>

			</li>
			
			
		</ul>
	</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/kubeflow-docs/docs/external-add-ons/serving/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">Tools for Serving</h1>
<div class="lead">Serving of ML models in Kubeflow</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-b846ae272222f6de23d4042d43dfeea9">Overview</a></li>


    
  
    
    
	
<li>2: <a href="#pg-3108d9ddd997e24e5b8436c63b4914d4">Seldon Core Serving</a></li>


    
  
    
    
	
<li>3: <a href="#pg-bd9c19194ad8f66e71fc6b468874ed49">BentoML</a></li>


    
  
    
    
	
<li>4: <a href="#pg-145f96a34e4a8b370a6013fbd8a1b5e1">MLRun Serving Pipelines</a></li>


    
  
    
    
	
<li>5: <a href="#pg-d97b7cb2a1b9c6a681aceec8809193ff">NVIDIA Triton Inference Server</a></li>


    
  
    
    
	
<li>6: <a href="#pg-a3d0c6465054fdbbd7e6aec57771eb34">TensorFlow Serving</a></li>


    
  
    
    
	
<li>7: <a href="#pg-dec844de279b9242c3a930b5ff4eda64">TensorFlow Batch Prediction</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-b846ae272222f6de23d4042d43dfeea9">1 - Overview</h1>
    <div class="lead">Model serving overview</div>
	<p>Kubeflow supports two model serving systems that allow multi-framework model
serving: <em>KFServing</em> and <em>Seldon Core</em>. Alternatively, you can use a
standalone model serving system. This page gives an overview of the options, so
that you can choose the framework that best supports your model serving
requirements.</p>
<h2 id="multi-framework-serving-with-kfserving-or-seldon-core">Multi-framework serving with KFServing or Seldon Core</h2>
<p>KFServing and Seldon Core are both open source systems that allow
multi-framework model serving. The following table compares
KFServing and Seldon Core. A check mark (<strong>âœ“</strong>) indicates that the system
(KFServing or Seldon Core) supports the feature specified in that row.</p>
<div class="table-responsive">
  <table class="table table-bordered">
    <thead class="thead-light">
      <tr>
        <th>Feature</th>
        <th>Sub-feature</th>
        <th>KFServing</th>
        <th>Seldon Core</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Framework</td>
        <td>TensorFlow</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1beta1/tensorflow">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>XGBoost</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1beta1/xgboost">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/servers/xgboost.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>scikit-learn</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1beta1/sklearn/v2">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/servers/sklearn.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>NVIDIA Triton Inference Server</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1beta1/triton">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/nvidia_mnist.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>ONNX</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1alpha2/onnx">sample</a></td>
        <td></td>
      </tr>
      <tr>
        <td></td>
        <td>PyTorch</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1beta1/torchserve">sample</a></td>
        <td><b>&check;</b></td>
      </tr>
      <tr>
        <td>Graph</td>
        <td>Transformers</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/blob/master/docs/samples/v1beta1/transformer/torchserve_image_transformer">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/transformer_spam_model.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>Combiners</td>
        <td>Roadmap</td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/openvino_ensemble.html">sample</a></td>
      </tr>
      <tr>
        <td></td>
        <td>Routers including <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">MAB</a></td>
        <td>Roadmap</td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/analytics/routers.html">docs</a></td>
      </tr>
      <tr>
        <td>Analytics</td>
        <td>Explanations</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/explanation/alibi">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/analytics/explainers.html">docs</a></td>
      </tr>
      <tr>
        <td>Scaling</td>
        <td>Knative</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/autoscaling">sample</a></td>
        <td></td>
      </tr>
      <tr>
        <td></td>
        <td>GPU AutoScaling</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/autoscaling">sample</a></td>
        <td></td>
      </tr>
      <tr>
        <td></td>
        <td>HPA</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/blob/master/test/benchmark/README.md">HPA vs KPA</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/graph/scaling.html#autoscaling-seldon-deployments">docs</a></td>
      </tr>
      <tr>
        <td>Custom</td>
        <td>Container</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1alpha2/custom">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>Language Wrappers</td>
        <td></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/python/index.html">Python</a>, <a href="https://docs.seldon.io/projects/seldon-core/en/latest/java/README.html">Java</a>, <a href="https://docs.seldon.io/projects/seldon-core/en/latest/R/README.html">R</a></td>
      </tr>
      <tr>
        <td></td>
        <td>Multi-Container</td>
        <td></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/graph/inference-graph.html">docs</a></td>
      </tr>
      <tr>
        <td>Rollout</td>
        <td>Canary</td>
        <td><b>&check;</b> <a href="https://github.com/kubeflow/kfserving/tree/master/docs/samples/v1beta1/rollout">sample</a></td>
        <td><b>&check;</b> <a href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/istio_canary.html">docs</a></td>
      </tr>
      <tr>
        <td></td>
        <td>Shadow</td>
        <td></td>
        <td><b>&check;</b></td>
      </tr>
      <tr>
        <td>Istio</td>
        <td></td>
        <td><b>&check;</b></td>
        <td><b>&check;</b></td>
      </tr>
    </tbody>
  </table>
</div>
<p>Notes:</p>
<ul>
<li>KFServing and Seldon Core share some technical features, including
explainability (using <a href="https://github.com/SeldonIO/alibi">Seldon Alibi
Explain</a>) and payload logging, as well
as other areas.</li>
<li>A commercial product,
<a href="https://www.seldon.io/tech/products/deploy/">Seldon Deploy</a>, supports both
KFServing and Seldon in production.</li>
<li>KFServing is part of the Kubeflow project ecosystem. Seldon Core is an
external project supported within Kubeflow.</li>
</ul>
<p>Further information:</p>
<ul>
<li>KFServing:
<ul>
<li><a href="/docs/components/kfserving/">Kubeflow documentation</a></li>
<li><a href="https://github.com/kubeflow/kfserving">GitHub repository</a></li>
<li><a href="/docs/about/community/">Kubeflow Community</a></li>
</ul>
</li>
<li>Seldon Core
<ul>
<li><a href="/docs/external-add-ons/serving/seldon/">Kubeflow documentation</a></li>
<li><a href="https://docs.seldon.io/projects/seldon-core/en/latest/">Seldon Core documentation</a></li>
<li><a href="https://github.com/SeldonIO/seldon-core">GitHub repository</a></li>
<li><a href="https://docs.seldon.io/projects/seldon-core/en/latest/developer/community.html">Community</a></li>
</ul>
</li>
</ul>
<h2 id="tensorflow-serving">TensorFlow Serving</h2>
<p>For TensorFlow models you can use TensorFlow Serving for
<a href="/docs/external-add-ons/serving/tfserving_new">real-time prediction</a>.
However, if you plan to use multiple frameworks, you should consider KFServing
or Seldon Core as described above.</p>
<h2 id="nvidia-triton-inference-server">NVIDIA Triton Inference Server</h2>
<p>NVIDIA Triton Inference Server is a REST and GRPC service for deep-learning
inferencing of TensorRT, TensorFlow, Pytorch, ONNX and Caffe2 models. The server is
optimized to deploy machine learning algorithms on both GPUs and
CPUs at scale. Triton Inference Server was previously known as TensorRT Inference Server.</p>
<p>You can use NVIDIA Triton Inference Server as a
<a href="/docs/external-add-ons/serving/tritoninferenceserver">standalone system</a>,
but you should consider KFServing as described above. KFServing includes support
for NVIDIA Triton Inference Server.</p>
<h2 id="bentoml">BentoML</h2>
<p><a href="https://bentoml.org">BentoML</a> is an open-source platform for high-performance ML model
serving. It makes building production API endpoint for your ML model easy and supports
all major machine learning training frameworks, including Tensorflow, Keras, PyTorch,
XGBoost, scikit-learn and etc.</p>
<p>BentoML comes with a high-performance API model server with adaptive micro-batching
support, which achieves the advantage of batch processing in online serving. It also
provides model management and model deployment functionality, giving ML teams an
end-to-end model serving workflow, with DevOps best practices baked in.</p>
<ul>
<li><a href="/docs/external-add-ons/serving/bentoml">BentoML guide for Kubeflow</a></li>
<li><a href="https://github.com/bentoml/BentoML">BentoML GitHub repository</a></li>
<li><a href="https://docs.bentoml.org">BentoML documentation</a></li>
<li><a href="https://docs.bentoml.org/en/latest/quickstart.html">Quick start guide</a></li>
<li><a href="https://join.slack.com/t/bentoml/shared_invite/enQtNjcyMTY3MjE4NTgzLTU3ZDc1MWM5MzQxMWQxMzJiNTc1MTJmMzYzMTYwMjQ0OGEwNDFmZDkzYWQxNzgxYWNhNjAxZjk4MzI4OGY1Yjg">Community</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-3108d9ddd997e24e5b8436c63b4914d4">2 - Seldon Core Serving</h1>
    <div class="lead">Model serving using Seldon</div>
	<div class="alert alert-primary" role="alert">
This Kubeflow component has <b>stable</b> status. See the
<a href="/docs/started/support/#application-status">Kubeflow versioning policies</a>.
</div>
<p>Seldon Core comes installed with Kubeflow. The <a href="https://docs.seldon.io/projects/seldon-core/en/latest/">Seldon Core documentation site</a> provides full documentation for running Seldon Core inference.</p>
<p>Seldon presently requires a Kubernetes cluster version &gt;= 1.12 and &lt;= 1.17.</p>
<p>If you have a saved model in a PersistentVolume (PV), Google Cloud Storage bucket or Amazon S3 Storage you can use one of the <a href="https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html">prepackaged model servers provided by Seldon Core</a>.</p>
<p>Seldon Core also provides <a href="https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html">language specific model wrappers</a> to wrap your inference code for it to run in Seldon Core.</p>
<h2 id="kubeflow-specifics">Kubeflow specifics</h2>
<ul>
<li>A namespace label set as <code>serving.kubeflow.org/inferenceservice=enabled</code></li>
</ul>
<p>The following example applies the label <code>seldon</code> to the namespace for serving:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">kubectl create namespace seldon
</span></span><span class="line"><span class="cl">kubectl label namespace seldon serving.kubeflow.org/inferenceservice=enabled
</span></span></code></pre></div><h3 id="istio-gateway">Istio Gateway</h3>
<p>By default Seldon will use the <code>kubeflow-gateway</code> in the kubeflow namespace. If you wish to change to a separate Gateway you would need to update the Kubeflow Seldon kustomize by changing the environment variable ISTIO_GATEWAY in the seldon-manager Deployment.</p>
<h4 id="kubeflow-100-101-102">Kubeflow 1.0.0, 1.0.1, 1.0.2</h4>
<p>For the above versions you would need to create an Istio Gateway in the namespace you want to run inference called kubeflow-gateway. For example, for a namespace <code>seldon</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">cat &lt;&lt;EOF | kubectl create -n seldon -f -
</span></span><span class="line"><span class="cl">apiVersion: networking.istio.io/v1alpha3
</span></span><span class="line"><span class="cl">kind: Gateway
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: kubeflow-gateway
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  selector:
</span></span><span class="line"><span class="cl">    istio: ingressgateway
</span></span><span class="line"><span class="cl">  servers:
</span></span><span class="line"><span class="cl">  - hosts:
</span></span><span class="line"><span class="cl">    - &#39;*&#39;
</span></span><span class="line"><span class="cl">    port:
</span></span><span class="line"><span class="cl">      name: http
</span></span><span class="line"><span class="cl">      number: 80
</span></span><span class="line"><span class="cl">      protocol: HTTP
</span></span><span class="line"><span class="cl">EOF
</span></span></code></pre></div><h2 id="simple-example">Simple example</h2>
<p>Create a new namespace:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">kubectl create ns seldon
</span></span></code></pre></div><p>Label that namespace so you can run inference tasks in it:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">kubectl label namespace seldon serving.kubeflow.org/inferenceservice=enabled
</span></span></code></pre></div><p>For Kubeflow version 1.0.0, 1.0.1 and 1.0.2 create an Istio Gateway as shown above.</p>
<p>Create an example <code>SeldonDeployment</code> with a dummy model:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">cat &lt;&lt;EOF | kubectl create -n seldon -f -
</span></span><span class="line"><span class="cl">apiVersion: machinelearning.seldon.io/v1
</span></span><span class="line"><span class="cl">kind: SeldonDeployment
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: seldon-model
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  name: test-deployment
</span></span><span class="line"><span class="cl">  predictors:
</span></span><span class="line"><span class="cl">  - componentSpecs:
</span></span><span class="line"><span class="cl">    - spec:
</span></span><span class="line"><span class="cl">        containers:
</span></span><span class="line"><span class="cl">        - image: seldonio/mock_classifier_rest:1.3
</span></span><span class="line"><span class="cl">          name: classifier
</span></span><span class="line"><span class="cl">    graph:
</span></span><span class="line"><span class="cl">      children: []
</span></span><span class="line"><span class="cl">      endpoint:
</span></span><span class="line"><span class="cl">        type: REST
</span></span><span class="line"><span class="cl">      name: classifier
</span></span><span class="line"><span class="cl">      type: MODEL
</span></span><span class="line"><span class="cl">    name: example
</span></span><span class="line"><span class="cl">    replicas: 1
</span></span><span class="line"><span class="cl">EOF
</span></span></code></pre></div><p>Wait for state to become available:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">kubectl get sdep seldon-model -n seldon -o jsonpath=&#39;{.status.state}\n&#39;
</span></span></code></pre></div><p>Port forward to the Istio gateway:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath=&#39;{.items[0].metadata.name}&#39;) -n istio-system 8004:80
</span></span></code></pre></div><p>Send a prediction request:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">curl -s -d &#39;{&#34;data&#34;: {&#34;ndarray&#34;:[[1.0, 2.0, 5.0]]}}&#39;    -X POST http://localhost:8004/seldon/seldon/seldon-model/api/v1.0/predictions    -H &#34;Content-Type: application/json&#34;
</span></span></code></pre></div><p>You should see a response:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">{
</span></span><span class="line"><span class="cl">  &#34;meta&#34;: {
</span></span><span class="line"><span class="cl">    &#34;puid&#34;: &#34;i2e1i8nq3lnttadd5i14gtu11j&#34;,
</span></span><span class="line"><span class="cl">    &#34;tags&#34;: {
</span></span><span class="line"><span class="cl">    },
</span></span><span class="line"><span class="cl">    &#34;routing&#34;: {
</span></span><span class="line"><span class="cl">    },
</span></span><span class="line"><span class="cl">    &#34;requestPath&#34;: {
</span></span><span class="line"><span class="cl">      &#34;classifier&#34;: &#34;seldonio/mock_classifier_rest:1.3&#34;
</span></span><span class="line"><span class="cl">    },
</span></span><span class="line"><span class="cl">    &#34;metrics&#34;: []
</span></span><span class="line"><span class="cl">  },
</span></span><span class="line"><span class="cl">  &#34;data&#34;: {
</span></span><span class="line"><span class="cl">    &#34;names&#34;: [&#34;proba&#34;],
</span></span><span class="line"><span class="cl">    &#34;ndarray&#34;: [[0.43782349911420193]]
</span></span><span class="line"><span class="cl">  }
</span></span><span class="line"><span class="cl">}
</span></span></code></pre></div><h2 id="further-documentation">Further documentation</h2>
<ul>
<li><a href="https://docs.seldon.io/projects/seldon-core/en/latest/">Seldon Core documentation</a></li>
<li><a href="https://docs.seldon.io/projects/seldon-core/en/latest/examples/notebooks.html">Example notebooks</a></li>
<li><a href="https://github.com/SeldonIO/seldon-core">GitHub repository</a></li>
<li><a href="https://docs.seldon.io/projects/seldon-core/en/latest/developer/community.html">Community</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-bd9c19194ad8f66e71fc6b468874ed49">3 - BentoML</h1>
    <div class="lead">Model serving with BentoML</div>
	

<div class="alert alert-warning" role="alert">
<h4 class="alert-heading">Out of date</h4>

    This guide contains outdated information pertaining to Kubeflow 1.0. This guide
needs to be updated for Kubeflow 1.1.

</div>

<p>This guide demonstrates how to serve a scikit-learn based iris classifier model with
BentoML on a Kubernetes cluster. The same deployment steps are also applicable for models
trained with other machine learning frameworks, see more BentoML examples
<a href="https://docs.bentoml.org/en/latest/examples.html">here</a>.</p>
<p><a href="https://bentoml.org">BentoML</a> is an open-source platform for high-performance ML model
serving. It makes building production API endpoint for your ML model easy and supports
all major machine learning training frameworks, including Tensorflow, Keras, PyTorch,
XGBoost, scikit-learn and etc.</p>
<p>BentoML comes with a high-performance API model server with adaptive micro-batching
support, which achieves the advantage of batch processing in online serving. It also
provides model management and model deployment functionality, giving ML teams an
end-to-end model serving workflow, with DevOps best practices baked in.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Before starting this tutorial, make sure you have the following:</p>
<ul>
<li>a Kubernetes cluster and <code>kubectl</code> installed on your local machine.
<ul>
<li><code>kubectl</code> install instruction: <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></li>
</ul>
</li>
<li>Docker and Docker Hub installed and configured in your local machine.
<ul>
<li>Docker install instruction: <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a></li>
</ul>
</li>
<li>Python 3.6 or above and required PyPi packages: <code>bentoml</code>, <code>scikit-learn</code>
<ul>
<li><code>pip install bentoml scikit-learn</code></li>
</ul>
</li>
</ul>
<h2 id="build-an-iris-classifier-model-server-with-bentoml">Build an iris classifier model server with BentoML</h2>
<p>The following code defines a BentoML prediction service that requires a <code>scikit-learn</code> model, and
asks BentoML to figure out the required PyPI packages automatically. It also defines an
API, which is the entry point for accessing this prediction service. And the API is
expecting a <code>pandas.DataFrame</code> object as its input data.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># iris_classifier.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">bentoml</span> <span class="kn">import</span> <span class="n">env</span><span class="p">,</span> <span class="n">artifacts</span><span class="p">,</span> <span class="n">api</span><span class="p">,</span> <span class="n">BentoService</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">bentoml.handlers</span> <span class="kn">import</span> <span class="n">DataframeHandler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">bentoml.artifact</span> <span class="kn">import</span> <span class="n">SklearnModelArtifact</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@env</span><span class="p">(</span><span class="n">auto_pip_dependencies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nd">@artifacts</span><span class="p">([</span><span class="n">SklearnModelArtifact</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">IrisClassifier</span><span class="p">(</span><span class="n">BentoService</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@api</span><span class="p">(</span><span class="n">DataframeHandler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</span></span></code></pre></div><p>The following code trains a classifier model and serves it with the IrisClassifier
defined above:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># main.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">iris_classifier</span> <span class="kn">import</span> <span class="n">IrisClassifier</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Load training data</span>
</span></span><span class="line"><span class="cl">    <span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Model Training</span>
</span></span><span class="line"><span class="cl">    <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Create a iris classifier service instance</span>
</span></span><span class="line"><span class="cl">    <span class="n">iris_classifier_service</span> <span class="o">=</span> <span class="n">IrisClassifier</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Pack the newly trained model artifact</span>
</span></span><span class="line"><span class="cl">    <span class="n">iris_classifier_service</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Save the prediction service to disk for model serving</span>
</span></span><span class="line"><span class="cl">    <span class="n">saved_path</span> <span class="o">=</span> <span class="n">iris_classifier_service</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</span></span></code></pre></div><p>The sample code above can be found in the BentoML repository, run them directly with the
following command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">git clone git@github.com:bentoml/BentoML.git
</span></span><span class="line"><span class="cl">python ./bentoml/guides/quick-start/main.py
</span></span></code></pre></div><p>After saving the BentoService instance, you can now start a REST API server with the
model trained and test the API server locally:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="c1"># Start BentoML API server:</span>
</span></span><span class="line"><span class="cl">bentoml serve IrisClassifier:latest
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Send test request</span>
</span></span><span class="line"><span class="cl">curl -i <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --header <span class="s2">&#34;Content-Type: application/json&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --request POST <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --data <span class="s1">&#39;[[5.1, 3.5, 1.4, 0.2]]&#39;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  localhost:5000/predict
</span></span></code></pre></div><p>BentoML provides a convenient way of containerizing the model API server with Docker. To
create a docker container image for the sample model above:</p>
<ol>
<li>Find the file directory of the SavedBundle with <code>bentoml get</code> command, which is
directory structured as a docker build context.</li>
<li>Running docker build with this directory produces a docker image containing the model
API server</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">saved_path</span><span class="o">=</span><span class="k">$(</span>bentoml get IrisClassifier:latest -q <span class="p">|</span> jq -r <span class="s2">&#34;.uri.uri&#34;</span><span class="k">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Replace `{docker_username} with your Docker Hub username</span>
</span></span><span class="line"><span class="cl">docker build -t <span class="o">{</span>docker_username<span class="o">}</span>/iris-classifier <span class="nv">$saved_path</span>
</span></span><span class="line"><span class="cl">docker push <span class="o">{</span>docker_username<span class="o">}</span>/iris-classifier
</span></span></code></pre></div><h2 id="deploy-model-server-to-kubernetes">Deploy model server to Kubernetes</h2>
<p>The following is an example YAML file for specifying the resources required to run and
expose a BentoML model server in a Kubernetes cluster. Replace <code>{docker_username}</code>
with your Docker Hub username and save it to <code>iris-classifier.yaml</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">predict</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">LoadBalancer</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span>{<span class="l">docker_username}/iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></span></span></code></pre></div><p>Use <code>kubectl</code> CLI to deploy the model API server to the Kubernetes cluster</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kubectl apply -f iris-classifier.yaml
</span></span></code></pre></div><h2 id="send-prediction-request">Send prediction request</h2>
<p>Use <code>kubectl describe</code> command to get the <code>NODE_PORT</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kubectl describe svc iris-classifier --namespace kubeflow
</span></span></code></pre></div><p>And then send the request:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">curl -i <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --header <span class="s2">&#34;Content-Type: application/json&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --request POST <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --data <span class="s1">&#39;[[5.1, 3.5, 1.4, 0.2]]&#39;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  http://EXTERNAL_IP:NODE_PORT/predict
</span></span></code></pre></div><h2 id="monitor-metrics-with-prometheus">Monitor metrics with Prometheus</h2>
<h3 id="prerequisites-1">Prerequisites</h3>
<p>Before starting this section, make sure you have the following:</p>
<ul>
<li>Prometheus installed in the cluster
<ul>
<li><a href="https://prometheus.io/docs/introduction/overview/">Prometheus documentation</a></li>
<li><a href="https://github.com/helm/charts/tree/master/stable/prometheus">Installation instruction with Helm chart</a></li>
</ul>
</li>
</ul>
<p>BentoML API server provides Prometheus support out of the box. It comes with a &ldquo;/metrics&rdquo;
endpoint which includes the essential metrics for model serving and the ability to
create and customize new metrics base on needs.</p>
<p>To enable Prometheus monitoring on the deployed model API server, update the YAML file
with Prometheus related annotations. Change the deployment spec as the following, and replace
<code>{docker_username}</code> with your Docker Hub username:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">prometheus.io/scrape</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">prometheus.io/port</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span>{<span class="l">docker_username}/iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iris-classifier</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">5000</span><span class="w">
</span></span></span></code></pre></div><p>Apply the change with <code>kubectl</code> CLI.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kubectl apply -f iris-classifier.yaml
</span></span></code></pre></div><h2 id="remove-deployment">Remove deployment</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kubectl delete -f iris-classifier.yaml
</span></span></code></pre></div><h2 id="additional-resources">Additional resources</h2>
<ul>
<li><a href="https://github.com/bentoml/BentoML">GitHub repository</a></li>
<li><a href="https://docs.bentoml.org">BentoML documentation</a></li>
<li><a href="https://docs.bentoml.org/en/latest/quickstart.html">Quick start guide</a></li>
<li><a href="https://join.slack.com/t/bentoml/shared_invite/enQtNjcyMTY3MjE4NTgzLTU3ZDc1MWM5MzQxMWQxMzJiNTc1MTJmMzYzMTYwMjQ0OGEwNDFmZDkzYWQxNzgxYWNhNjAxZjk4MzI4OGY1Yjg">Community</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-145f96a34e4a8b370a6013fbd8a1b5e1">4 - MLRun Serving Pipelines</h1>
    <div class="lead">Real-time Serving Pipelines and Model Monitoring with MLRun and Nuclio</div>
	<p><a href="https://docs.mlrun.org/en/latest/serving/build-graph-model-serving.html">MLRun serving</a> graphs allow you to build, test, deploy, and monitor real-time data processing and advanced model serving pipelines with minimal effort.
MLRun Serving is built on top of the real-time serverless framework <a href="https://github.com/nuclio/nuclio">Nuclio</a>, and is API compatible with KFServing v2. MLRunâ€™s serving functions can be deployed automatically using CLI, SDK, or Kubeflow Pipelines (KFP) operations.</p>
<p>With MLRun Serving you compose a graph of steps (composed of pre-defined graph blocks or native python classes/functions).
A graph can have data processing steps, model ensembles, model servers, post-processing, etc. (<a href="https://docs.mlrun.org/en/latest/serving/graph-example.html">see example</a>).
MLRun Serving supports complex and distributed graphs (<a href="https://docs.mlrun.org/en/latest/serving/distributed-graph.html">see example</a>)
which may involve streaming, data/document/image processing, NLP, model monitoring, etc.</p>
<p>MLRun is natively integrated with Kubeflow and Kubeflow Pipelines, MLRun function objects can be deployed, tested and executed through Kubeflow (see example below).</p>
<h3 id="accelerate-performance-and-time-to-production">Accelerate performance and time to production</h3>
<p>MLRun&rsquo;s underline serverless engine (<a href="https://nuclio.io/">Nuclio</a>) uses a high-performance parallel processing engine that maximizes the utilization of CPUs and GPUs.</p>
<p>MLRun Serving provides native model monitoring, including auto drift detection and custom metric, models can be tracked via the Grafana plug-in or in MLRun UI (<a href="https://docs.mlrun.org/en/latest/model_monitoring/index.html">see details</a>).</p>
<p>The serving pipelines can be tested locally or in a notebook, and deployed into multiple managed serverless functions in a single command (<code>deploy()</code>). Such functions are fully managed, with logging, monitoring, auto-scaling, security, etc., which eliminate the deployment overhead, improve performance and scalability, and accelerate time to production.</p>
<p>MLRun serving is natively integrated with MLRun Online Feature Store, which can be used to generate and/or enrich real-time feature vectors as well as store back production features for later analysis and re-training.</p>
<p>MLRun allows developers to focus on code and deploy faster by supporting:</p>
<ul>
<li>13 protocols and invocation methods (HTTP, Cron, Kafka, Kinesis, etc&hellip;),</li>
<li>Dynamic auto-scaling for http and streaming,</li>
<li>Optimal resource management for CPUs and GPUs,</li>
<li>Full life cycle&ndash;including auto-generation of micro-services, APIs, load-balancing, logging, monitoring, and configuration management.</li>
</ul>
<h3 id="examples">Examples</h3>
<p>Loading library serving function, adding models, testing the pipeline, deploy to the cluster, and test the live endpoint:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">mlrun</span>  
</span></span><span class="line"><span class="cl"><span class="c1"># load the sklearn model serving function and add models to it  </span>
</span></span><span class="line"><span class="cl"><span class="n">fn</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">import_function</span><span class="p">(</span><span class="s1">&#39;hub://v2_model_server&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">fn</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span><span class="s2">&#34;model1&#34;</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="p">{</span><span class="n">model1</span><span class="o">-</span><span class="n">url</span><span class="p">})</span>
</span></span><span class="line"><span class="cl"><span class="n">fn</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span><span class="s2">&#34;model2&#34;</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="p">{</span><span class="n">model2</span><span class="o">-</span><span class="n">url</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># test the serving pipeline using the graph simulator</span>
</span></span><span class="line"><span class="cl"><span class="n">server</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">to_mock_server</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">server</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s2">&#34;/v2/models/model1/infer&#34;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&#34;inputs&#34;</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># deploy the function to the cluster</span>
</span></span><span class="line"><span class="cl"><span class="n">fn</span><span class="o">.</span><span class="n">deploy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># test the live model endpoint</span>
</span></span><span class="line"><span class="cl"><span class="n">fn</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s1">&#39;/v2/models/model1/infer&#39;</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;inputs&#34;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">]})</span>
</span></span></code></pre></div><p><strong>Building your own serving class:</strong></p>
<p>MLRun Model Serving classes look and behave like KFServing classes, but are faster, support advanced graphs and capabilities, and eliminate all the deployment overhead.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">cloudpickle</span> <span class="kn">import</span> <span class="n">load</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">mlrun</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ClassifierModel</span><span class="p">(</span><span class="n">mlrun</span><span class="o">.</span><span class="n">serving</span><span class="o">.</span><span class="n">V2ModelServer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;load and initialize the model and/or other elements&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">model_file</span><span class="p">,</span> <span class="n">extra_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="s1">&#39;.pkl&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">body</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Generate model predictions from sample&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">feats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">body</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">result</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span></code></pre></div><p><strong>Deploy and Test Model Serving using Kubeflow Pipelines:</strong></p>
<p>The following Kubeflow pipeline uses MLRun Serverless functions from the MLRun marketplace and
execute a simple training, serving deployment, and serving testing Kubefow pipeline.
(see the <a href="https://github.com/mlrun/demos/blob/0.6.x/scikit-learn-pipeline/sklearn-project.ipynb">full example</a>)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;Demo pipeline&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">kfpipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl">    <span class="c1"># train with hyper-paremeters </span>
</span></span><span class="line"><span class="cl">    <span class="n">train</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">import_function</span><span class="p">(</span><span class="s1">&#39;hub://sklearn_classifier&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">as_step</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="s2">&#34;train&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;sample&#34;</span>          <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;label_column&#34;</span>    <span class="p">:</span> <span class="n">LABELS</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;test_size&#34;</span>       <span class="p">:</span> <span class="mf">0.10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s1">&#39;model_pkg_class&#39;</span><span class="p">:</span> <span class="s2">&#34;sklearn.ensemble.RandomForestClassifier&#34;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;dataset&#34;</span>         <span class="p">:</span> <span class="n">DATASET</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="s1">&#39;test_set&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># deploy our model as a serverless function, we can pass a list of models to serve </span>
</span></span><span class="line"><span class="cl">    <span class="n">deploy</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">import_function</span><span class="p">(</span><span class="s1">&#39;hub://v2_model_server&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">deploy_step</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">models</span><span class="o">=</span><span class="p">[{</span><span class="s2">&#34;key&#34;</span><span class="p">:</span> <span class="s2">&#34;mymodel:v1&#34;</span><span class="p">,</span> <span class="s2">&#34;model_path&#34;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]}])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># test out new model server (via REST API calls)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tester</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">import_function</span><span class="p">(</span><span class="s1">&#39;hub://v2_model_tester&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">as_step</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;model-tester&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;addr&#39;</span><span class="p">:</span> <span class="n">deploy</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;endpoint&#39;</span><span class="p">],</span> <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="s2">&#34;mymodel:v1&#34;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;table&#39;</span><span class="p">:</span> <span class="n">train</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;test_set&#39;</span><span class="p">]})</span>
</span></span></code></pre></div><p>See the documentation links below for more advanced examples</p>
<h3 id="additional-resources">Additional Resources</h3>
<p><strong>Further Documentation for Serving</strong></p>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/serving/serving-graph.html">MLRun Serving Graphs</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/serving/serving-graph.html#overview">Overview</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/serving-graph.html#examples">Examples</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/serving-graph.html#the-graph-state-machine">The Graph State Machine</a></li>
</ul>
</li>
<li><a href="https://docs.mlrun.org/en/latest/serving/model-api.html">Model Serving API and Protocol</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/serving/model-api.html#creating-custom-model-serving-class">Creating Custom Model Serving Class</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/model-api.html#model-server-api">Model Server API</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/model-api.html#model-monitoring">Model Monitoring</a></li>
</ul>
</li>
<li><a href="https://docs.mlrun.org/en/latest/serving/graph-example.html">Advance Graph Notebook Example</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/serving/graph-example.html#define-functions-and-classes-used-in-our-graph">Define Functions and Classes (used in our graph)</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/graph-example.html#create-a-new-serving-function-and-graph">Create a New Serving Function and Graph</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/graph-example.html#test-our-function-locally">Test our functions locally</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/graph-example.html#deploy-the-graph-as-a-real-time-serverless-function">Deploy a Graph as a Real-time Serverless function</a></li>
</ul>
</li>
<li><a href="https://docs.mlrun.org/en/latest/serving/distributed-graph.html">Distributed (Multi-function) Pipeline Example</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/serving/distributed-graph.html#create-the-pipeline">Create the Pipeline</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/distributed-graph.html#test-the-pipeline-locally">Test the Pipeline locally</a></li>
<li><a href="https://docs.mlrun.org/en/latest/serving/distributed-graph.html#deploy-to-the-cluster">Deploy to the Cluster</a></li>
</ul>
</li>
</ul>
<p><strong>Further Documentation for Monitoring</strong></p>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html">Model Monitoring Overview</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#introduction">Introduction</a></li>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#architecture">Architecture</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#drift-analysis">Drift Analysis</a></li>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#common-terminology">Common Terminology</a></li>
</ul>
</li>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#model-monitoring-using-the-iguazio-platform-interface">Model Monitoring Using the Iguazio Platform Interface</a>
<ul>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#model-endpoint-summary-list">Model Endpoint Summary List</a></li>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#model-endpoint-overview">Model Endpoint Overview</a></li>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#model-drift-analysis">Model Drift Analysis</a></li>
<li><a href="https://docs.mlrun.org/en/latest/model_monitoring/model-monitoring-deployment.html#model-features-analysis">Model Features Analysis</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-d97b7cb2a1b9c6a681aceec8809193ff">5 - NVIDIA Triton Inference Server</h1>
    <div class="lead">Model serving with Triton Inference Server</div>
	

<div class="alert alert-warning" role="alert">
<h4 class="alert-heading">Out of date</h4>

    This guide contains outdated information pertaining to Kubeflow 1.0. This guide
needs to be updated for Kubeflow 1.1.

</div>

<p>Kubeflow currently doesn&rsquo;t have a specific guide for NVIDIA Triton Inference
Server. Note that Triton was previously known as the TensorRT Inference Server.
See the <a href="https://github.com/NVIDIA/triton-inference-server/tree/master/deploy/single_server">NVIDIA
documentation</a>
for instructions on running NVIDIA inference server on Kubernetes.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-a3d0c6465054fdbbd7e6aec57771eb34">6 - TensorFlow Serving</h1>
    <div class="lead">Serving TensorFlow models</div>
	

<div class="alert alert-warning" role="alert">
<h4 class="alert-heading">Out of date</h4>

    This guide contains outdated information pertaining to Kubeflow 1.0. This guide
needs to be updated for Kubeflow 1.1.

</div>

<div class="alert alert-primary" role="alert">
This Kubeflow component has <b>stable</b> status. See the
<a href="/docs/started/support/#application-status">Kubeflow versioning policies</a>.
</div>
<h2 id="serving-a-model">Serving a model</h2>
<p>To deploy a model we create following resources as illustrated below</p>
<ul>
<li>A deployment to deploy the model using TFServing</li>
<li>A K8s service to create an endpoint a service</li>
<li>An Istio virtual service to route traffic to the model and expose it through the Istio gateway</li>
<li>An Istio DestinationRule is for doing traffic splitting.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">grpc-tf-serving</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">http-tf-serving</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterIP</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">sidecar.istio.io/inject</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;true&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">args</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">port=9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">rest_api_port=8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">model_name=mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">model_base_path=YOUR_MODEL</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="l">/usr/bin/tensorflow_model_server</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">tensorflow/serving:1.11.1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">30</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">30</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">tcpSocket</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;4&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">4Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;1&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/var/config/</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">config-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">configMap</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-v1-config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">config-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">networking.istio.io/v1alpha3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">DestinationRule</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">host</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">subsets</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">networking.istio.io/v1alpha3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">VirtualService</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">gateways</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="l">kubeflow-gateway</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">hosts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="s1">&#39;*&#39;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">http</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">match</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">method</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">exact</span><span class="p">:</span><span class="w"> </span><span class="l">POST</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">uri</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">prefix</span><span class="p">:</span><span class="w"> </span><span class="l">/tfserving/models/mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">rewrite</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">uri</span><span class="p">:</span><span class="w"> </span><span class="l">/v1/models/mnist:predict</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">route</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">destination</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">host</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">port</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">number</span><span class="p">:</span><span class="w"> </span><span class="m">8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">subset</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">
</span></span></span></code></pre></div><p>Referring to the above example, you can customize your deployment by changing the following configurations in the YAML file:</p>
<ul>
<li>
<p>In the deployment resource, the <code>model_base_path</code> argument points to the model.
Change the value to your own model.</p>
</li>
<li>
<p>The example contains three configurations for Google Cloud Storage (GCS) access:
volumes (secret <code>user-gcp-sa</code>), volumeMounts, and
env (GOOGLE_APPLICATION_CREDENTIALS).
If your model is not at GCS (e.g. using S3 from AWS), See the section below on
how to setup access.</p>
</li>
<li>
<p>GPU. If you want to use GPU, add <code>nvidia.com/gpu: 1</code>
in container resources, and use a GPU image, for example:
<code>tensorflow/serving:1.11.1-gpu</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;4&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">4Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span></code></pre></div></li>
<li>
<p>The resource <code>VirtualService</code> and <code>DestinationRule</code> are for routing.
With the example above, the model is accessible at <code>HOSTNAME/tfserving/models/mnist</code>
(HOSTNAME is your Kubeflow deployment hostname). To change the path, edit the
<code>http.match.uri</code> of VirtualService.</p>
</li>
</ul>
<h3 id="pointing-to-the-model">Pointing to the model</h3>
<p>Depending where model file is located, set correct parameters</p>
<p><em>Google cloud</em></p>
<p>Change the deployment spec as follows:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">sidecar.istio.io/inject</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;true&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">args</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">port=9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">rest_api_port=8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">model_name=mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">model_base_path=gs://kubeflow-examples-data/mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="l">/usr/bin/tensorflow_model_server</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">env</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">GOOGLE_APPLICATION_CREDENTIALS</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">/secret/gcp-credentials/user-gcp-sa.json</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">tensorflow/serving:1.11.1-gpu</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">30</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">30</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">tcpSocket</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;4&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">4Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;1&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/var/config/</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">config-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/secret/gcp-credentials</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">gcp-credentials</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">configMap</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mnist-v1-config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">config-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">gcp-credentials</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">secret</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">secretName</span><span class="p">:</span><span class="w"> </span><span class="l">user-gcp-sa</span><span class="w">
</span></span></span></code></pre></div><p>The changes are:</p>
<ul>
<li>environment variable  <code>GOOGLE_APPLICATION_CREDENTIALS</code></li>
<li>volume <code>gcp-credentials</code></li>
<li>volumeMount <code>gcp-credentials</code></li>
</ul>
<p>We need a service account that can access the model.
If you are using Kubeflow&rsquo;s click-to-deploy app, there should be already a secret, <code>user-gcp-sa</code>, in the cluster.</p>
<p>The model at gs://kubeflow-examples-data/mnist is publicly accessible. However, if your environment doesn&rsquo;t
have google cloud credential setup, TF serving will not be able to read the model.
See this <a href="https://github.com/kubeflow/kubeflow/issues/621">issue</a> for example.
To setup the google cloud credential, you should either have the environment variable
<code>GOOGLE_APPLICATION_CREDENTIALS</code> pointing to the credential file, or run <code>gcloud auth login</code>.
See <a href="https://cloud.google.com/docs/authentication/">doc</a> for more detail.</p>
<p><em>S3</em></p>
<p>To use S3, first you need to create secret that will contain access credentials. Use base64 to encode your credentials and check details in the Kubernetes guide to <a href="https://kubernetes.io/docs/concepts/configuration/secret/#creating-a-secret-manually">creating a secret manually</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">apiVersion: v1
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: secretname
</span></span><span class="line"><span class="cl">data:
</span></span><span class="line"><span class="cl">  AWS_ACCESS_KEY_ID: bmljZSB0cnk6KQ==
</span></span><span class="line"><span class="cl">  AWS_SECRET_ACCESS_KEY: YnV0IHlvdSBkaWRuJ3QgZ2V0IG15IHNlY3JldCE=
</span></span><span class="line"><span class="cl">kind: Secret
</span></span></code></pre></div><p>Then use the following manifest as an example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">s3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">s3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kubeflow</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">mnist</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">sidecar.istio.io/inject</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">s3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">args</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">port=9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">rest_api_port=8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">model_name=s3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">model_base_path=s3://abc</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- --<span class="l">monitoring_config_file=/var/config/monitoring_config.txt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="l">/usr/bin/tensorflow_model_server</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">env</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">AWS_ACCESS_KEY_ID</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">valueFrom</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">secretKeyRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">              </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">AWS_ACCESS_KEY_ID</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">              </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">secretname</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">AWS_SECRET_ACCESS_KEY</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">valueFrom</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">secretKeyRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">              </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">AWS_SECRET_ACCESS_KEY</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">              </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">secretname</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">AWS_REGION</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">us-west-1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">S3_USE_HTTPS</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;true&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">S3_VERIFY_SSL</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;true&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">S3_ENDPOINT</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">s3.us-west-1.amazonaws.com</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">tensorflow/serving:1.11.1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">30</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">30</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">tcpSocket</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">s3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">9000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8500</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;4&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">4Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;1&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/var/config/</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">config-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">configMap</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">s3-config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">config-volume</span><span class="w">
</span></span></span></code></pre></div><h3 id="sending-prediction-request-directly">Sending prediction request directly</h3>
<p>If the service type is LoadBalancer, it will have its own accessible external ip.
Get the external ip by:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">kubectl get svc mnist-service
</span></span></code></pre></div><p>And then send the request</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">curl -X POST -d @input.json http://EXTERNAL_IP:8500/v1/models/mnist:predict
</span></span></code></pre></div><h3 id="sending-prediction-request-through-ingress-and-iap">Sending prediction request through ingress and IAP</h3>
<p>If the service type is ClusterIP, you can access through ingress.
It&rsquo;s protected and only one with right credentials can access the endpoint.
Below shows how to programmatically authenticate a service account to access IAP.</p>
<ol>
<li>Save the client ID that you used to
<a href="/docs/gke/deploy/">deploy Kubeflow</a> as <code>IAP_CLIENT_ID</code>.</li>
<li>Create a service account
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">gcloud iam service-accounts create --project=$PROJECT $SERVICE_ACCOUNT
</span></span></code></pre></div></li>
<li>Grant the service account access to IAP enabled resources:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">gcloud projects add-iam-policy-binding $PROJECT \
</span></span><span class="line"><span class="cl"> --role roles/iap.httpsResourceAccessor \
</span></span><span class="line"><span class="cl"> --member serviceAccount:$SERVICE_ACCOUNT
</span></span></code></pre></div></li>
<li>Download the service account key:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">gcloud iam service-accounts keys create ${KEY_FILE} \
</span></span><span class="line"><span class="cl">   --iam-account ${SERVICE_ACCOUNT}@${PROJECT}.iam.gserviceaccount.com
</span></span></code></pre></div></li>
<li>Export the environment variable <code>GOOGLE_APPLICATION_CREDENTIALS</code> to point to the key file of the service account.</li>
</ol>
<p>Finally, you can send the request with an input file with this python
<a href="https://github.com/kubeflow/kubeflow/blob/master/docs/gke/iap_request.py">script</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">python iap_request.py https://YOUR_HOST/tfserving/models/mnist IAP_CLIENT_ID --input=YOUR_INPUT_FILE
</span></span></code></pre></div><p>To send a GET request:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">python iap_request.py https://YOUR_HOST/models/MODEL_NAME/ IAP_CLIENT_ID
</span></span></code></pre></div><h2 id="telemetry-and-rolling-out-model-using-istio">Telemetry and Rolling out model using Istio</h2>
<p>Please look at the <a href="/docs/external-add-ons/istio/">Istio guide</a>.</p>
<h2 id="logs-and-metrics-with-stackdriver">Logs and metrics with Stackdriver</h2>
<p>See the guide to <a href="/docs/gke/monitoring/">logging and monitoring</a>
for instructions on getting logs and metrics using Stackdriver.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-dec844de279b9242c3a930b5ff4eda64">7 - TensorFlow Batch Prediction</h1>
    <div class="lead">See Kubeflow <a href="https://v0-6.kubeflow.org/docs/external-add-ons/serving/tfbatchpredict/">v0.6 docs</a> for batch prediction with TensorFlow models</div>
	

<div class="alert alert-warning" role="alert">
<h4 class="alert-heading">Out of date</h4>

    This guide contains outdated information pertaining to Kubeflow 1.0. This guide
needs to be updated for Kubeflow 1.1.

</div>

<div class="alert alert-warning" role="alert">
  <h4 class="alert-heading">Alpha</h4>
  This Kubeflow component has <b>alpha</b> status with limited support. See the
  <a href="/docs/started/support/#application-status">Kubeflow versioning policies</a>.
  The Kubeflow team is interested in your   
  <a href="https://github.com/kubeflow/batch-predict/issues">feedback</a></h4> 
  about the usability of the feature.
</div>
<p><a href="https://github.com/kubeflow/batch-predict">TensorFlow batch prediction</a> is not
supported in Kubeflow versions greater than v0.6. See the <a href="https://v0-6.kubeflow.org/docs/external-add-ons/serving/tfbatchpredict/">Kubeflow v0.6
documentation</a>
for earlier support for batch prediction with TensorFlow models.</p>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark pt-3 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Kubeflow mailing list" aria-label="Kubeflow mailing list">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-mailing-list" aria-label="Kubeflow mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/kubeflow" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" rel="noopener" href="https://stackoverflow.com/questions/tagged/kubeflow" aria-label="Stack Overflow">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-slack" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Kubeflow community calendar" aria-label="Kubeflow community calendar">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-community-calendars" aria-label="Kubeflow community calendar">
      <i class="fa fa-calendar"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-5 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022 Google | Documentation Distributed under CC BY 4.0</small>
        <p><small class="ml-1"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">Privacy Policy</a></small></p>
	
		<p class="mt-2"><a href="/kubeflow-docs/docs/about/">About</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="/kubeflow-docs/js/main.min.301c0110334bec1b4445867d27dc7dd69b2df859154ccf252005508bc860cc5a.js" integrity="sha256-MBwBEDNL7BtERYZ9J9x91pst&#43;FkVTM8lIAVQi8hgzFo=" crossorigin="anonymous"></script>
<script src='/kubeflow-docs/js/tabpane-persist.js'></script>

  </body>
</html>
