<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.105.0">
<link rel="canonical" type="text/html" href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v2/author-a-pipeline/">
<link rel="alternate" type="application/rss&#43;xml" href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v2/author-a-pipeline/index.xml">
<meta name="robots" content="noindex, nofollow">

<script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "WebSite",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/gkcalat.github.io\/kubeflow-docs"
      },
      "articleSection" : "docs",
      "name" : "Author a Pipeline",
      "headline" : "Author a Pipeline",
      "description" : "Concepts and objects for authoring pipelines",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "0001",
      "datePublished": "0001-01-01 00:00:00 \u002b0000 UTC",
      "dateModified" : "0001-01-01 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/gkcalat.github.io\/kubeflow-docs\/docs\/components\/pipelines\/v2\/author-a-pipeline\/",
      "wordCount" : "0",
      "keywords" : [ "Kubeflow" ]
  }
  </script>

<link rel="shortcut icon" href="/kubeflow-docs/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/kubeflow-docs/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-32x32.png" sizes="32x32">
<link rel="manifest" href="/kubeflow-docs/favicons/manifest.json">
<meta name="msapplication-config" content="/kubeflow-docs/favicons/browserconfig.xml" />
<meta name="msapplication-TileColor" content="#4279f4">
<meta name="theme-color" content="#4279f4">

<title>Author a Pipeline | Kubeflow on Google Cloud Platform</title>
<meta name="description" content="Concepts and objects for authoring pipelines">
<meta property="og:title" content="Author a Pipeline" />
<meta property="og:description" content="Concepts and objects for authoring pipelines" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v2/author-a-pipeline/" /><meta property="og:site_name" content="Kubeflow on Google Cloud Platform" />

<meta itemprop="name" content="Author a Pipeline">
<meta itemprop="description" content="Concepts and objects for authoring pipelines"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Author a Pipeline"/>
<meta name="twitter:description" content="Concepts and objects for authoring pipelines"/>




<link rel="preload" href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" as="style">
<link href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-GK9XL47N6S"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-GK9XL47N6S', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand-md navbar-dark  td-navbar">
        <a class="navbar-brand" href="/kubeflow-docs/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 276.93 274.55"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M95.9 62.15l4.1 102.1 73.75-94.12a6.79 6.79.0 019.6-1.11l46 36.92-15-65.61z" fill="#4279f4"/><path fill="#0028aa" d="M102.55 182.98h65.42l-40.17-32.23-25.25 32.23z"/><path fill="#014bd1" d="M180.18 83.92l-44 56.14 46.88 37.61 44.47-55.76-47.35-37.99z"/><path fill="#bedcff" d="M83.56 52.3l.01-.01 38.69-48.52-62.39 30.05-15.41 67.51 39.1-49.03z"/><path fill="#6ca1ff" d="M45.32 122.05l41.44 51.96-3.95-98.98-37.49 47.02z"/><path fill="#a1c3ff" d="M202.31 28.73 142.65.0l-37.13 46.56 96.79-17.83z"/><path d="M1.6 272v-44.78h5.74v23.41l20.48-23.41h6.4l-17.39 19.7 19 25.07H29.1l-15.92-20.8-5.84 6.65V272zm40.02-9.79V240h5.43v22.39a4.67 4.67.0 002.35 4.19 11 11 0 0011 0 4.69 4.69.0 002.33-4.19V240h5.43v22.19a9.08 9.08.0 01-4.1 7.87 16.2 16.2.0 01-18.37.0 9.07 9.07.0 01-4.07-7.85zM77.46 272v-48h5.43v16.81a29.29 29.29.0 019.32-1.73 13.1 13.1.0 016.2 1.41 10.71 10.71.0 014.18 3.74 18.07 18.07.0 012.23 5.06 21.26 21.26.0 01.73 5.58q0 8.43-4.38 12.79T87.35 272zm5.43-4.87h4.55q6.77.0 9.72-2.95t3-9.51a14.21 14.21.0 00-2-7.52 6.55 6.55.0 00-6-3.22 24.73 24.73.0 00-9.25 1.54zm29.47-11.19q0-7.71 4.09-12.3a13.75 13.75.0 0110.8-4.59q13.35.0 13.36 18.86h-22.82a12.3 12.3.0 002.9 7.07q2.59 3.11 7.9 3.1a24.92 24.92.0 0010.55-2v5a27.74 27.74.0 01-9.86 1.87 19.83 19.83.0 01-7.7-1.37 13.31 13.31.0 01-5.28-3.76 16.21 16.21.0 01-3-5.38 20.84 20.84.0 01-.94-6.5zm5.62-2.12h17.26a14.91 14.91.0 00-2.37-7.12 6.44 6.44.0 00-5.62-2.78 8.2 8.2.0 00-6.21 2.72 12.07 12.07.0 00-3.04 7.18z" fill="#4279f4" stroke="#4279f4" stroke-miterlimit="10" stroke-width="3.2"/><path d="M147.32 244.89V240h5v-7.59a8.14 8.14.0 012.31-6.05 7.79 7.79.0 015.69-2.28h7.86V229h-5c-2.21.0-3.67.45-4.37 1.34s-1.06 2.55-1.06 5V240h8.46v4.87h-8.46V272h-5.44v-27.1zM175.26 272v-48h5.43v48zm19.15-3.95a17.86 17.86.0 1112.33 4.9 16.57 16.57.0 01-12.33-4.9zm3.84-20.65a13.16 13.16.0 000 17.2 12.07 12.07.0 0017 0 13.09 13.09.0 000-17.2 12.07 12.07.0 00-17 0zm30.2-7.4h5.75l7.3 25.32 7.43-25.32h5.36l7.34 25.34L269 240h5.74l-10.04 32h-6.12l-6.83-24.58L245 272h-6.47z" fill="#0028aa" stroke="#0028aa" stroke-miterlimit="10" stroke-width="3.2"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Kubeflow on Google Cloud Platform</span>
	</a>
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main_navbar" aria-controls="main_navbar" aria-expanded="false" aria-label="Toggle navigation">
		<span class="navbar-toggler-icon"></span>
	</button>
	<div class="collapse navbar-collapse ml-md-auto" id="main_navbar">
		<ul class="navbar-nav ml-auto pt-4 pt-md-0 my-2 my-md-1">
			
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/docs/" ><span>Docs</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/news/" ><span>News</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" target="_blank" ><i class='fa-brands fa-github pr-2'></i><span>Source</span></a>
			</li>
			
			
			<li class="nav-item dropdown mt-1 mt-lg-0 mr-2">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Releases
</a>
<div class="dropdown-menu dropdown-menu-md-right dropdown-menu-lg-left" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">latest</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">v1.6</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.5-release/docs">v1.5</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.4-release/docs">v1.4</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/main/docs">dev</a>
	
</div>

			</li>
			
			
		</ul>
	</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/kubeflow-docs/docs/components/pipelines/v2/author-a-pipeline/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">Author a Pipeline</h1>
<div class="lead">Concepts and objects for authoring pipelines</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-8399b7eb477a6311c212af1521456bad">Components</a></li>


    
  
    
    
	
<li>2: <a href="#pg-6434584f19aa221c1b86bb04ddc1aebe">Tasks</a></li>


    
  
    
    
	
<li>3: <a href="#pg-6afd16685922f350ab1b27a4d4e79d0c">Pipelines</a></li>


    
  
    
    
	
<li>4: <a href="#pg-4cdabdf4d68974491ee69accb5f7080d">Component I/O</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-8399b7eb477a6311c212af1521456bad">1 - Components</h1>
    <div class="lead">Author KFP components</div>
	<h2 id="summary">Summary</h2>
<p>A <em>component</em> is the basic unit of execution logic in KFP. A component is a named template for how to run a container using an image, a command, and arguments. Components may also have inputs and outputs, making a component a computational template, analogous to a function.</p>
<p>Component inputs are dynamic data used in either the container commands or arguments.</p>
<p>Component outputs may be machine learning artifacts or other JSON-serializable data.</p>
<h2 id="author-a-component">Author a component</h2>
<p>At the lowest level of execution, all components define their execution logic via a container image, command, and arguments. An importer component is a special case and the only exception to this.</p>
<p>The KFP SDK exposes three ways of authoring components with these three properties.</p>
<h3 id="1-lighweight-python-function-based-components">1. Lighweight Python function-based components</h3>
<p>The most simple way to author a component is via a lightweight Python function-based component (also known as a lightweight component).</p>
<p>Lightweight components provides a fully Pythonic approach to creating a component that executes a single Python function within a container at runtime.</p>
<p>To create a lightweight component, you must:</p>
<ol>
<li>
<p>Define a standalone function.</p>
<p>A standalone Python function is a function that does not reference any symbols defined outside of its scope. This means the function must define all objects it uses within the scope of the function and must include all import statements within the function body.</p>
</li>
<li>
<p>Include type annotations for the function parameters and return values.</p>
<p>Type annotations indicate what the component inputs and outputs are and tells the KFP lightweight component executor how to serialize and deserialize the data as it is passed within a pipeline. This also (optionally) allows the KFP DSL compiler to type check your pipeline.</p>
<p>Valid parameter annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, <code>list</code>, <code>OutputPath</code>, <code>InputPath</code>, <code>Input[&lt;Artifact&gt;]</code>, and <code>Output[&lt;Artifact&gt;]</code>.</p>
<p>Valid return annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, and <code>list</code>. You may also specify multiple return values by using these annotations within a <code>typing.NamedTuple</code>.</p>
<p>For detailed discussion on type annotations and runtime behavior, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io">Data Passing</a>.</p>
</li>
<li>
<p>Decorate your function with the <code>@kfp.dsl.component</code> decorator.
This decorator transforms a Python function into a component that can be used within a pipeline.</p>
<p>For a comprehensive list of <code>@kfp.dsl.component</code> decorator arguments, see the DSL <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html">reference documentation</a>.</p>
</li>
</ol>
<p>The following is an example of a lightweight component that trains a model on an existing input <code>Dataset</code> artifact for <code>num_epochs</code> epochs, then saves the output <code>Model</code> artifact.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">base_image</span><span class="o">=</span><span class="s1">&#39;python:3.7&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensorflow==2.9.1&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># load and process the Dataset artifact</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="o">...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer1&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer2&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer2&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;layer3&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># train for num_epochs</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># save the Model artifact</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</span></span></code></pre></div><p>Notice the <code>base_image</code> argument to the <code>@kfp.dsl.component</code> decorator. Despite not having the word &ldquo;container&rdquo; in its name, lightweight components are still executed as a container at runtime. The <code>@kfp.dsl.component</code> decorator mereley provides a convient Pythonic interface to defining this container image, command, and arguments. <a href="https://hub.docker.com/_/python"><code>python:3.7</code></a> is the default image, but can be changed to any image accessible to the executing backend, as long as the image has a Python interpreter available as <code>python3</code>. Packages in <code>packages_to_install</code> will be pip installed at container runtime.</p>
<p><strong>When to use?</strong> Lightweight components should be used if your component implementation can be written as a standalone Python function and does not require an abundance of source code. This is the preferred authoring approach for quick demos and when authoring components in a noteebok.</p>
<p>For more involved components and for production usage, prefer containerized components and custom container components for their increased flexibility.</p>
<p>Note: This authoring approach replaces <code>kfp.components.create_component_from_func</code> in KFP v1.</p>
<h3 id="2-containerized-python-components">2. Containerized Python components</h3>
<p>Containerized Python components extend lightweight components by allowing users to package and build their Python function-based components into containers.</p>
<p>Unlike lightweight components, containerized Python components allow authors to use additional source code outside of the component&rsquo;s Python function definition, including source code across multiple files. This is the preferred approach for authoring Python components that require more source code than can cleanly be included in the body of a standalone function or in cases where you wish to reuse the same source code in multiple components.</p>
<p>To create a containerized component, you must:</p>
<ol>
<li>
<p>Define a component using the <code>@kfp.dsl.component</code> decorator.</p>
<p>A containerized Python component definition is very similar to a lightweight component definition, but with a few key differences:</p>
<p>a) The <code>@kfp.dsl.component</code> decorator is given a <code>target_image</code>. This is the name of containerized component image that will be created from the <code>base_image</code> in Step 2 below.</p>
<p>b) The <code>tensorflow</code> import is included outside of the <code>train_model</code> function. This is possible because the entire module will be executed at component runtime, not only the Python function as in a lightweight component.</p>
<p>c) The component uses functions defined in <code>my_helper_module</code> imported via a <a href="https://docs.python.org/3/reference/import.html#package-relative-imports">relative import</a>. This is possible because <code>my_helper_module.py</code> will be included in the container image created in Step 2 below. This is unlike a lighweight component, which only uses the source code included in the Python function definition. This helper code could have also been defined within the same module outside of the <code>train_model</code> function.</p>
<p>The following containerized component adapts the lightweight component in the previous section to a containerized component. Notice that most of the logic is extracted into helper functions in <code>my_helper_module</code>, permitting a cleaner, modular component function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># my_component.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">.my_helper_module</span> <span class="kn">import</span> <span class="n">compile_and_train</span><span class="p">,</span> <span class="n">get_model</span><span class="p">,</span> <span class="n">split_dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">base_image</span><span class="o">=</span><span class="s1">&#39;python:3.7&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">target_image</span><span class="o">=</span><span class="s1">&#39;gcr.io/my-project/my-component:v1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># load and process the Dataset artifact</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">untrained_model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># train for num_epochs</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">compile_and_train</span><span class="p">(</span><span class="n">untrained_model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># save the Model artifact</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>my_component.py</code> module, the <code>my_helper_module.py</code> module, and any other source code files you wish to include in the container image should be grouped together in a directory. When you build the component in Step 2 below, this directory will by <a href="https://docs.docker.com/engine/reference/builder/#copy">COPY</a>&rsquo;d into the image:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">src/
</span></span><span class="line"><span class="cl">├── my_component.py
</span></span><span class="line"><span class="cl">└── my_helper_module.py
</span></span><span class="line"><span class="cl">└── another_module.py
</span></span></code></pre></div></li>
<li>
<p>Build the component.</p>
<p>Once you&rsquo;ve written a component and associated source code files and put them in a standalone directory, you can use the KFP CLI to build your component. This command to do this takes the form:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp component build <span class="o">[</span>OPTIONS<span class="o">]</span> COMPONENTS_DIRECTORY <span class="o">[</span>ARGS<span class="o">]</span>...
</span></span></code></pre></div><p>When you run this command, KFP will build an image with all the source code found in <code>COMPONENTS_DIRECTORY</code>. KFP will find your component definition in <code>src/</code> and execute the component function you defined at component runtime. Include the <code>--push-image</code> flag to push your image to a remote registry from which the executing backend can pull your image at runtime. For example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">kfp component build src/ --push-image
</span></span></code></pre></div><p>For detailed information about all arguments/flags, see <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/cli.html#kfp-component-build">CLI reference documentation</a>.</p>
</li>
</ol>
<p><strong>When to use?</strong> Containerized Python components should be used any time your component is implemented as Python code, but cannot be written as a standalone Python function or you wish to organize source code outside of the component Python function definition.</p>
<h3 id="3-custom-container-components">3. Custom container components</h3>
<p>Custom container components allow you to specify a container to execute as your component. The <code>dsl.ContainerSpec</code> object allows you to specify a container via an image, command, and args.</p>
<p>To define a custom container component, you must:</p>
<ol>
<li>
<p>Write your component’s code as a Python function that returns a <code>dsl.ContainerSpec</code> object to specify the container image and the commands to be run in the container and wrap the function into a <code>@container_component</code> decorator. The function should do nothing other than returning a <code>dsl.ContainerSpec</code> object, with the following parameters:</p>
<ul>
<li><code>image</code>: The image that the container will run. You can use <code>command</code> and <code>args</code> to control the entrypoint.</li>
<li><code>command</code> (optional): The command to be executed.</li>
<li><code>args</code> (optional): The arguments of the command. It’s recommended to place the input of the components in the args section instead of the command section.</li>
</ul>
<p>The decorator will then compose a component using the <code>ContainerSpec</code>, which can be used the same as a Python component. (Learn more about <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html">ContainerSpec</a> in documentation.)</p>
</li>
<li>
<p>Specify your function&rsquo;s inputs and outputs in the function&rsquo;s signature <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io">Learn more about passing data between components</a>. Specifically for custom container components, your function&rsquo;s inputs and outputs must meet the following requirements:</p>
<ul>
<li>All your function&rsquo;s arguments must have data type annotations.</li>
<li>Different from a Python component, your return type annotation for the function
must either be <code>dsl.ContainerSpec</code> or omitted.</li>
<li>If the function accepts or returns large amounts of data or complex
data types, you must annotate that argument as an <em>artifact</em>. Note that in the function you defined, you can only access artifacts via its <code>.url</code>, <code>.path</code>, or <code>.metadata</code> attribute. Accessing any other attribute or the artifact variable by itself is not allowed.</li>
</ul>
</li>
</ol>
<p>Below is an example that authors a pipelines from two custom container components. Just as using with a Python component, you can access the outputs of a <code>container_component</code> for downstream tasks as demonstrated in the pipeline:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">container_component</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">ContainerSpec</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">Input</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">Output</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_gcs</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;sh&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;-c&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;mkdir --parents $(dirname &#34;$1&#34;) &amp;&amp; echo &#34;$0&#34; &gt; &#34;$1&#34;&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">text</span><span class="p">,</span> <span class="n">output_gcs</span><span class="o">.</span><span class="n">path</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_dataset</span><span class="p">(</span><span class="n">input_gcs</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ContainerSpec</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span> <span class="n">command</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">input_gcs</span><span class="o">.</span><span class="n">path</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">two_step_pipeline_containerized</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">create_dataset_task</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_dataset_task</span> <span class="o">=</span> <span class="n">print_dataset</span><span class="p">(</span><span class="n">input_gcs</span><span class="o">=</span><span class="n">create_dataset_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_gcs&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>In the above example, the <code>create_dataset</code> component takes in a text and output it to a path as an artifact. Then, the <code>print_dataset</code> component retrieves the artifact output by the <code>create_dataset</code> component and prints it out.</p>
<h2 id="special-case-importer-components">Special case: Importer components</h2>
<p>Unlike the previous three authoring approaches, an importer component not a general authoring style but a pre-baked component for a specific use case: loading a machine learning artifact from remote storage to machine learning metadata (MLMD).</p>
<p><strong>Before you continue:</strong> Understand how KFP <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io">Artifacts</a> work.</p>
<p>Typically, the input artifact to a task is an output from an upstream task. In this case, the artifact can be easily accessed from the upstream task using <code>my_task.outputs['artifact_name']</code>. The artifact is also registered in MLMD when it is created by the upstream task.</p>
<p>If you wish to use an existing artifact that is not generated by a task in the current pipeline <em>or</em> wish to use as an artifact an external file that was not generated by a pipeline at all, you can use an importer component to load an artifact from its URI.</p>
<p>You do not need to write an importer component; it can be imported from the <code>dsl</code> module and used directly:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">get_date_string</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">importer_task</span> <span class="o">=</span> <span class="n">dsl</span><span class="o">.</span><span class="n">importer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">artifact_uri</span><span class="o">=</span><span class="s1">&#39;gs://ml-pipeline-playground/shakespeare1.txt&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">artifact_class</span><span class="o">=</span><span class="n">dsl</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">reimport</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">task</span><span class="o">.</span><span class="n">output</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">    <span class="n">other_component</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">importer_task</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><p>In addition to the <code>artifact_uri</code>, you must provide an <code>artifact_class</code>, indicating the type of the artifact.</p>
<p>The <code>importer</code> component permits setting artifact metadata via the <code>metadata</code> argument. Metadata can be constructed with outputs from upstream tasks, as is done for the <code>'date'</code> value in the example pipeline.</p>
<p>You may also specify a boolean <code>reimport</code> argument. If <code>reimport</code> is <code>False</code>, KFP will use an existing MLMD artifact if it already exists from an earlier importer execution. If <code>reimport</code> is <code>True</code>, KFP will reimport the artifact as a new artifact, irrespective of whether it was previously imported.</p>
<h2 id="compile-save-a-component">Compile (save) a component</h2>
<p>Once you&rsquo;ve written a component, you may wish to write the component definition to YAML for future use or submission for execution. This can be done via the KFP SDK DSL compiler:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">compiler</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pipeline_func</span><span class="o">=</span><span class="n">addition_component</span><span class="p">,</span> <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;addition_component.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="load-a-component">Load a component</h2>
<p>You can load saved components via the <code>kfp.components</code> module. This is helpful for integrating existing components stored as YAML into a larger pipeline definition:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">components</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">addition_component</span> <span class="o">=</span> <span class="n">components</span><span class="o">.</span><span class="n">load_component_from_file</span><span class="p">(</span><span class="s1">&#39;addition_component.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>Once loaded, you can use the component in a pipeline just as you would a component defined in Python:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">addition_task</span> <span class="o">=</span> <span class="n">addition_component</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>components</code> module also includes <code>.load_component_from_text</code> and <code>.load_component_from_url</code> for loading YAML from different sources.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6434584f19aa221c1b86bb04ddc1aebe">2 - Tasks</h1>
    <div class="lead">Understand and use KFP tasks</div>
	<h2 id="summary">Summary</h2>
<p>A <em>task</em> is an execution of a <a href="/docs/components/pipelines/v2/author-a-pipeline/components">component</a> with a set of inputs. It can be thought of as an instantiation of a component template. A pipeline is composed of individual tasks that may or may not pass data betwen one another.</p>
<p>One component can be used to instantiate multiple tasks within a single pipeline. Tasks can also be created and executed dynamically using pipeline control flow features such as loops, conditions, and exit handlers.</p>
<p>Because tasks represent a runtime execution of a component, you may set additional runtime configuration on a task, such as environment variables, hardware resource requirements, and various other task-level configurations.</p>
<h2 id="task-dependencies">Task dependencies</h2>
<h3 id="independent-tasks">Independent tasks</h3>
<p>Tasks may or may not depend on one another. Two tasks are independent of one another if no outputs of one are inputs to the other and neither task calls <code>.after()</code> on the other. When two tasks are independent, they execute concurrently at pipeline runtime. In the following example, <code>my_task1</code> and <code>my_task2</code> have no dependency and will execute at the same time.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task1</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hello, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task2</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hi, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;universe&#39;</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="implicitly-dependent-tasks">Implicitly dependent tasks</h3>
<p>When the output of one task is the input to another, an implicit dependency is created between the two tasks. When this is the case, the upstream task will execute first so that its output can be passed to the downstream task. In the following example, the argument to the <code>prefix</code> parameter on <code>my_tasks2</code> is the output from <code>my_task1</code>. This means <code>my_task2</code> implicitly depends and will execute after <code>my_task1</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task1</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hello, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task2</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="n">my_task1</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;!&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>For more information on passing inputs and outputs between components, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io-passing-data-between-tasks/#passing-data-between-tasks">Component I/O: Passing data between tasks</a>.</p>
<h3 id="explicitly-dependent-tasks">Explicitly dependent tasks</h3>
<p>Sometimes you want to order execution of two tasks but not pass data between the tasks. When this is the case, you can call the intended second task&rsquo;s <code>.after()</code> on the intended first task create an explicit dependency. In the following example, <code>my_task2</code> explicitly depends on <code>my_task1</code>, so <code>my_task1</code> will execute before <code>my_task2</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task1</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hello, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task2</span> <span class="o">=</span> <span class="n">concat_comp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;hi, &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">&#39;universe&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">after</span><span class="p">(</span><span class="n">my_task1</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="task-level-configurations">Task-level configurations</h2>
<p>The KFP SDK exposes several platform-agnostic task-level configurations for use during authoring. Platform-agnostic configurations are those that are expected to exhibit similar execution behavior on all KFP-conformant backends, such as the open source KFP backend or the Vertex Pipelines backend. The remainder of this section refers only to platform-agnostic task-level configurations.</p>
<p>All task-level configurations are set using a method on the task. Take the following environment variable example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_env_var</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;MY_ENV_VAR&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">print_env_var</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span><span class="o">.</span><span class="n">set_env_variable</span><span class="p">(</span><span class="s1">&#39;MY_ENV_VAR&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>When executed, the <code>print_env_var</code> component should print <code>'hello'</code>.</p>
<p>Task-level configuration methods can also be chained:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">print_env_var</span><span class="p">()</span><span class="o">.</span><span class="n">set_env_variable</span><span class="p">(</span><span class="s1">&#39;MY_ENV_VAR&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_env_variable</span><span class="p">(</span><span class="s1">&#39;OTHER_VAR&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>The KFP SDK provides the following task methods for setting task-level configurations:</p>
<ul>
<li><code>.add_node_selector_constraint</code></li>
<li><code>.set_caching_options</code></li>
<li><code>.set_cpu_limit</code></li>
<li><code>.set_display_name</code></li>
<li><code>.set_env_variable</code></li>
<li><code>.set_gpu_limit</code></li>
<li><code>.set_memory_limit</code></li>
<li><code>.set_retry</code></li>
</ul>
<p>For detailed information on how to use the above methods, see the <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>kfp.dsl.PipelineTask</code> reference documentation</a>.</p>
<h3 id="caching">Caching</h3>
<p>KFP provides task-level output caching to reduce redundant computation by skipping the execution of tasks that were completed in a previous pipeline run. Caching is enabled by default, but can be disabled by calling <code>.set_caching_options(False)</code> on a task.</p>
<p>The cache key is determined by the task&rsquo;s component specification (image, command, arguments, input/output interface) and the task&rsquo;s provided inputs (the name and URI of artifacts and the name and value of parameters). Cache hit status is not determined until task runtime since input values may be unknown until pipeline runtime.</p>
<p>When a task&rsquo;s cache hits and its execution is skipped, it will be displayed on the KFP UI:</p>
<!-- TODO: add photo of cache on UI -->

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6afd16685922f350ab1b27a4d4e79d0c">3 - Pipelines</h1>
    <div class="lead">Create a pipeline</div>
	<p>A <em>pipeline</em> is a description of a multi-task workflow, including how tasks relate to each other to form an computational graph. Pipelines may have inputs which can be passed to tasks within the pipeline.</p>
<h2 id="author-a-pipeline">Author a pipeline</h2>
<p>Unlike components which have three authoring approaches, pipelines have one authoring approach: they are defined using Python pipeline functions decorated with <code>@dsl.pipeline</code>. For example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_task</span> <span class="o">=</span> <span class="n">my_component</span><span class="p">(</span><span class="n">arg1</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
</span></span></code></pre></div><p>The <code>@dsl.pipeline</code> decorator takes three optional arguments.</p>
<ul>
<li><code>name</code> is the name of your pipeline. If not provided, the name defaults to a sanitized version of the pipeline function name.</li>
<li><code>description</code> is a description of the pipeline.</li>
<li><code>pipeline_root</code> is the remote storage root path from which your pipeline will write and read artifacts (e.g., <code>gs://my/path</code>).</li>
</ul>
<p>A pipeline function is a function that may have inputs, instantiates components as tasks and uses them to form a computational graph, and only uses the KFP domain-specific language objects and syntax within the function scope. Let&rsquo;s walk through each of these parts one-by-one.</p>
<p>First, like a component, a pipeline function may have inputs and outputs. This allows your pipeline to serve as a computational template that can be executed with different input parameters to create a specified set of outputs. See <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io/#pipeline-io">Component I/O: Pipeline I/O</a> for how to use type annotations in a pipeline.</p>
<p>Second, a pipeline function instantiates components as tasks and uses them to form a computational graph. For information on how to instatiate components as tasks and pass data between them, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io#passing-data-between-tasks">Component I/O: Passing data between tasks</a>. For information on task dependencies, see <a href="/docs/components/pipelines/v2/author-a-pipeline/tasks">Tasks</a>.</p>
<p>Third, a pipeline function only uses domain-specific language (DSL) objects and syntax within the function scope. Because the body of a Python pipeline function must ultimately be compiled to IR YAML, pipeline functions only support a very narrow set of Python language features, as specified by the KFP DSL. In addition to instantiation and data passing between tasks, the only three other features permitted are <code>dsl.Condition</code>, <code>dsl.ParallelFor</code> and <code>dsl.ExitHandler</code>. Use of these three features is covered in the next section. Use of classes, list comprehensions, lambda functions, and other arbitrary Python language features are not permitted within the scope of a Python pipeline function.</p>
<h2 id="dsl-control-flow-features">DSL control flow features</h2>
<p>A critical difference between components and pipelines is how control flow is authored and executed. Within a Python component, control flow is authored using arbitrary Python language features and the raw Python code is executed at component runtime. Within the scope of a pipeline, control flow acts on tasks, is authored using DSL features, and is executed by the KFP backend through the creation of Kubernetes Pods to execute those tasks.  <code>dsl.Condition</code>, <code>dsl.ParallelFor</code> and <code>dsl.ExitHandler</code> can be used to orchestrate the completion of tasks within a pipeline function body. Each is implemented as a Python context manager.</p>
<h3 id="dslcondition">dsl.Condition</h3>
<p>The <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>dsl.Condition</code></a> context manager allows conditional execution of tasks within its scope based on the output of an upstream task. The context manager takes two arguments: a required <code>condition</code> and an optional <code>name</code>. The <code>condition</code> is a comparative expression where at least one of the two operands is an output from an upstream task.</p>
<p>In the following pipeline, <code>conditional_task</code> only executes if <code>coin_flip_task</code> has the output <code>'heads'</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">coin_flip_task</span> <span class="o">=</span> <span class="n">flip_coin</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">Condition</span><span class="p">(</span><span class="n">coin_flip_task</span><span class="o">.</span><span class="n">output</span> <span class="o">==</span> <span class="s1">&#39;heads&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">conditional_task</span> <span class="o">=</span> <span class="n">my_comp</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="dslparallelfor">dsl.ParallelFor</h3>
<p>The <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>dsl.ParallelFor</code></a> context manager allows parallelized execution of tasks over a static set of items. The context manager takes two arguments: a required <code>items</code>, an optional <code>parallelism</code>, and an optional <code>name</code>. <code>items</code> is the static set of items to loop over, while <code>parallelism</code> is the maximum number of concurrent iterations permitted while executing the <code>dsl.ParallelFor</code> group. <code>parallelism=0</code> indicates unconstrained parallelism.</p>
<p>In the following pipeline, <code>train_model</code> will train a model for 1, 5, 10, and 25 epochs, with no more than two training tasks running at one time:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ParallelFor</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">items</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">parallelism</span><span class="o">=</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="k">as</span> <span class="n">epochs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_model</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="dslexithandler">dsl.ExitHandler</h3>
<p>The <a href="https://kubeflow-pipelines.readthedocs.io/en/master/source/dsl.html"><code>dsl.ExitHandler</code></a> context manager allows pipeline authors to specify an &ldquo;exit handler&rdquo; task which will run after the tasks within its scope finish execution or one of them fails. This is analogous to using <code>try:</code> followed by <code>finally:</code> in normal Python. The context manager takes two arguments: a required <code>exit_task</code> and an optional <code>name</code>. The <code>exit_task</code> is the &ldquo;exit handler&rdquo; task and must be instantiated before the <code>dsl.ExitHandler</code> context manager is entered.</p>
<p>In the following pipeline, <code>clean_up_task</code> will execute after either both <code>create_dataset</code> and <code>train_and_save_models</code> finish or one of them fails:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">clean_up_task</span> <span class="o">=</span> <span class="n">clean_up_resources</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ExitHandler</span><span class="p">(</span><span class="n">exit_task</span><span class="o">=</span><span class="n">clean_up_task</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset_task</span> <span class="o">=</span> <span class="n">create_datasets</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_task</span> <span class="o">=</span> <span class="n">train_and_save_models</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset_task</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><p>The task you use as an exit task may use a special backend-provided input that provides access to pipeline and task status metadata, including pipeline failure or success status. You can use this special input by annotating your exit task with the <code>dsl.PipelineTaskFinalStatus</code> annotation. You should not provide any input to this annotation when you instantiate your exit task.</p>
<p>The following pipeline uses <code>PipelineTaskFinalStatus</code> to obtain information about the pipeline and task failure, even after <code>fail_op</code> fails:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">PipelineTaskFinalStatus</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">exit_op</span><span class="p">(</span><span class="n">user_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">status</span><span class="p">:</span> <span class="n">PipelineTaskFinalStatus</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Prints pipeline run status.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">user_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pipeline status: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Job resource name: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">pipeline_job_resource_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pipeline task name: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">pipeline_task_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error code: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">error_code</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error message: &#39;</span><span class="p">,</span> <span class="n">status</span><span class="o">.</span><span class="n">error_message</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fail_op</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">sys</span>
</span></span><span class="line"><span class="cl">    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_op</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_status_task</span> <span class="o">=</span> <span class="n">exit_op</span><span class="p">(</span><span class="n">user_input</span><span class="o">=</span><span class="s1">&#39;Task execution status:&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ExitHandler</span><span class="p">(</span><span class="n">exit_task</span><span class="o">=</span><span class="n">print_status_task</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">fail_op</span><span class="p">()</span>
</span></span></code></pre></div><!-- TODO: make this reference more precise throughout -->

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-4cdabdf4d68974491ee69accb5f7080d">4 - Component I/O</h1>
    <div class="lead">Use parameter/artifact inputs and outputs</div>
	<p>Components may accept inputs and create outputs. Inputs and outputs can be one of two types: parameters or artifacts. The following matrix describes possible component inputs and outputs:</p>
<table>
<thead>
<tr>
<th></th>
<th>Parameter</th>
<th>Artifact</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input</td>
<td>Input Parameter</td>
<td>Input Artifact</td>
</tr>
<tr>
<td>Output</td>
<td>Output Parameter</td>
<td>Output Artifact</td>
</tr>
</tbody>
</table>
<p>Throughout the remainder of this section, we will use the following example dataset creation pipeline to understand the behavior and usage of input and output parameters and artifacts:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Output</span><span class="p">,</span> <span class="n">Dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">initial_text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">output_dataset</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Create a dataset containing the string `initial_text`.&#34;&#34;&#34;</span> 
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sh&#39;</span><span class="p">,</span> <span class="s1">&#39;-c&#39;</span><span class="p">,</span> <span class="s1">&#39;mkdir --parents $(dirname &#34;$1&#34;) &amp;&amp; echo &#34;$0&#34; &gt; &#34;$1&#34;&#39;</span><span class="p">,],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">initial_text</span><span class="p">,</span> <span class="n">output_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">augment_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">existing_dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">resulting_dataset</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Append `text` `num` times to an existing dataset, then write it as a new dataset.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">additional_data</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">existing_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">existing_dataset_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">resulting_dataset_text</span> <span class="o">=</span> <span class="n">existing_dataset_text</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">additional_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">resulting_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">resulting_dataset_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">resulting_dataset_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">initial_text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;initial dataset text&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">create_task</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">initial_text</span><span class="o">=</span><span class="n">initial_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">augment_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">existing_dataset</span><span class="o">=</span><span class="n">create_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_dataset&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">text</span><span class="o">=</span><span class="s1">&#39;additional text&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>This pipeline uses a <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container component</a> <code>create_dataset</code> to construct an initial <code>Dataset</code> artifact containing <code>initial_text</code>. Then, the downstream <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#1-lighweight-python-function-based-components">lightweight Python component</a> <code>augment_dataset</code> appends <code>text</code> repeated <code>num</code> times to the dataset and saves it as a new dataset.</p>
<h2 id="inputs">Inputs</h2>
<p>Component inputs are specified by the component function&rsquo;s signature. This applies for all authoring approaches: <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#1-lighweight-python-function-based-components">lightweight Python components</a>, <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#2-containerized-python-components">containerized Python components</a>, and <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container components</a>.</p>
<p>Ultimately, each authoring style creates a component definitied by an <code>image</code>, <code>command</code>, and <code>args</code>. When you use an input, it is represented as a placeholder in the <code>command</code> or <code>args</code> and is interpolated at component runtime.</p>
<p>There is one additional type of input, the struct <code>PipelineTaskFinalStatus</code>, which allows access to the metadata of one task from within another via a system-provided value at runtime. This input is a special case, as it is neither a typical parameter nor an artifact and it is only usable in <code>dsl.ExitHandler</code> exit tasks. Use of this input is covered in <a href="/docs/components/pipelines/v2/author-a-pipeline/pipelines">Authoring: Pipelines</a>.</p>
<h3 id="input-parameters">Input parameters</h3>
<p>Input parameters are declared when you use a <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code> or <code>list</code> type annotation. The data passed to parameters typed with <code>dict</code> or <code>list</code> may only container JSON-serializable Python primitives. <code>Union</code> types are not permitted.</p>
<p>In the example <code>create_dataset</code> component, <code>initial_text</code> is an input parameter. In <code>augment_dataset</code>, <code>text</code> and <code>num</code> are input parameters.</p>
<p>Input parameters may have default values. For example, <code>augment_dataset</code>&rsquo;s <code>num</code> parameter has a default value of <code>10</code>.</p>
<p>Within a component function body, use input parameters just as you would in a normal Python function.</p>
<h3 id="input-artifacts">Input artifacts</h3>
<p>Input artifacts are defined when you use an <code>Input[&lt;ArtifactClass&gt;]</code> annotation. For more information about artifacts, see <a href="/docs/components/pipelines/v2/author-a-pipeline/component-io/">Component I/O</a>.</p>
<p>At component runtime, input artifacts are copied to the local filesystem by the executing backend. This abstracts away the need for the component author to know where artifacts are stored in remote storage and allows component authors to only interact with the local filesystem when implementing a component that uses an artifact. All artifacts implement a <code>.path</code> method, which can be used to access the local path where the artifact file has been copied.</p>
<p>Let&rsquo;s see how this works in practice. In our example pipeline, <code>augment_dataset</code> specifies the input <code>existing_dataset: Input[Dataset]</code>. In the pipeline definition, we pass the output dataset from <code>create_dataset</code> to this parameter. When the <code>augument_dataset</code> component runs, the executing backend copies the <code>output_dataset</code> artifact file to the container filesystem and passes in an instance of <code>Dataset</code> as an argument to <code>existing_dataset</code>. The <code>Dataset</code> instance has a <code>.path</code> handle to its location in the container filesystem, allowing the component to read it:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">existing_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">existing_dataset_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span></code></pre></div><h2 id="outputs">Outputs</h2>
<p>Like inputs, component outputs are also specified by the component function&rsquo;s signature. Depending on the component authoring approach and the type of output (parameter or artifact), outputs may be specified by the function return type annotation (e.g., <code>-&gt; int</code>), the type annotation generic <code>Output[]</code>, or the type annotation class <code>OutputPath</code>. Uses for each are explained in the sections to follow.</p>
<p>For all output types and authoring styles, outputs from a component are persisted to a remote file store, such as <a href="https://min.io/">Minio</a>, <a href="https://cloud.google.com/storage">Google Cloud Storage</a>, or <a href="https://aws.amazon.com/s3/">AWS S3</a>, that way they outlast the ephemeral container that creates them and can be picked up for use by a downstream task.</p>
<h3 id="output-parameters">Output parameters</h3>
<p>Output parameters are declared in different ways depending on the authoring approach.</p>
<h4 id="python-components">Python components</h4>
<p>For lightweight Python components and containerized Python components, output parameters are declared by the Python component function return type annotation (e.g., <code>-&gt; int</code>). Like parameter inputs, return type annotations may be <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code> or <code>list</code>.</p>
<p>In our example, <code>augment_dataset</code> has a one integer output.</p>
<p>You may also specify multiple output parameters by using these annotations within a <code>typing.NamedTuple</code> as follows:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_component</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]):</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">output</span><span class="p">(</span><span class="s1">&#39;my_dataset&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="custom-container-components">Custom container components</h4>
<p>For <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container components</a>, output parameters are declared via an <code>OutputPath</code> annotation, which is a class that takes a type as its only argument (e.g., <code>OutputPath(int)</code>). At runtime, the backend will pass a filepath string to parameters with this annotation. This string indicating where in the container filesystem the component should write this parameter output. The backend will copy the file specified by this path to remote storage after component execution.</p>
<p>While the lightweight component executor handles writing the output parameters to the correct local filepath, custom container component authors must implement this in the container logic.</p>
<p>For example, the following very simple <code>create_text_output_parameter</code> component creates the output parameter string <code>&quot;some text&quot;</code> by using an <code>OutputPath(str)</code> annotation and writing the parameter to the path in the variable <code>output_string_path</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">OutputPath</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_text_output_parameter</span><span class="p">(</span><span class="n">output_string_path</span><span class="p">:</span> <span class="n">OutputPath</span><span class="p">(</span><span class="nb">str</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;sh&#39;</span><span class="p">,</span> <span class="s1">&#39;-c&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;mkdir --parents $(dirname &#34;$0&#34;) &amp;&amp; echo &#34;some text&#34; &gt; &#34;$0&#34;&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">output_string</span><span class="p">])</span>
</span></span></code></pre></div><h3 id="output-artifacts">Output artifacts</h3>
<p>Output artifacts are declared when you use an <code>Output[&lt;ArtifactClass&gt;]</code> annotation. For more information about artifacts, see [Artifacts][artifacts].</p>
<p>Output artifacts are treated inversely to input artifacts at component runtime: instead of being <em>copied to the container</em> from remote storage, they are <em>copied to remote storage</em> from the <code>.path</code> location in the container&rsquo;s filesystem after the component executes. This abstracts away the need for the component author to know where artifacts are stored in remote storage and allows component authors to only interact with the local filesystem when implementing a component that creates an artifact. As with using an artifact input, component authors should write artifacts to <code>.path</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">resulting_dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">resulting_dataset_text</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="pipeline-io">Pipeline I/O</h2>
<p>A pipeline may be used like a component by instantiating it as a task within another pipeline.</p>
<h3 id="inputs-1">Inputs</h3>
<p>All pipeline inputs must include type annotations. Valid input parameter annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, <code>list</code>. Input parameters may also have defaults. The only valid input artifact annotation is <code>Input[&lt;Artifact&gt;]</code> (where <code>&lt;Artifact&gt;</code> is any KFP-compatible artifact class). Input artifacts may not have defaults.</p>
<p>The following simple pipeline has a <code>str</code> parameter <code>text</code> and an <code>int</code> parameter <code>number</code>. <code>number</code> has a default value of <code>10</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">number</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span></code></pre></div><p>Ultimately, all inputs must be passed to an inner &ldquo;primitive&rdquo; component in order to perform computation on the input. See <a href="#from-a-pipeline-input">Passing data between tasks: From a pipeline input</a> for information about how to pass data from a pipeline input to a component within the pipeline.</p>
<h3 id="outputs-1">Outputs</h3>
<p>Pipelines may also have output parameters. All outputs are specified by a normal Python function return type annotation indicated by the <code>-&gt;</code> token (e.g., <code>-&gt; int</code>). Valid parameter type annotations include <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, and <code>list</code>. Valid artifact type return annotations include <code>&lt;Artifact&gt;</code> (where <code>&lt;Artifact&gt;</code> is a KFP-compatible artifact class). You may specify multiple outputs using a <code>typing.NamedTuple</code> return annotation (see <a href="#python-components">Python Components</a>) for more information on how to use named tuple return types.</p>
<p>Ultimately, all outputs must be created by an inner &ldquo;primitive&rdquo; component. Pipelines may return this output as its output.</p>
<p>For example, the following <code>double</code> pipeline returns the single <code>int</code> output of the <code>multiply</code> component:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">double</span><span class="p">(</span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">multiply</span><span class="p">(</span><span class="n">num1</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">num2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">output</span>
</span></span></code></pre></div><p>In the following different example, the <code>training_workflow</code> pipeline returns a <code>Model</code> from the inner <code>train_model</code> component:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Output</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># do training</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span> <span class="o">=</span> <span class="o">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">trained_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">training_workflow</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">get_dataset_op</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_model_op</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">get_dataset_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;dataset&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">train_model_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span>
</span></span></code></pre></div><h2 id="passing-data-between-tasks">Passing data between tasks</h2>
<p>To instantiate a component as a task, you must pass to it any required inputs. Required inputs include all input parameters without default values and all input artifacts.</p>
<p>Output parameters (e.g., <code>OutputPath</code>) and output artifacts (e.g., <code>Output[&lt;ArtifactClass&gt;]</code>) should not be passed explicitly by the pipeline author; they will be passed at component runtime by the executing backend. This allows component internals to know where output parameters and artifacts should be written in the container filesystem in order to be copied to remote storage by the backend.</p>
<p>Task inputs may come from one of three different places: a static variable, a pipeline parameter, or an upstream task output. Let&rsquo;s walk through each, using the following <code>identity</code> component to help illustrate each approach:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><h3 id="from-a-static-variable">From a static variable</h3>
<p>To provide static data as an input to a component, simply pass it as you would when using a normal function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><p>Note: Input artifacts cannot be passed as static variables; they must always be passed from an upstream task or an <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#special-case-importer-components"><code>importer</code> component</a>.</p>
<h3 id="from-a-pipeline-input">From a pipeline input</h3>
<p>To pass data from a pipeline input to an inner task, simply pass the variable name as you normally would when calling one function within another:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline_var_x</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">pipeline_var_x</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="from-a-task-output">From a task output</h3>
<p>Tasks provide references to their outputs in order to support passing data between tasks in a pipeline.</p>
<p>In nearly all cases, outputs are accessed via <code>.outputs['&lt;parameter&gt;']</code>, where <code>'&lt;parameter&gt;'</code> is the parameter name or named tuple field name from the task that produced the output which you wish to access. The <code>.outputs['&lt;parameter&gt;']</code> access pattern is used to access <code>Output[]</code> artifacts, <code>OutputPath</code> output parameters, and <code>NamedTuple</code> output parameters.</p>
<p>The only exception to this access pattern is when you wish to access a single return value from a lightweight Python component, which can be accessed through the task&rsquo;s <code>.output</code> attribute.</p>
<p>The following two subsections demonstrate this for parameters then artifacts.</p>
<h4 id="passing-parameters-from-task-to-task">Passing parameters from task to task</h4>
<p>Let&rsquo;s introduce two more components for sake of demonstrating passing parameters between components:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">named_tuple</span><span class="p">(</span><span class="n">an_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Lightweight Python component with a NamedTuple output.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Outputs&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">outputs</span><span class="p">(</span><span class="s1">&#39;my_dataset&#39;</span><span class="p">,</span> <span class="n">an_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">identity_container</span><span class="p">(</span><span class="n">integer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_int</span><span class="p">:</span> <span class="n">OutputPath</span><span class="p">(</span><span class="nb">int</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Custom container component that creates an integer output parameter.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;sh&#39;</span><span class="p">,</span> <span class="s1">&#39;-c&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;mkdir --parents $(dirname &#34;$0&#34;) &amp;&amp; echo &#34;$1&#34; &gt; &#34;$0&#34;&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">output_int</span><span class="p">,</span> <span class="n">integer</span><span class="p">])</span>
</span></span></code></pre></div><p>Using the new <code>named_tuple</code> and <code>identity_container</code> components with our original <code>identity</code> component, the following pipeline shows the full range of task-to-task data passing styles:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">pipeline_parameter_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">named_tuple_task</span> <span class="o">=</span> <span class="n">named_tuple</span><span class="p">(</span><span class="n">an_id</span><span class="o">=</span><span class="n">pipeline_parameter_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># access a named tuple parameter output via .outputs[&#39;&lt;parameter&gt;&#39;]</span>
</span></span><span class="line"><span class="cl">    <span class="n">identity_container_task</span> <span class="o">=</span> <span class="n">identity_container</span><span class="p">(</span><span class="n">integer</span><span class="o">=</span><span class="n">named_tuple_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># access an OutputPath parameter output via .outputs[&#39;&lt;parameter&gt;&#39;]</span>
</span></span><span class="line"><span class="cl">    <span class="n">identity_task_1</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">identity_container_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_int&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># access a lightweight component return value via .output</span>
</span></span><span class="line"><span class="cl">    <span class="n">identity_task_2</span> <span class="o">=</span> <span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">identity_task_1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="passing-artifacts-from-task-to-task">Passing artifacts from task to task</h4>
<p>Artifacts may only be annotated via <code>Input[&lt;ArtifactClass&gt;]</code>/<code>Output[&lt;ArtifactClass&gt;]</code> annotations and may only be accessed via the <code>.outputs['&lt;parameter&gt;']</code> syntax. This makes passing them between tasks somewhat simpler than for parameters.</p>
<p>The pipeline below demonstrates passing an artifact between tasks using an artifact producer and an artifact consumer:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.dsl</span> <span class="kn">import</span> <span class="n">Artifact</span><span class="p">,</span> <span class="n">Input</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">producer</span><span class="p">(</span><span class="n">output_artifact</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Artifact</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_artifact</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;my artifact&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">consumer</span><span class="p">(</span><span class="n">input_artifact</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Artifact</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_artifact</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">producer_task</span> <span class="o">=</span> <span class="n">producer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">consumer</span><span class="p">(</span><span class="n">input_artifact</span><span class="o">=</span><span class="n">producer_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_artifact&#39;</span><span class="p">])</span>
</span></span></code></pre></div><h2 id="special-input-values">Special input values</h2>
<p>There are a few special input values that may be used to access pipeline or task metadata within a component. These values can passed to input parameters typed with <code>str</code>. For example, the following <code>print_op</code> component can obtain the pipeline job name at component runtime by using the <code>dsl.PIPELINE_JOB_NAME_PLACEHOLDER</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_op</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">dsl</span><span class="o">.</span><span class="n">PIPELINE_JOB_NAME_PLACEHOLDER</span><span class="p">)</span>
</span></span></code></pre></div><p>There several placeholders that may be used in this style, including:</p>
<ul>
<li><code>dsl.PIPELINE_JOB_NAME_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_JOB_RESOURCE_NAME_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_JOB_ID_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_TASK_NAME_PLACEHOLDER</code></li>
<li><code>dsl.PIPELINE_TASK_ID_PLACEHOLDER</code></li>
</ul>
<h2 id="placeholders">Placeholders</h2>
<p>In general, each of the three component authoring styles handle the injection of placeholders into your container <code>command</code> and <code>args</code>, allowing the component author to not have to worry about them. However, there are two types of placeholders you may wish to use directly: <code>ConcatPlaceholder</code> and <code>IfPresentPlaceholder</code>. These placeholders may only be used when authoring <a href="/docs/components/pipelines/v2/author-a-pipeline/components/#3-custom-container-components">custom container components</a> via the <code>@dsl.container_component</code> decorator.</p>
<h3 id="concatplaceholder">ConcatPlaceholder</h3>
<p>When you provide a container <code>command</code> or container <code>args</code> as a list of strings, each element in the list is concatenated using a space separator, then issued to the container. Concatenating an one input to another string without a space separator requires special handling provided by the <code>ConcatPlaceholder</code>.</p>
<p><code>ConcatPlaceholder</code> takes one argument, <code>items</code> which may be a list of any combination of static strings, parameter inputs, or other instances of <code>ConcatPlaceholder</code> or <code>IfPresentPlaceholder</code>. At runtime, these strings will be concatenated together without a separator.</p>
<p>For example, you can use <code>ConcatPlaceholder</code> to concatenate a file path prefix, suffix, and extension:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">concatenator</span><span class="p">(</span><span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">suffix</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;alpine&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;my_program.sh&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--input&#39;</span><span class="p">,</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ConcatPlaceholder</span><span class="p">([</span><span class="n">prefix</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="s1">&#39;.txt&#39;</span><span class="p">])]</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><h3 id="ifpresentplaceholder">IfPresentPlaceholder</h3>
<p><code>IfPresentPlaceholder</code> is used to conditionally provide command line arguments. The <code>IfPresentPlaceholder</code> takes three arguments: <code>input_name</code>, <code>then</code>, and optionally <code>else_</code>. This placeholder is easiest to understand through an example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">container_component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">hello_someone</span><span class="p">(</span><span class="n">optional_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">ContainerSpec</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">image</span><span class="o">=</span><span class="s1">&#39;python:3.7&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">command</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;echo&#39;</span><span class="p">,</span> <span class="s1">&#39;hello&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">dsl</span><span class="o">.</span><span class="n">IfPresentPlaceholder</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">input_name</span><span class="o">=</span><span class="s1">&#39;optional_name&#39;</span><span class="p">,</span> <span class="n">then</span><span class="o">=</span><span class="p">[</span><span class="n">optional_name</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="p">])</span>
</span></span></code></pre></div><p>If the <code>hello_someone</code> component is passed <code>'world'</code> as an argument for <code>optional_name</code>, the component will print <code>hello world</code>. If not, it will only print <code>hello</code>.</p>
<p>The third parameter <code>else_</code> can be used to provide a default value to fall back to if <code>input_name</code> is not provided.</p>
<p>Arguments to <code>then</code> and <code>else_</code> may be a list of any combination of static strings, parameter inputs, or other instances of <code>ConcatPlaceholder</code> or <code>IfPresentPlaceholder</code>.</p>
<h2 id="component-interfaces-and-type-checking">Component interfaces and type checking</h2>
<p>The KFP SDK compiler has the ability to use the type annotations you provide to type check your pipeline definition for mismatches between input and output types. The type checking logic is simple yet handy, particularly for complex pipelines. The type checking logic is:</p>
<ul>
<li>Parameter outputs may only be passed to parameter inputs. Artifact outputs may only be passed to artifact inputs.</li>
<li>A parameter output type (<code>int</code>, <code>str</code>, etc.) must match the annotation of the parameter input to which it is passed.</li>
<li>An artifact output type (<code>Dataset</code>, <code>Model</code>, etc.) must match the artifact input type to which it is passed <em>or</em> either of the two artifact annotations must use the generic KFP <code>Artifact</code> class.</li>
</ul>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark pt-3 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Kubeflow mailing list" aria-label="Kubeflow mailing list">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-mailing-list" aria-label="Kubeflow mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/kubeflow" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" rel="noopener" href="https://stackoverflow.com/questions/tagged/kubeflow" aria-label="Stack Overflow">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-slack" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Kubeflow community calendar" aria-label="Kubeflow community calendar">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-community-calendars" aria-label="Kubeflow community calendar">
      <i class="fa fa-calendar"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-5 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022 Google | Documentation Distributed under CC BY 4.0</small>
        <p><small class="ml-1"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">Privacy Policy</a></small></p>
	
		<p class="mt-2"><a href="/kubeflow-docs/docs/about/">About</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="/kubeflow-docs/js/main.min.301c0110334bec1b4445867d27dc7dd69b2df859154ccf252005508bc860cc5a.js" integrity="sha256-MBwBEDNL7BtERYZ9J9x91pst&#43;FkVTM8lIAVQi8hgzFo=" crossorigin="anonymous"></script>
<script src='/kubeflow-docs/js/tabpane-persist.js'></script>

  </body>
</html>
