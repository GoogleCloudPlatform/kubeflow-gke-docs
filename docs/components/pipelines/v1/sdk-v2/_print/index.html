<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.105.0">
<link rel="canonical" type="text/html" href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/sdk-v2/">
<link rel="alternate" type="application/rss&#43;xml" href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/sdk-v2/index.xml">
<meta name="robots" content="noindex, nofollow">

<script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "WebSite",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/gkcalat.github.io\/kubeflow-docs"
      },
      "articleSection" : "docs",
      "name" : "Pipelines SDK (v2)",
      "headline" : "Pipelines SDK (v2)",
      "description" : "Information about the Kubeflow Pipelines SDK (v2)",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "0001",
      "datePublished": "0001-01-01 00:00:00 \u002b0000 UTC",
      "dateModified" : "0001-01-01 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/gkcalat.github.io\/kubeflow-docs\/docs\/components\/pipelines\/v1\/sdk-v2\/",
      "wordCount" : "0",
      "keywords" : [ "Kubeflow" ]
  }
  </script>

<link rel="shortcut icon" href="/kubeflow-docs/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/kubeflow-docs/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/kubeflow-docs/favicons/favicon-32x32.png" sizes="32x32">
<link rel="manifest" href="/kubeflow-docs/favicons/manifest.json">
<meta name="msapplication-config" content="/kubeflow-docs/favicons/browserconfig.xml" />
<meta name="msapplication-TileColor" content="#4279f4">
<meta name="theme-color" content="#4279f4">

<title>Pipelines SDK (v2) | Kubeflow on Google Cloud Platform</title>
<meta name="description" content="Information about the Kubeflow Pipelines SDK (v2)">
<meta property="og:title" content="Pipelines SDK (v2)" />
<meta property="og:description" content="Information about the Kubeflow Pipelines SDK (v2)" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/sdk-v2/" /><meta property="og:site_name" content="Kubeflow on Google Cloud Platform" />

<meta itemprop="name" content="Pipelines SDK (v2)">
<meta itemprop="description" content="Information about the Kubeflow Pipelines SDK (v2)"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pipelines SDK (v2)"/>
<meta name="twitter:description" content="Information about the Kubeflow Pipelines SDK (v2)"/>




<link rel="preload" href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" as="style">
<link href="/kubeflow-docs/scss/main.min.5006b434b14f73c3d5537a7ba4c8ecef723ddc93f3a3c8530e19d24f75486ea9.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-GK9XL47N6S"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-GK9XL47N6S', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand-md navbar-dark  td-navbar">
        <a class="navbar-brand" href="/kubeflow-docs/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 276.93 274.55"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M95.9 62.15l4.1 102.1 73.75-94.12a6.79 6.79.0 019.6-1.11l46 36.92-15-65.61z" fill="#4279f4"/><path fill="#0028aa" d="M102.55 182.98h65.42l-40.17-32.23-25.25 32.23z"/><path fill="#014bd1" d="M180.18 83.92l-44 56.14 46.88 37.61 44.47-55.76-47.35-37.99z"/><path fill="#bedcff" d="M83.56 52.3l.01-.01 38.69-48.52-62.39 30.05-15.41 67.51 39.1-49.03z"/><path fill="#6ca1ff" d="M45.32 122.05l41.44 51.96-3.95-98.98-37.49 47.02z"/><path fill="#a1c3ff" d="M202.31 28.73 142.65.0l-37.13 46.56 96.79-17.83z"/><path d="M1.6 272v-44.78h5.74v23.41l20.48-23.41h6.4l-17.39 19.7 19 25.07H29.1l-15.92-20.8-5.84 6.65V272zm40.02-9.79V240h5.43v22.39a4.67 4.67.0 002.35 4.19 11 11 0 0011 0 4.69 4.69.0 002.33-4.19V240h5.43v22.19a9.08 9.08.0 01-4.1 7.87 16.2 16.2.0 01-18.37.0 9.07 9.07.0 01-4.07-7.85zM77.46 272v-48h5.43v16.81a29.29 29.29.0 019.32-1.73 13.1 13.1.0 016.2 1.41 10.71 10.71.0 014.18 3.74 18.07 18.07.0 012.23 5.06 21.26 21.26.0 01.73 5.58q0 8.43-4.38 12.79T87.35 272zm5.43-4.87h4.55q6.77.0 9.72-2.95t3-9.51a14.21 14.21.0 00-2-7.52 6.55 6.55.0 00-6-3.22 24.73 24.73.0 00-9.25 1.54zm29.47-11.19q0-7.71 4.09-12.3a13.75 13.75.0 0110.8-4.59q13.35.0 13.36 18.86h-22.82a12.3 12.3.0 002.9 7.07q2.59 3.11 7.9 3.1a24.92 24.92.0 0010.55-2v5a27.74 27.74.0 01-9.86 1.87 19.83 19.83.0 01-7.7-1.37 13.31 13.31.0 01-5.28-3.76 16.21 16.21.0 01-3-5.38 20.84 20.84.0 01-.94-6.5zm5.62-2.12h17.26a14.91 14.91.0 00-2.37-7.12 6.44 6.44.0 00-5.62-2.78 8.2 8.2.0 00-6.21 2.72 12.07 12.07.0 00-3.04 7.18z" fill="#4279f4" stroke="#4279f4" stroke-miterlimit="10" stroke-width="3.2"/><path d="M147.32 244.89V240h5v-7.59a8.14 8.14.0 012.31-6.05 7.79 7.79.0 015.69-2.28h7.86V229h-5c-2.21.0-3.67.45-4.37 1.34s-1.06 2.55-1.06 5V240h8.46v4.87h-8.46V272h-5.44v-27.1zM175.26 272v-48h5.43v48zm19.15-3.95a17.86 17.86.0 1112.33 4.9 16.57 16.57.0 01-12.33-4.9zm3.84-20.65a13.16 13.16.0 000 17.2 12.07 12.07.0 0017 0 13.09 13.09.0 000-17.2 12.07 12.07.0 00-17 0zm30.2-7.4h5.75l7.3 25.32 7.43-25.32h5.36l7.34 25.34L269 240h5.74l-10.04 32h-6.12l-6.83-24.58L245 272h-6.47z" fill="#0028aa" stroke="#0028aa" stroke-miterlimit="10" stroke-width="3.2"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Kubeflow on Google Cloud Platform</span>
	</a>
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main_navbar" aria-controls="main_navbar" aria-expanded="false" aria-label="Toggle navigation">
		<span class="navbar-toggler-icon"></span>
	</button>
	<div class="collapse navbar-collapse ml-md-auto" id="main_navbar">
		<ul class="navbar-nav ml-auto pt-4 pt-md-0 my-2 my-md-1">
			
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/docs/" ><span>Docs</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="/kubeflow-docs/news/" ><span>News</span></a>
			</li>
			
			<li class="nav-item mr-2 mr-lg-4 mt-1 mt-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" target="_blank" ><i class='fa-brands fa-github pr-2'></i><span>Source</span></a>
			</li>
			
			
			<li class="nav-item dropdown mt-1 mt-lg-0 mr-2">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Releases
</a>
<div class="dropdown-menu dropdown-menu-md-right dropdown-menu-lg-left" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">latest</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.6-release/docs">v1.6</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.5-release/docs">v1.5</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/v1.4-release/docs">v1.4</a>
	
	<a class="dropdown-item" href="https://gkcalat.github.io/kubeflow-docs/main/docs">dev</a>
	
</div>

			</li>
			
			
		</ul>
	</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/kubeflow-docs/docs/components/pipelines/v1/sdk-v2/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">Pipelines SDK (v2)</h1>
<div class="lead">Information about the Kubeflow Pipelines SDK (v2)</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-7de693453582d12951b61f9fd9caa3ab">Introducing Kubeflow Pipelines SDK v2</a></li>


    
  
    
    
	
<li>2: <a href="#pg-71afab4db485174bd352d12f64e8e088">Comparing Pipeline Runs</a></li>


    
  
    
    
	
<li>3: <a href="#pg-f31ed082c64d3490d1377466dfdc3520">Kubeflow Pipelines v2 Component I/O</a></li>


    
  
    
    
	
<li>4: <a href="#pg-3dcf3dde7fbe3043d83871453e9b58d7">Build a Pipeline</a></li>


    
  
    
    
	
<li>5: <a href="#pg-9184b16f91df608e5869bd5db102ef95">Building Components</a></li>


    
  
    
    
	
<li>6: <a href="#pg-1b784a63be21dc3d677420b83ac1439e">Building Python Function-based Components</a></li>


    
  
    
    
	
<li>7: <a href="#pg-469c8de604213a6de88b276eeb473f1b">Importer component</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-7de693453582d12951b61f9fd9caa3ab">1 - Introducing Kubeflow Pipelines SDK v2</h1>
    <div class="lead">Overview of how to get started with Kubeflow Pipelines SDK v2</div>
	<div class="alert alert-warning" role="alert">
  <h4 class="alert-heading">Beta</h4>
  This Kubeflow component has <b>beta</b> status. See the
  <a href="/docs/started/support/#application-status">Kubeflow versioning policies</a>.
  The Kubeflow team is interested in your   
  <a href="https://github.com/kubeflow/pipelines/issues">feedback</a></h4> 
  about the usability of the feature.
</div>
<p>The Kubeflow Pipelines SDK provides a set of Python packages that you can use to specify and run your machine learning (ML) workflow as a pipeline. Version 2 of the SDK adds support for tracking pipeline runs and artifacts using ML Metadata. Starting with Kubeflow Pipelines 1.6, you can build and run pipelines in v2 compatibility mode.</p>
<p>Kubeflow Pipelines SDK v2 compatibility mode lets you use the new pipeline semantics and gain the benefits of logging your metadata to ML Metadata. You can use ML Metadata to help answer questions about the lineage of your pipeline’s artifacts.</p>
<p>To learn more about the work towards Kubeflow Pipelines v2, read the design documents for <a href="http://bit.ly/kfp-v2">Kubeflow Pipelines v2</a> and <a href="http://bit.ly/kfp-v2-compatible">Kubeflow Pipelines v2 compatible
mode</a>, or join the Kubeflow Pipelines community.</p>
<h2 id="before-you-begin">Before you begin</h2>
<ol>
<li>
<p>Install <a href="/docs/components/pipelines/installation/standalone-deployment">Kubeflow Pipelines Standalone</a> 1.7.0 or higher. Note, support for other distributions is under development, see <a href="#current-caveats">Current Caveats section</a>.</p>
</li>
<li>
<p>Run the following command to install Kubeflow Pipelines SDK v1.7.2 or higher. If you run this command in a Jupyter notebook, restart the kernel after installing the SDK.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">pip install kfp --upgrade
</span></span></code></pre></div></li>
<li>
<p>Import the kfp and kfp.components packages.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp</span>
</span></span></code></pre></div></li>
<li>
<p>Create an instance of the kfp.Client class. To find your Kubeflow Pipelines cluster’s hostname and URL scheme, open the Kubeflow Pipelines user interface in your browser. The URL of the Kubeflow Pipelines user interface is something like <a href="https://my-cluster.my-organization.com/pipelines">https://my-cluster.my-organization.com/pipelines</a>. In this case, the host name and URL scheme are <a href="https://my-cluster.my-organization.com">https://my-cluster.my-organization.com</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># If you run this command on a Jupyter notebook running on Kubeflow, you can</span>
</span></span><span class="line"><span class="cl"><span class="c1"># exclude the host parameter.</span>
</span></span><span class="line"><span class="cl"><span class="c1"># client = kfp.Client()</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;&lt;your-kubeflow-pipelines-host-name&gt;&#39;</span><span class="p">)</span>
</span></span></code></pre></div></li>
</ol>
<h2 id="building-pipelines-using-the-kubeflow-pipelines-sdk-v2">Building pipelines using the Kubeflow Pipelines SDK v2</h2>
<p>If you are new to building pipelines, read the following guides to learn more about
using Kubeflow Pipelines SDK v2 to build pipelines and components.</p>
<ul>
<li><a href="/docs/components/pipelines/sdk-v2/build-pipeline/">Get started building pipelines using Pipelines SDK v2</a>.</li>
<li><a href="/docs/components/pipelines/sdk-v2/component-development/">Learn how to build pipeline components using Pipelines SDK v2</a>.</li>
<li><a href="/docs/components/pipelines/sdk-v2/python-function-components/">Build lightweight Python function-based components using Pipelines SDK
v2</a>.</li>
</ul>
<p>If you are familiar with building Kubeflow pipelines, the Kubeflow Pipelines SDK v2
introduces the following changes:</p>
<ul>
<li>
<p>The following changes affect how you build components:</p>
<ul>
<li>
<p>All component inputs and outputs must be annotated with their data type.</p>
</li>
<li>
<p>The Kubeflow Pipelines SDK v2 makes a distinction between inputs and outputs that
are <em>parameters</em> and those that are <em>artifacts</em>.</p>
<ul>
<li>
<p>Parameters are inputs or outputs of type <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, or <code>list</code>
that typically are used to change the behavior of a pipeline. Input parameters
are always passed by value, which means that they are inserted into the
command used to execute the component. Parameters are stored in ML Metadata.</p>
</li>
<li>
<p><a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py">Artifacts</a>
are larger inputs or outputs, such as datasets or models. Input
artifacts are always passed as a reference to a path.</p>
<p>You can also access an artifact&rsquo;s metadata. For input artifacts, you can
read the artifact&rsquo;s metadata. For output artifacts, you can write key/value
pairs to the metadata dictionary.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>The following changes affect how you define a pipeline:</p>
<ul>
<li>
<p>Pipeline functions must be decorated with
<a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/_pipeline.py"><code>@kfp.dsl.pipeline</code></a>. Specify the following arguments for the
<code>@pipeline</code> annotation.</p>
<ul>
<li>
<p><code>name</code>: The pipeline name is used when querying MLMD to store or lookup
component parameters and artifacts. Reusing pipeline names may result in unexpected behaviors. You can override this name when you run the pipeline.</p>
</li>
<li>
<p><code>description</code>: (Optional.) A user friendly description of this pipeline.</p>
</li>
<li>
<p><code>pipeline_root</code>: (Optional.) The root path where this pipeline&rsquo;s outputs
are stored. This can be a MinIO, Google Cloud Storage, or Amazon Web Services
S3 URI. You can override the pipeline root when you run the pipeline.</p>
<p>If you do not specify the <code>pipeline_root</code>, Kubeflow Pipelines stores your
artifacts using MinIO.</p>
</li>
</ul>
</li>
<li>
<p>The Kubeflow Pipelines SDK v2 compiler checks that data types are used correctly in pipelines,
and that parameters outputs are not passed to artifact inputs and vice versa</p>
<p>You might need to modify existing pipelines to run them in v2 compatibility mode.</p>
</li>
<li>
<p>It is not longer supported to pass constants to artifact inputs.</p>
</li>
<li>
<p>All pipeline parameters must be annotated with their data type.</p>
</li>
</ul>
</li>
</ul>
<h2 id="compiling-and-running-pipelines-in-v2-compatibility-mode">Compiling and running pipelines in v2 compatibility mode</h2>
<p>First we define a v2 compatible pipeline:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp.dsl</span> <span class="k">as</span> <span class="nn">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2.dsl</span> <span class="kn">import</span> <span class="n">component</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;Calculates sum of two arguments&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;addition-pipeline&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">description</span><span class="o">=</span><span class="s1">&#39;An example pipeline that performs addition calculations.&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># pipeline_root=&#39;gs://my-pipeline-root/example-pipeline&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">add_pipeline</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">7</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">add_task</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span></code></pre></div><p>To compile your pipeline in v2 compatibility mode, specify that
<code>mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE</code> when you initiate the compiler:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp</span> <span class="kn">import</span> <span class="n">compiler</span>
</span></span><span class="line"><span class="cl"><span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pipeline_func</span><span class="o">=</span><span class="n">add_pipeline</span><span class="p">,</span> <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;pipeline.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>To run your pipeline in v2 compatibility mode:</p>
<ol>
<li>Create an instance of the <a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client"><code>kfp.Client</code> class</a> following steps in <a href="/docs/components/pipelines/sdk/connect-api/">connecting to Kubeflow Pipelines using the SDK client</a>.</li>
<li>Specify that <code>mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE</code> when you create a pipeline
run using <code>create_run_from_pipeline_func</code>.</li>
</ol>
<p>The following example demonstrates how to run a pipeline using v2 compatibility mode.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># run the pipeline in v2 compatibility mode</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">arguments</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h2 id="current-caveats">Current Caveats</h2>
<p>Kubeflow Pipelines v2 compatible mode is currently in Beta stage. It is under active development and some features may not be complete. To find out its current caveats, refer to <a href="https://github.com/kubeflow/pipelines/issues/6133">v2 compatible mode &ndash; known caveats &amp; breaking changes #6133</a>.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-71afab4db485174bd352d12f64e8e088">2 - Comparing Pipeline Runs</h1>
    <div class="lead">Using the KFPv2 Run Comparison page to compare parameters and metrics across pipeline runs</div>
	<h2 id="prerequisites">Prerequisites</h2>
<p>To compare pipeline runs, you need to first have at least two pipeline runs of the same version!
You can run your first pipeline by following the
<a href="/docs/components/pipelines/overview/quickstart">pipelines quickstart guide</a>.</p>
<p>This page will show the v2 UI, which allows you to compare the following visualization types:</p>
<ul>
<li>Scalar Metrics</li>
<li>Confusion Matrices</li>
<li>ROC Curves</li>
<li>HTML</li>
<li>Markdown</li>
</ul>
<h2 id="basic-layout">Basic Layout</h2>
<p>The KFPv2 Run Comparison page has three major sections:</p>
<ul>
<li>Run overview</li>
<li>Parameters</li>
<li>Metrics</li>
</ul>
<p><strong>KFPv2 Run Comparison Full Page</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/full-page.png" 
alt="KFPv2 Run Comparison Full Page"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<p>The Run overview section allows the user to view and select specific runs. Any changes to these
selections will automatically update the Parameters and Metrics sections accordingly. The &ldquo;Refresh&rdquo;
button at the top-right of the page will re-fetch the runs, and display any new run status or artifact
information on the page. In order to best use this page, we recommend that run names are
reasonably differentiated, preferably at the start of the run name.</p>
<p>The Parameters section consists of a table that shows the run parameters for each run, even if a run
has no parameters. These parameters are only shown if they are explicitely included in the pipeline
run (default parameters are not present). The new KFPv2 update allows different parameter types
(Double, Integer, String, Boolean, List, and Struct), and the format of the display allows users to
differentiate these data types.</p>
<p><strong>Run Parameters Compare Table</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/run-parameters.png" 
alt="Run Parameters Compare Table"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<p>The Metrics section has five different tabs, one for each visualization type. The below sections
will review each of these tabs.</p>
<h2 id="scalar-metrics">Scalar Metrics</h2>
<p>The Scalar Metrics tab compares scalar metrics across runs in table form. The top row of this table
groups the executions and artifacts into their runs. The second row shows each artifact via the
format <code>&lt;execution-name&gt;-&lt;artifact-name&gt;</code>, which allows each artifact to be uniquely differentiated.
If a run is not present, then that means it did not have any scalar metrics artifacts. The data is
then presented in the rows below.</p>
<p><em>Note:</em> In the case that an execution or artifact name cannot be found, it will display its
corresponding ID as a placeholder.</p>
<p><strong>Scalar Metrics Compare Table</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/scalar-metrics.png" 
alt="Scalar Metrics Compare Table"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<h2 id="confusion-matrix-html-and-markdown">Confusion Matrix, HTML, and Markdown</h2>
<p>The display for comparing Confusion Matrices, HTML, and Markdown all use a two-panel layout
to compare the data side-by-side. A specific artifact can be selected via the two-level dropdown;
the first level shows the list of runs with the specified artifact, and the second level shows
the list of selectable artifacts with the naming schema <code>&lt;execution-name&gt;-&lt;artifact-name&gt;</code>.
This dropdown is visible on the HTML tab below.</p>
<p><strong>Confusion Matrix Comparison</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/confusion-matrix.png" 
alt="Confusion Matrix Comparison"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<p><strong>HTML Comparison</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/html.png" 
alt="HTML Comparison"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<p><strong>Markdown Comparison</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/markdown.png" 
alt="Markdown Comparison"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<h2 id="roc-curve">ROC Curve</h2>
<p>The ROC Curve tab consists of two major components: an ROC Curve plot which displays all of the
selected artifacts, and the filter table which allows users to search for and select artifacts.
The plot limits selection up to 10 curves, after which you must de-select artifacts in order to
select more.</p>
<p>The user can hover over any &ldquo;Series&rdquo; item in the plot legend in order to highlight the curve; since
many curves may be identical, this will also bring the selected curve to the forefront. De-selecting
and re-selecting an artifact on the filter table will also bring that curve to the top of the plot.</p>
<p><strong>ROC Curve Plot</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/roc-curve-plot.png" 
alt="ROC Curve Plot"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<p>The ROC Curve filter table allows you to filter and select artifacts. The user can search by run
name or the combination of <code>[execution-name] &gt; [artifact-name]</code> (which is shown on the first column).
When you select a artifact, the table will assign it a color which you can then use to identify the
Series # and the line on the plot. If you select 10 artifacts while there are more artifacts
available, a warning will pop up indicating that you have reached the maximum number of selected
artifacts, and the remaining artifact checkbox selections will be disabled; this prevents the table
from becoming too cluttered.</p>
<p><strong>ROC Curve Filter Table</strong></p>
<p><img src="/docs/images/pipelines/v2/run-comparison/roc-curve-filter-table.png" 
alt="ROC Curve Filter Table"
class="mt-3 mb-3 p-3 border border-info rounded"></p>
<h2 id="conclusion">Conclusion</h2>
<p>The KFPv2 Run Comparison page allows users to perform faster analysis when comparing their runs
by comparing different visualization types across pipeline run artifacts.</p>
<h2 id="next-steps">Next Steps</h2>
<ul>
<li>Follow the full guide to experimenting with
<a href="/docs/components/pipelines/tutorials/build-pipeline/">the Kubeflow Pipelines samples</a>.</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-f31ed082c64d3490d1377466dfdc3520">3 - Kubeflow Pipelines v2 Component I/O</h1>
    <div class="lead">Differences between artifacts and parameters, and how to migrate an existing pipeline to be v2 compatible.</div>
	<div class="alert alert-warning" role="alert">
  <h4 class="alert-heading">Beta</h4>
  This Kubeflow component has <b>beta</b> status. See the
  <a href="/docs/started/support/#application-status">Kubeflow versioning policies</a>.
  The Kubeflow team is interested in your   
  <a href="https://github.com/kubeflow/pipelines/issues">feedback</a></h4> 
  about the usability of the feature.
</div>
<h2 id="artifacts-and-parameters">Artifacts and Parameters</h2>
<p>The Kubeflow Pipelines SDK v2 makes a distinction between inputs and outputs that are <em>parameters</em> and those that are <em>artifacts</em>.</p>
<ul>
<li>
<p>Parameters represent values.
They are inputs or outputs of type <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, or <code>list</code> that typically are used to change the behavior of a pipeline.
Parameters are stored in ML Metadata, thus you can query ML Metadata for the values of parameters.
Input parameters are always passed by value, which means that they are inserted into the command used to execute the component.</p>
</li>
<li>
<p>Artifacts represent references to objects&ndash;most commonly files&ndash;that are produced during pipeline executions.
Examples of artifacts include <code>Model</code>, <code>Datasets</code>, <code>Metrics</code>, and so on.
Regardless of the types of artifacts, all artifacts have a <code>name</code>, a <code>uri</code>, and optionally some <code>metadata</code>.
Most commonly, the <code>uri</code> of an artifact is a cloud storage URI such as a Google Cloud Storage URI, or an Amazon Web Services S3 URI.
The <code>name</code>, <code>uri</code>, and <code>metadata</code> of artifacts are stored in ML Metadata, but not the contents referenced by the <code>uri</code>.
Input artifacts are always passed by reference, i.e. the <code>uri</code> of an artifact or a JSON object containing the <code>name</code>, <code>uri</code>, and <code>metadata</code> of an artifact.</p>
</li>
</ul>
<p>Whether an input/output is a parameter or an artifact is decided by its type annotation. Inputs/outputs typed as <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>dict</code>, or <code>list</code> are parameters, while everything else are artifacts. Kubeflow Pipelines SDK v2 defines a list of system artifact types including <code>Model</code>, <code>Dataset</code>, <code>Metrics</code>, <code>ClassificationMetrics</code>, <code>SlicedClassificationMetrics</code>, <code>HTML</code>, <code>Markdown</code>, and the generic <code>Artifact</code>. All unknown types including non-type are treated the same as the generic <code>Artifact</code> type.</p>
<p>Artifacts and parameters cannot be passed to each other. By default, when compiling a pipeline with option <code>type_check=True</code>, only inputs and outputs with the exact same type can be connected together with the exception that the generic <code>Artifact</code> type is compatible with any artifact types.</p>
<h2 id="migrating-from-v1-components">Migrating from v1 components</h2>
<h3 id="review-and-update-inputsoutputs-types">Review and update inputs/outputs types.</h3>
<p>In Kubeflow Pipelines SDK v1, type annotations for inputs/outputs are optional, and when there is no type annotation on an input/output, it is treated as compatible with any type, hence the input/output can be connected to any outputs/inputs regardless of their types. This is no longer the case in v2.
As mentioned above, type annotation in v2 is the sole decision factor on whether an input/output is an artifact or a parameter. Component authors should first decide the category for each input/output, and then explicitly type annotate them accordingly.</p>
<h3 id="review-and-update-inputsoutputs-placeholders-if-applicable">Review and update inputs/outputs placeholders if applicable.</h3>
<p>For components defined via YAML, inputs/outputs are referenced by placeholders in the container command line arguments.</p>
<p>In Kubeflow Pipelines SDK v1, there are three types of input/output placeholders:</p>
<ul>
<li>
<p><code>{inputValue: &lt;input-name&gt;}</code>:
This placeholder is replaced with the value of the specified input.
This is useful for small pieces of input data, such as numbers or small
strings.</p>
</li>
<li>
<p><code>{inputPath: &lt;input-name&gt;}</code>:
This placeholder is replaced with the path to this input as a file.
Your component can read the contents of that input at that path during
the pipeline run.</p>
</li>
<li>
<p><code>{outputPath: &lt;output-name&gt;}</code>:
This placeholder is replaced with the path where your program writes
this output&rsquo;s data. This lets the Kubeflow Pipelines system read the
contents of the file and store it as the value of the specified output.</p>
</li>
</ul>
<p>In Kubeflow Pipelines SDK v2, we introduced two additional input/output placeholders:</p>
<ul>
<li>
<p><code>{inputUri: &lt;input-name&gt;}</code>:
This placeholder is replaced with the URI to this input. In case the
URI is a cloud storage URI, Your component can read the contents of
that input through the corresponding cloud storage client during the
pipeline run.</p>
</li>
<li>
<p><code>{outputUri: &lt;output-name&gt;}</code>:
This placeholder is replaced with URI where your program writes this
output&rsquo;s data. This lets the Kubeflow Pipelines system read the contents
of the file and store it as the value of the specified output.</p>
</li>
</ul>
<p>For the five input/output placeholders, there are rules on which placeholders are valid for artifacts and which are valid for parameters. Specifically,</p>
<ul>
<li>
<p>Placeholders for parameters</p>
<ul>
<li>
<p>For input parameters, the valid placeholder is <code>{inputValue: &lt;input-name&gt;}</code>.</p>
</li>
<li>
<p>For output parameters, the valid placeholder is <code>{outputPath: &lt;output-name&gt;}</code>.</p>
</li>
</ul>
</li>
<li>
<p>Placeholders for artifacts</p>
<ul>
<li>
<p>For input artifacts, the valid placeholders are <code>{inputPath: &lt;input-name&gt;}</code>
and <code>{inputUri: &lt;input-name&gt;}</code>.</p>
</li>
<li>
<p>For output artifacts, the only valid placeholders are <code>{outputPath: &lt;output-name&gt;}</code>
and <code>{outputUri: &lt;output-name&gt;}</code>.</p>
</li>
</ul>
</li>
</ul>
<p>Misuse of input/output placeholders results in compilation errors. When there is a type-placeholder mismatch error, most often it is due to the input/output is mis-typed. You should review if the input/output
is meant to be a parameter or an artifact and type it accordingly. In case when the type is intended, you need to update the placeholder for the input/output. Changing input/output placeholders often requires
updating the code of the component as well. For instance, changing from <code>{inputValue: &lt;input-name&gt;}</code> to <code>{inputPath: &lt;input_name&gt;}</code> means your component code will not receive the actual value of the input but a file path where the value is in the file. In this case, a file read logic should be added to the component code.</p>
<h3 id="use-v2-component-decorator-for-python-function-based-components">Use v2 <code>@component</code> decorator for Python function-based components.</h3>
<p>For Python function-based components created via <code>create_component_from_func</code> or <code>func_to_container_op</code>, we recommend migrating to using the new <code>@component</code> decorator available from <code>kfp.v2.dsl</code> package.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2.dsl</span> <span class="kn">import</span> <span class="n">component</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Output</span><span class="p">,</span> <span class="n">OutputPath</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Use Input[T] to get a metadata-rich handle to the input artifact of type `Dataset`.</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Use Output[T] to get a metadata-rich handle to the output artifact of type `Dataset`.</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Model</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># An input parameter of type int.</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># An output parameter of type str.</span>
</span></span><span class="line"><span class="cl">    <span class="n">output_message_path</span><span class="p">:</span> <span class="n">OutputPath</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Dummy Training step.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">input_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset_contents</span> <span class="o">=</span> <span class="n">input_file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">output_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">output_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="se">\n</span><span class="s1">=====</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Model artifact has a `.metadata` dictionary</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># to store arbitrary metadata for the output artifact.</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_message_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">output_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Model trained successfully.&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>Using v2 <code>@component</code> decorator, input and output artifacts should be annotated with <code>Input[T]</code> and <code>Output[T]</code>, respectively. And <code>T</code> is the class <a href="https://github.com/kubeflow/pipelines/blob/7875b68654a69ca761cb0ba4a920a30925a0e94b/sdk/python/kfp/v2/components/types/artifact_types.py#L27"><code>Artifact</code></a> or a subclass of it. You can access the properties and methods defined for the specific artifact class, such as <code>dataset.path</code> or <code>model.metadata</code> as shown in the above example.</p>
<p>Note that <code>Input[T]</code> and <code>Output[T]</code> should not be applied on input/output parameters. Input parameters need to be type annotated using one of the parameter types mentioned earlier. Output parameters should be type annotated with <code>OutputPath(T)</code> or via the function return type, just like how it can be specified in v1 lightweight function components.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-3dcf3dde7fbe3043d83871453e9b58d7">4 - Build a Pipeline</h1>
    <div class="lead">A tutorial on using Pipelines SDK v2 to orchestrate your ML workflow as a pipeline</div>
	<!--
AUTOGENERATED FROM content/en/docs/components/pipelines/sdk-v2/build-pipeline.ipynb
PLEASE UPDATE THE JUPYTER NOTEBOOK AND REGENERATE THIS FILE USING scripts/nb_to_md.py.-->
<style>
.notebook-links {display: flex; margin: 1em 0;}
.notebook-links a {padding: .75em; margin-right: .75em; font-weight: bold;}
a.colab-link {
padding-left: 3.25em;
background-image: url(/docs/images/logos/colab.ico);
background-repeat: no-repeat;
background-size: contain;
}
a.github-link {
padding-left: 2.75em;
background-image: url(/docs/images/logos/github.png);
background-repeat: no-repeat;
background-size: auto 75%;
background-position: left center;
}
</style>
<div class="notebook-links">
<a class="colab-link" href="https://colab.research.google.com/github/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/build-pipeline.ipynb">Run in Google Colab</a>
<a class="github-link" href="https://github.com/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/build-pipeline.ipynb">View source on GitHub</a>
</div>
<p>A Kubeflow pipeline is a portable and scalable definition of a machine learning
(ML) workflow. Each step in your ML workflow, such as preparing data or
training a model, is an instance of a pipeline component. This document
provides an overview of pipeline concepts and best practices, and instructions
describing how to build an ML pipeline.</p>
<p><strong>Note:</strong> This guide demonstrates how to build pipelines using the Pipelines SDK v2.
Currently, Kubeflow Pipelines v2 is in development. You can use this guide to start
building and running pipelines that are compatible with the Pipelines SDK v2.</p>
<p><a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/v2-compatibility">Learn more about Pipelines SDK v2</a>.</p>
<h2 id="before-you-begin">Before you begin</h2>
<ol>
<li>Run the following command to install the Kubeflow Pipelines SDK v1.6.2 or higher.
If you run this command in a Jupyter notebook, restart the kernel after
installing the SDK.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">kfp</span>
</span></span></code></pre></div><ol start="2">
<li>Import the <code>kfp</code> packages.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2.dsl</span> <span class="kn">import</span> <span class="n">component</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2.dsl</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">Input</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Output</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Artifact</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h2 id="understanding-pipelines">Understanding pipelines</h2>
<p>A Kubeflow pipeline is a portable and scalable definition of an ML workflow,
based on containers. A pipeline is composed of a set of input parameters and a
list of the steps in this workflow. Each step in a pipeline is an instance of a
component, which is represented as an instance of
<a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#kfp.dsl.ContainerOp"><code>ContainerOp</code></a>.</p>
<p>You can use pipelines to:</p>
<ul>
<li>Orchestrate repeatable ML workflows.</li>
<li>Accelerate experimentation by running a workflow with different sets of
hyperparameters.</li>
</ul>
<h3 id="understanding-pipeline-components">Understanding pipeline components</h3>
<p>A pipeline component is a containerized application that performs one step in a
pipeline&rsquo;s workflow. Pipeline components are defined in
<a href="https://www.kubeflow.org/docs/components/pipelines/reference/component-spec/">component specifications</a>, which define the following:</p>
<ul>
<li>The component&rsquo;s interface, its inputs and outputs.</li>
<li>The component&rsquo;s implementation, the container image and the command to
execute.</li>
<li>The component&rsquo;s metadata, such as the name and description of the
component.</li>
</ul>
<p>You can build components by <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/component-development/">defining a component specification for a
containerized application</a>, or you can <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/python-function-components/">use the Kubeflow
Pipelines SDK to generate a component specification for a Python
function</a>. You can also <a href="https://www.kubeflow.org/docs/examples/shared-resources/">reuse prebuilt components
in your pipeline</a>.</p>
<h3 id="understanding-the-pipeline-graph">Understanding the pipeline graph</h3>
<p>Each step in your pipeline&rsquo;s workflow is an instance of a component. When
you define your pipeline, you specify the source of each step&rsquo;s inputs. Step
inputs can be set from the pipeline&rsquo;s input arguments, constants, or step
inputs can depend on the outputs of other steps in this pipeline. Kubeflow
Pipelines uses these dependencies to define your pipeline&rsquo;s workflow as
a graph.</p>
<p>For example, consider a pipeline with the following steps: ingest data,
generate statistics, preprocess data, and train a model. The following
describes the data dependencies between each step.</p>
<ul>
<li><strong>Ingest data</strong>: This step loads data from an external source which is
specified using a pipeline argument, and it outputs a dataset. Since
this step does not depend on the output of any other steps, this step
can run first.</li>
<li><strong>Generate statistics</strong>: This step uses the ingested dataset to generate
and output a set of statistics. Since this step depends on the dataset
produced by the ingest data step, it must run after the ingest data step.</li>
<li><strong>Preprocess data</strong>: This step preprocesses the ingested dataset and
transforms the data into a preprocessed dataset. Since this step depends
on the dataset produced by the ingest data step, it must run after the
ingest data step.</li>
<li><strong>Train a model</strong>: This step trains a model using the preprocessed dataset,
the generated statistics, and pipeline parameters, such as the learning
rate. Since this step depends on the preprocessed data and the generated
statistics, it must run after both the preprocess data and generate
statistics steps are complete.</li>
</ul>
<p>Since the generate statistics and preprocess data steps both depend on the
ingested data, the generate statistics and preprocess data steps can run in
parallel. All other steps are executed once their data dependencies are
available.</p>
<h2 id="designing-your-pipeline">Designing your pipeline</h2>
<p>When designing your pipeline, think about how to split your ML workflow into
pipeline components. The process of splitting an ML workflow into pipeline
components is similar to the process of splitting a monolithic script into
testable functions. The following rules can help you define the components
that you need to build your pipeline.</p>
<ul>
<li>
<p>Components should have a single responsibility. Having a single
responsibility makes it easier to test and reuse a component. For example,
if you have a component that loads data you can reuse that for similar
tasks that load data. If you have a component that loads and transforms
a dataset, the component can be less useful since you can use it only when
you need to load and transform that dataset.</p>
</li>
<li>
<p>Reuse components when possible. Kubeflow Pipelines provides <a href="https://www.kubeflow.org/docs/examples/shared-resources/">components for
common pipeline tasks and for access to cloud
services</a>.</p>
<p>Note: Not all prebuilt components are compatible with Pipelines SDK v2.
For example, you might need to update the type hints for component inputs
and outputs.</p>
</li>
<li>
<p>Consider what you need to know to debug your pipeline and research the
lineage of the models that your pipeline produces. Kubeflow Pipelines
stores the inputs and outputs of each pipeline step. By interrogating the
artifacts produced by a pipeline run, you can better understand the
variations in model quality between runs or track down bugs in your
workflow.</p>
</li>
</ul>
<p>In general, you should design your components with composability in mind.</p>
<p>Pipelines are composed of component instances, also called steps. Steps can
define their inputs as depending on the output of another step. The
dependencies between steps define the pipeline workflow graph.</p>
<h3 id="building-pipeline-components">Building pipeline components</h3>
<p>Kubeflow pipeline components are containerized applications that perform a
step in your ML workflow. Here are the ways that you can define pipeline
components:</p>
<ul>
<li>
<p>If you have a containerized application that you want to use as a
pipeline component, create a component specification to define this
container image as a pipeline component.</p>
<p>This option provides the flexibility to include code written in any
language in your pipeline, so long as you can package the application
as a container image. Learn more about <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/component-development/">building pipeline
components</a>.</p>
</li>
<li>
<p>If your component code can be expressed as a Python function, <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/python-function-components/">evaluate if
your component can be built as a Python function-based
component</a>. The Kubeflow Pipelines SDK makes it
easier to build lightweight Python function-based components by saving you
the effort of creating a component specification.</p>
</li>
</ul>
<p>Whenever possible, <a href="https://www.kubeflow.org/docs/examples/shared-resources/">reuse prebuilt components</a> to save
yourself the effort of building custom components.</p>
<p>The example in this guide demonstrates how to build a pipeline that uses a
Python function-based component and reuses a prebuilt component.</p>
<h3 id="understanding-how-data-is-passed-between-components">Understanding how data is passed between components</h3>
<p>When Kubeflow Pipelines runs a component, a container image is started in a
Kubernetes Pod and your component’s inputs are passed in as command-line
arguments. When your component has finished, the component&rsquo;s outputs are
returned as files.</p>
<p>In your component&rsquo;s specification, you define the components inputs and outputs
and how the inputs and output paths are passed to your program as command-line
arguments.</p>
<p>Component inputs and outputs are classified as either <em>parameters</em> or <em>artifacts</em>,
depending on their data type.</p>
<ul>
<li>
<p>Parameters typically represent settings that affect the behavior of your pipeline.
Parameters are passed into your component by value, and can be of any of
the following types: <code>int</code>, <code>double</code>, <code>float</code>, or <code>str</code>. Since parameters are
passed by value, the quantity of data passed in a parameter must be appropriate
to pass as a command-line argument.</p>
</li>
<li>
<p>Artifacts represent large or complex data structures like datasets or models, and
are passed into components as a reference to a file path.</p>
<p>If you have large amounts of string data to pass to your component, such as a JSON
file, annotate that input or output as a type of <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Artifact</code></a>, such
as <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Dataset</code></a>, to let Kubeflow Pipelines know to pass this to
your component as a file.</p>
<p>In addition to the artifact’s data, you can also read and write the artifact&rsquo;s
metadata. For output artifacts, you can record metadata as key-value pairs, such
as the accuracy of a trained model. For input artifacts, you can read the
artifact&rsquo;s metadata — for example, you could use metadata to decide if a
model is accurate enough to deploy for predictions.</p>
</li>
</ul>
<p>All outputs are returned as files, using the the paths that Kubeflow Pipelines
provides.</p>
<p>Python function-based components make it easier to build pipeline components
by building the component specification for you. Python function-based
components also handle the complexity of passing inputs into your component
and passing your function’s outputs back to your pipeline.</p>
<p>Learn more about how <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/python-function-components/#understanding-how-data-is-passed-between-components">Python function-based components handle inputs and
outputs</a>.</p>
<h2 id="getting-started-building-a-pipeline">Getting started building a pipeline</h2>
<p>The following sections demonstrate how to get started building a Kubeflow
pipeline by walking through the process of converting a Python script into
a pipeline.</p>
<h3 id="design-your-pipeline">Design your pipeline</h3>
<p>The following steps walk through some of the design decisions you may face
when designing a pipeline.</p>
<ol>
<li>Evaluate the process. In the following example, a Python function downloads
a zipped tar file (<code>.tar.gz</code>) that contains several CSV files, from a
public website. The function extracts the CSV files and then merges them
into a single file.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">glob</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tarfile</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">urllib.request</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">download_and_merge_csv</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_csv</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="k">as</span> <span class="n">res</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fileobj</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;r|gz&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">      <span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">       <span class="k">for</span> <span class="n">csv_file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;data/*.csv&#39;</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">  <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_csv</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span></code></pre></div><ol start="2">
<li>Run the following Python command to test the function.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">download_and_merge_csv</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">url</span><span class="o">=</span><span class="s1">&#39;https://storage.googleapis.com/ml-pipeline-playground/iris-csv-files.tar.gz&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">    <span class="n">output_csv</span><span class="o">=</span><span class="s1">&#39;merged_data.csv&#39;</span><span class="p">)</span>
</span></span></code></pre></div><ol start="3">
<li>Run the following to print the first few rows of the
merged CSV file.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="err">$</span> <span class="n">head</span> <span class="n">merged_data</span><span class="o">.</span><span class="n">csv</span>
</span></span></code></pre></div><ol start="4">
<li>
<p>Design your pipeline. For example, consider the following pipeline designs.</p>
<ul>
<li>
<p>Implement the pipeline using a single step. In this case, the pipeline
contains one component that works similarly to the example function.
This is a straightforward function, and implementing a single-step
pipeline is a reasonable approach in this case.</p>
<p>The down side of this approach is that the zipped tar file would not be
an artifact of your pipeline runs. Not having this artifact available
could make it harder to debug this component in production.</p>
</li>
<li>
<p>Implement this as a two-step pipeline. The first step downloads a file
from a website. The second step extracts the CSV files from a zipped
tar file and merges them into a single file.</p>
<p>This approach has a few benefits:</p>
<ul>
<li>You can reuse the <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/components/web/Download/component.yaml">Web Download component</a>
to implement the first step.</li>
<li>Each step has a single responsibility, which makes the components
easier to reuse.</li>
<li>The zipped tar file is an artifact of the first pipeline step.
This means that you can examine this artifact when debugging
pipelines that use this component.</li>
</ul>
</li>
</ul>
<p>This example implements a two-step pipeline.</p>
</li>
</ol>
<h3 id="build-your-pipeline-components">Build your pipeline components</h3>
<p>Build your pipeline components. This example modifies the initial script to
extract the contents of a zipped tar file, merge the CSV files that were
contained in the zipped tar file, and return the merged CSV file.</p>
<p>This example builds a Python function-based component. You can also package
your component&rsquo;s code as a Docker container image and define the component
using a ComponentSpec.</p>
<p>In this case, the following modifications were required to the original
function.</p>
<ul>
<li>
<p>The file download logic was removed. The path to the zipped tar file
is passed to this function as the <code>tar_data</code> argument.</p>
</li>
<li>
<p>The import statements were moved inside of the function. Python
function-based components require standalone Python functions. This
means that any required import statements must be defined within the
function, and any helper functions must be defined within the function.</p>
</li>
<li>
<p>The function&rsquo;s arguments are annotated as an <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>kfp.dsl.Input</code></a>
or <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>kfp.dsl.Output</code></a> artifact. These annotations let Kubeflow
Pipelines know to provide the path to the zipped tar file and to
create a path where your function stores the merged CSV file.</p>
</li>
<li>
<p>The function is decorated with the <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/_component.py"><code>kfp.dsl.component</code></a>
annotation. You can also use this annotation to define the following:</p>
<ul>
<li>The container image that your function runs in.</li>
<li>Any PyPI packages that this function depends on, that are not already
installed on the container image.</li>
<li>The location to save the component specification to. You can use the
component specification to share this component with your colleagues.</li>
</ul>
<p>This annotation converts your function into a factory function that
creates pipeline steps. These pipeline steps execute the function you
defined as a part of a pipeline&rsquo;s workflow.</p>
</li>
</ul>
<p>Learn more about <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/python-function-components/">building Python function-based components</a>.</p>
<p>The following example shows the updated <code>merge_csv</code> function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@component</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">packages_to_install</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pandas==1.1.4&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">output_component_file</span><span class="o">=</span><span class="s1">&#39;component.yaml&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">merge_csv</span><span class="p">(</span><span class="n">tar_data</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Artifact</span><span class="p">],</span> <span class="n">output_csv</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">glob</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">tarfile</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">tar_data</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;r|gz&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">      <span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">       <span class="k">for</span> <span class="n">csv_file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;data/*.csv&#39;</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">  <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_csv</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="build-your-pipeline">Build your pipeline</h3>
<ol>
<li>Use <a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html?highlight=load_component_from_url#kfp.components.load_component_from_url"><code>kfp.components.load_component_from_url</code></a>
to load the component specification YAML for any components that you are
reusing in this pipeline.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">web_downloader_op</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">load_component_from_url</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;https://raw.githubusercontent.com/kubeflow/pipelines/master/components/web/Download/component-sdk-v2.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><ol start="2">
<li>
<p>Define your pipeline as a Python function.</p>
<p>Your pipeline function&rsquo;s arguments define your pipeline&rsquo;s parameters. Use
pipeline parameters to experiment with different hyperparameters, such as
the learning rate used to train a model, or pass run-level inputs, such as
the path to an input file, into a pipeline run. The data type must be
specified for all pipeline parameters.</p>
<p>Use the factory functions created by
the <code>kfp.dsl.component</code> annotation and the
<code>kfp.components.load_component_from_url</code> function to create your pipeline&rsquo;s tasks.
The inputs to the component factory functions can be pipeline parameters,
the outputs of other tasks, or a constant value. In this case, the
<code>web_downloader_task</code> task uses the <code>url</code> pipeline parameter, and the
<code>merge_csv_task</code> uses the <code>data</code> output of the <code>web_downloader_task</code>.</p>
<p>The <code>kfp.dsl.pipeline</code> annotation lets you specify the following:</p>
<ul>
<li><code>name</code>: The pipeline&rsquo;s name.</li>
<li><code>description</code>: (Optional.) A description of the pipeline&rsquo;s workflow.</li>
<li><code>pipeline_root</code>: The default path where your pipeline&rsquo;s artifacts are
stored. This must be a path that your pipeline can read and write to,
such as a Persistent Volume Claim or a cloud service such as Google
Cloud Storage.</li>
</ul>
</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Define a pipeline and create a task from a component:</span>
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;my-pipeline&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># You can optionally specify your own pipeline_root</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># pipeline_root=&#39;gs://my-pipeline-root/example-pipeline&#39;,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">web_downloader_task</span> <span class="o">=</span> <span class="n">web_downloader_op</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">merge_csv_task</span> <span class="o">=</span> <span class="n">merge_csv</span><span class="p">(</span><span class="n">tar_data</span><span class="o">=</span><span class="n">web_downloader_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># The outputs of the merge_csv_task can be referenced using the</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># merge_csv_task.outputs dictionary: merge_csv_task.outputs[&#39;output_csv&#39;]</span>
</span></span></code></pre></div><h3 id="compile-and-run-your-pipeline">Compile and run your pipeline</h3>
<p>After defining the pipeline in Python as described in the preceding section, use one of the following options to compile the pipeline and submit it to the Kubeflow Pipelines service.</p>
<h4 id="option-1-compile-and-then-upload-in-ui">Option 1: Compile and then upload in UI</h4>
<ol>
<li>Run the following to compile your pipeline and save it as <code>pipeline.yaml</code>.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">kfp</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">Compiler</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">)</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">pipeline_func</span><span class="o">=</span><span class="n">my_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">package_path</span><span class="o">=</span><span class="s1">&#39;pipeline.yaml&#39;</span><span class="p">)</span>
</span></span></code></pre></div><ol start="2">
<li>Upload and run your <code>pipeline.yaml</code> using the Kubeflow Pipelines user interface.
See the guide to <a href="https://www.kubeflow.org/docs/components/pipelines/overview/quickstart">getting started with the UI</a>.</li>
</ol>
<h4 id="option-2-run-the-pipeline-using-kubeflow-pipelines-sdk-client">Option 2: run the pipeline using Kubeflow Pipelines SDK client</h4>
<ol>
<li>Create an instance of the <a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client"><code>kfp.Client</code> class</a> following steps in <a href="https://www.kubeflow.org/docs/components/pipelines/sdk/connect-api">connecting to Kubeflow Pipelines using the SDK client</a>.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span> <span class="c1"># change arguments accordingly</span>
</span></span></code></pre></div><ol start="2">
<li>Run the pipeline using the <code>kfp.Client</code> instance:</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">my_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># You can optionally override your pipeline_root when submitting the run too:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># pipeline_root=&#39;gs://my-pipeline-root/example-pipeline&#39;,</span>
</span></span><span class="line"><span class="cl">    <span class="n">arguments</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;url&#39;</span><span class="p">:</span> <span class="s1">&#39;https://storage.googleapis.com/ml-pipeline-playground/iris-csv-files.tar.gz&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="p">})</span>
</span></span></code></pre></div><h2 id="next-steps">Next steps</h2>
<ul>
<li>Learn about advanced pipeline features, such as <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/tutorials/DSL%20-%20Control%20structures/DSL%20-%20Control%20structures.py">using conditional execution in a
pipeline</a>.</li>
</ul>
<div class="notebook-links">
<a class="colab-link" href="https://colab.research.google.com/github/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/build-pipeline.ipynb">Run in Google Colab</a>
<a class="github-link" href="https://github.com/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/build-pipeline.ipynb">View source on GitHub</a>
</div>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-9184b16f91df608e5869bd5db102ef95">5 - Building Components</h1>
    <div class="lead">A tutorial on how to use the Pipelines SDK v2 to create components and use them in a pipeline</div>
	<p>A pipeline component is a self-contained set of code that performs one step in
your ML workflow. This document describes the concepts required to build
components, and demonstrates how to get started building components.</p>
<p><strong>Note:</strong> This guide demonstrates how to build components using the Pipelines SDK v2.
Currently, Kubeflow Pipelines v2 is in development. You can use this guide to start
building and running pipelines that are compatible with the Pipelines SDK v2.</p>
<p><a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/v2-compatibility/">Learn more about Pipelines SDK v2</a>.</p>
<h2 id="before-you-begin">Before you begin</h2>
<p>Run the following command to install the Kubeflow Pipelines SDK v1.6.1 or higher.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">pip install kfp --upgrade
</span></span></code></pre></div><p>For more information about the Kubeflow Pipelines SDK, see the <a href="https://kubeflow-pipelines.readthedocs.io/en/latest/index.html">SDK reference guide</a>.</p>
<h2 id="understanding-pipeline-components">Understanding pipeline components</h2>
<p>Pipeline components are self-contained sets of code that perform one step in
your ML workflow, such as preprocessing data or training a model. To create a
component, you must <em>build the component&rsquo;s implementation</em> and <em>define the
component specification</em>.</p>
<p>Your component&rsquo;s implementation includes the component&rsquo;s executable code and
the Docker container image that the code runs in.  <a href="#design">Learn more about designing
a pipeline component</a>.</p>
<p>Once you have built your component&rsquo;s implementation, you can define your
component&rsquo;s interface as a component specification. A component specification
defines:</p>
<ul>
<li>The component&rsquo;s inputs and outputs.</li>
<li>The container image that your component&rsquo;s code runs in, the command to use
to run your component&rsquo;s code, and the command-line arguments to pass to
your component&rsquo;s code.</li>
<li>The component&rsquo;s metadata, such as the name and description.</li>
</ul>
<p><a href="#component-spec">Learn more about creating a component specification</a>.</p>
<p>If your component&rsquo;s code is implemented as a Python function, use the
Kubeflow Pipelines SDK to package your function as a component. <a href="https://www.kubeflow.org/docs/pipelines/sdk/python-function-components/">Learn more
about building Python function-based components</a>.</p>
<p><a name="design"></a></p>
<h2 id="designing-a-pipeline-component">Designing a pipeline component</h2>
<p>When Kubeflow Pipelines executes a component, a container image is started in a
Kubernetes Pod. Your component&rsquo;s inputs and the paths to your components outputs
are passed in as command-line arguments.</p>
<p>When you design your component&rsquo;s code, consider the following:</p>
<ul>
<li>
<p>Which inputs and outputs are <em>parameters</em> and which are <em>artifacts</em>?
Component inputs and outputs are classified as either <em>parameters</em> or
<em>artifacts</em>, depending on their data type and how they are passed to
components as inputs. All outputs are returned as files, using the the
paths that Kubeflow Pipelines provides.</p>
<p><em>Parameters</em> typically represent settings that affect the behavior of your pipeline.
Parameters are passed into your component by value, and can be of any of
the following types: <code>int</code>, <code>float</code>, <code>str</code>, <code>bool</code>, <code>dict</code>, or <code>list</code>. Since parameters are
passed by value, the quantity of data passed in a parameter must be appropriate
to pass as a command-line argument.</p>
<p><em>Artifacts</em> represent large or complex data structures like datasets or models, and
are passed into components as a reference to a file path.</p>
<p>If you have large amounts of string data to pass to your component, such as a JSON
file, annotate that input or output as a type of <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Artifact</code></a>, such
as <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Dataset</code></a>, to let Kubeflow Pipelines know to pass this to
your component as a file.</p>
<p>In addition to the artifact’s data, you can also read and write the artifact&rsquo;s
metadata. For output artifacts, you can record metadata as key-value pairs, such
as the accuracy of a trained model. For input artifacts, you can read the
artifact&rsquo;s metadata — for example, you could use metadata to decide if a
model is accurate enough to deploy for predictions.</p>
</li>
<li>
<p>To return an output from your component, the output&rsquo;s data must be stored as a file.
When you define your component, you let Kubeflow Pipelines know what outputs your
component produces. When your pipeline runs, Kubeflow Pipelines passes the
paths that you use to store your component&rsquo;s outputs as inputs to your component.</p>
</li>
<li>
<p>Outputs are typically written to a single file. In some cases, you may need to
return a directory of files as an output. In this case, create a directory at the
output path and write the output files to that location. In both cases, it may be
necessary to create parent directories if they do not exist.</p>
</li>
<li>
<p>Your component&rsquo;s goal may be to create a dataset in an external service,
such as a BigQuery table. In this case, it may make sense for the component
to output an identifier for the produced data, such as a table name,
instead of the data itself. We recommend that you limit this pattern to
cases where the data must be put into an external system instead of keeping it
inside the Kubeflow Pipelines system.</p>
</li>
<li>
<p>Since your inputs and output paths are passed in as command-line
arguments, your component&rsquo;s code must be able to read inputs from the
command line. If your component is built with Python, libraries such as
<a href="https://docs.python.org/3/library/argparse.html">argparse</a> and
<a href="https://abseil.io/docs/python/guides/flags">absl.flags</a> make it easier to
read your component&rsquo;s inputs.</p>
</li>
<li>
<p>Your component&rsquo;s code can be implemented in any language, so long as it can
run in a container image.</p>
</li>
</ul>
<p>The following is an example program written using Python3. This program reads a
given number of lines from an input file and writes those lines to an output
file. This means that this function accepts three command-line parameters:</p>
<ul>
<li>The path to the input file.</li>
<li>The number of lines to read.</li>
<li>The path to the output file.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/env python3</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">argparse</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Function doing the actual work (Outputs first N lines from a text file)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">do_work</span><span class="p">(</span><span class="n">input1_file</span><span class="p">,</span> <span class="n">output1_file</span><span class="p">,</span> <span class="n">param1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input1_file</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">param1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">break</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span> <span class="o">=</span> <span class="n">output1_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="c1"># Defining and parsing the command-line arguments</span>
</span></span><span class="line"><span class="cl"><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;My program description&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Paths must be passed in, not hardcoded</span>
</span></span><span class="line"><span class="cl"><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--input1-path&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Path of the local file containing the Input 1 data.&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--output1-path&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Path of the local file where the Output 1 data should be written.&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--param1&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">help</span><span class="o">=</span><span class="s1">&#39;The number of lines to read from the input and write to the output.&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Creating the directory where the output file is created (the directory</span>
</span></span><span class="line"><span class="cl"><span class="c1"># may or may not exist).</span>
</span></span><span class="line"><span class="cl"><span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output1_path</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">input1_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">input1_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output1_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">output1_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">do_work</span><span class="p">(</span><span class="n">input1_file</span><span class="p">,</span> <span class="n">output1_file</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">param1</span><span class="p">)</span>
</span></span></code></pre></div><p>If this program is saved as <code>program.py</code>, the command-line invocation of this
program is:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python3 program.py --input1-path &lt;path-to-the-input-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --param1 &lt;number-of-lines-to-read&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --output1-path &lt;path-to-write-the-output-to&gt; 
</span></span></code></pre></div><h2 id="containerize-your-components-code">Containerize your component&rsquo;s code</h2>
<p>For Kubeflow Pipelines to run your component, your component must be packaged
as a <a href="https://docs.docker.com/get-started/">Docker</a> container image and published to a container registry
that your Kubernetes cluster can access. The steps to create a container image
are not specific to Kubeflow Pipelines. To make things easier for you, this
section provides some guidelines on standard container creation.</p>
<ol>
<li>
<p>Create a <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a> for your container. A Dockerfile
specifies:</p>
<ul>
<li>The base container image. For example, the operating system that your
code runs on.</li>
<li>Any dependencies that need to be installed for your code to run.</li>
<li>Files to copy into the container, such as the runnable code for this
component.</li>
</ul>
<p>The following is an example Dockerfile.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">FROM python:3.7
</span></span><span class="line"><span class="cl">RUN python3 -m pip install keras
</span></span><span class="line"><span class="cl">COPY ./src /pipelines/component/src
</span></span></code></pre></div><p>In this example:</p>
<ul>
<li>The base container image is <a href="https://hub.docker.com/_/python"><code>python:3.7</code></a>.</li>
<li>The <code>keras</code> Python package is installed in the container image.</li>
<li>Files in your <code>./src</code> directory are copied into
<code>/pipelines/component/src</code> in the container image.</li>
</ul>
</li>
<li>
<p>Create a script named <code>build_image.sh </code> that uses Docker to build your
container image and push your container image to a container registry.
Your Kubernetes cluster must be able to access your container registry
to run your component. Examples of container registries include <a href="https://cloud.google.com/container-registry/docs/">Google
Container Registry</a> and
<a href="https://hub.docker.com/">Docker Hub</a>.</p>
<p>The following example builds a container image, pushes it to a container
registry, and outputs the strict image name. It is a best practice to use
the strict image name in your component specification to ensure that you
are using the expected version of a container image in each component
execution.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="cp">#!/bin/bash -e
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="nv">image_name</span><span class="o">=</span>gcr.io/my-org/my-image
</span></span><span class="line"><span class="cl"><span class="nv">image_tag</span><span class="o">=</span>latest
</span></span><span class="line"><span class="cl"><span class="nv">full_image_name</span><span class="o">=</span><span class="si">${</span><span class="nv">image_name</span><span class="si">}</span>:<span class="si">${</span><span class="nv">image_tag</span><span class="si">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> <span class="s2">&#34;</span><span class="k">$(</span>dirname <span class="s2">&#34;</span><span class="nv">$0</span><span class="s2">&#34;</span><span class="k">)</span><span class="s2">&#34;</span> 
</span></span><span class="line"><span class="cl">docker build -t <span class="s2">&#34;</span><span class="si">${</span><span class="nv">full_image_name</span><span class="si">}</span><span class="s2">&#34;</span> .
</span></span><span class="line"><span class="cl">docker push <span class="s2">&#34;</span><span class="nv">$full_image_name</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Output the strict image name, which contains the sha256 image digest</span>
</span></span><span class="line"><span class="cl">docker inspect --format<span class="o">=</span><span class="s2">&#34;{{index .RepoDigests 0}}&#34;</span> <span class="s2">&#34;</span><span class="si">${</span><span class="nv">full_image_name</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span></code></pre></div><p>In the preceding example:</p>
<ul>
<li>The <code>image_name</code> specifies the full name of your container image in the
container registry.</li>
<li>The <code>image_tag</code> specifies that this image should be tagged as
<strong>latest</strong>.</li>
</ul>
<p>Save this file and run the following to make this script executable.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">chmod +x build_image.sh
</span></span></code></pre></div></li>
<li>
<p>Run your <code>build_image.sh</code> script to build your container image and push it
to a container registry.</p>
</li>
<li>
<p><a href="https://docs.docker.com/engine/reference/commandline/run/">Use <code>docker run</code> to test your container image locally</a>. If
necessary, revise your application and Dockerfile until your application
works as expected in the container.</p>
</li>
</ol>
<p><a name="component-spec"></a></p>
<h2 id="creating-a-component-specification">Creating a component specification</h2>
<p>To create a component from your containerized program, you must create a
component specification that defines the component&rsquo;s interface and
implementation. The following sections provide an overview of how to create a
component specification by demonstrating how to define the component&rsquo;s
implementation, interface, and metadata.</p>
<p>To learn more about defining a component specification, see the
<a href="/docs/components/pipelines/reference/component-spec/">component specification reference guide</a>.</p>
<h3 id="define-your-components-implementation">Define your component&rsquo;s implementation</h3>
<p>The following example creates a component specification YAML and defines the
component&rsquo;s implementation.</p>
<ol>
<li>
<p>Create a file named <code>component.yaml</code> and open it in a text editor.</p>
</li>
<li>
<p>Create your component&rsquo;s implementation section and specify the strict name
of your container image. The strict image name is provided when you run
your <code>build_image.sh</code> script.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">implementation</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">container</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># The strict name of a container image that you&#39;ve pushed to a container registry.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">gcr.io/my-org/my-image@sha256:a172..752f</span><span class="w">
</span></span></span></code></pre></div></li>
<li>
<p>Define a <code>command</code> for your component&rsquo;s implementation. This field
specifies the command-line arguments that are used to run your program in
the container.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">implementation</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">container</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">gcr.io/my-org/my-image@sha256:a172..752f</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># command is a list of strings (command-line arguments). </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># The YAML language has two syntaxes for lists and you can use either of them. </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># Here we use the &#34;flow syntax&#34; - comma-separated strings inside square brackets.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">python3, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="c"># Path of the program inside the container</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">/pipelines/component/src/program.py,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">input1-path,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">inputPath</span><span class="p">:</span><span class="w"> </span><span class="l">input_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">param1, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">inputValue</span><span class="p">:</span><span class="w"> </span><span class="l">parameter_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">output1-path, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">outputPath</span><span class="p">:</span><span class="w"> </span><span class="l">output_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">]</span><span class="w">
</span></span></span></code></pre></div><p>The <code>command</code> is formatted as a list of strings. Each string in the
<code>command</code> is a command-line argument or a placeholder. At runtime,
placeholders are replaced with an input or output. In the preceding
example, two inputs and one output path are passed into a Python script at
<code>/pipelines/component/src/program.py</code>.</p>
<p>There are three types of input/output placeholders:</p>
<ul>
<li>
<p><code>{inputValue: &lt;input-name&gt;}</code>:
This placeholder is replaced with the value of the specified input.
This is useful for small pieces of input data, such as numbers or small
strings.</p>
</li>
<li>
<p><code>{inputPath: &lt;input-name&gt;}</code>:
This placeholder is replaced with the path to this input as a file.
Your component can read the contents of that input at that path during
the pipeline run.</p>
</li>
<li>
<p><code>{outputPath: &lt;output-name&gt;}</code>:
This placeholder is replaced with the path where your program writes
this output&rsquo;s data. This lets the Kubeflow Pipelines system read the
contents of the file and store it as the value of the specified output.</p>
</li>
</ul>
<p>The <code>&lt;input-name&gt;</code> name must match the name of an input in the <code>inputs</code>
section of your component specification. The <code>&lt;output-name&gt;</code> name must
match the name of an output in the <code>outputs</code> section of your component
specification.</p>
</li>
</ol>
<h3 id="define-your-components-interface">Define your component&rsquo;s interface</h3>
<p>The following examples demonstrate how to specify your component&rsquo;s interface.</p>
<ol>
<li>
<p>To define an input in your <code>component.yaml</code>, add an item to the
<code>inputs</code> list with the following attributes:</p>
<ul>
<li><code>name</code>: Human-readable name of this input. Each input&rsquo;s name must be
unique.</li>
<li><code>description</code>: (Optional.) Human-readable description of the input.</li>
<li><code>default</code>: (Optional.) Specifies the default value for this input.</li>
<li><code>type</code>: Specifies the input’s type. Learn more about the
<a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/types.py">types defined in the Kubeflow Pipelines SDK</a> and <a href="https://www.kubeflow.org/docs/components/pipelines/sdk/static-type-checking/">how type
checking works in pipelines and components</a>.</li>
<li><code>optional</code>: Specifies if this input is optional. The value of this
attribute is of type <code>Bool</code>, and defaults to <strong>False</strong>.</li>
</ul>
<p>In this example, the Python program has two inputs:</p>
<ul>
<li><code>input_1</code> contains <code>String</code> data.</li>
<li><code>Parameter 1</code> contains an <code>Integer</code>.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">inputs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: input_1, type: String, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Data for input_1&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: parameter_1, type: Integer, default: &#39;100&#39;, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Number of lines to copy&#39;</span>}<span class="w">
</span></span></span></code></pre></div><p>Note: <code>input_1</code> and <code>parameter_1</code> do not specify any details about how they
are stored or how much data they contain. Consider using naming conventions
to indicate if inputs are expected to be artifacts or parameters.</p>
</li>
<li>
<p>After your component finishes its task, the component&rsquo;s outputs are passed
to your pipeline as paths. At runtime, Kubeflow Pipelines creates a
path for each of your component&rsquo;s outputs. These paths are passed as inputs
to your component&rsquo;s implementation.</p>
<p>To define an output in your component specification YAML, add an item to
the <code>outputs</code> list with the following attributes:</p>
<ul>
<li><code>name</code>: Human-readable name of this output. Each output&rsquo;s name must be
unique.</li>
<li><code>description</code>: (Optional.) Human-readable description of the output.</li>
<li><code>type</code>: Specifies the output&rsquo;s type. Learn more about the
<a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/types.py">types defined in the Kubeflow Pipelines SDK</a> and <a href="https://www.kubeflow.org/docs/components/pipelines/sdk/static-type-checking/">how type
checking works in pipelines and components</a>.</li>
</ul>
<p>In this example, the Python program returns one output. The output is named
<code>output_1</code> and it contains <code>String</code> data.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">outputs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: output_1, type: String, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;output_1 data.&#39;</span>}<span class="w">
</span></span></span></code></pre></div><p>Note: Consider using naming conventions to indicate if this output is
expected to be small enough to pass by value. You should limit the amount
of data that is passed by value to 200 KB per pipeline run.</p>
</li>
<li>
<p>After you define your component&rsquo;s interface, the <code>component.yaml</code> should be
something like the following:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">inputs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: input_1, type: String, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Data for input_1&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: parameter_1, type: Integer, default: &#39;100&#39;, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Number of lines to copy&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">outputs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: output_1, type: String, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;output_1 data.&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">implementation</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">container</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">gcr.io/my-org/my-image@sha256:a172..752f</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># command is a list of strings (command-line arguments). </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># The YAML language has two syntaxes for lists and you can use either of them. </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># Here we use the &#34;flow syntax&#34; - comma-separated strings inside square brackets.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">python3, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="c"># Path of the program inside the container</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">/pipelines/component/src/program.py,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">input1-path,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">inputPath</span><span class="p">:</span><span class="w"> </span><span class="l">input_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">param1, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">inputValue</span><span class="p">:</span><span class="w"> </span><span class="l">parameter_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">output1-path, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">outputPath</span><span class="p">:</span><span class="w"> </span><span class="l">output_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">]</span><span class="w">
</span></span></span></code></pre></div></li>
</ol>
<h3 id="specify-your-components-metadata">Specify your component&rsquo;s metadata</h3>
<p>To define your component&rsquo;s metadata, add the <code>name</code> and <code>description</code>
fields to your <code>component.yaml</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Get Lines</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="l">Gets the specified number of lines from the input file.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">inputs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: input_1, type: String, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Data for input_1&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: parameter_1, type: Integer, default: &#39;100&#39;, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Number of lines to copy&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">outputs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- {<span class="nt">name: output_1, type: String, description</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;output_1 data.&#39;</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">implementation</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">container</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">gcr.io/my-org/my-image@sha256:a172..752f</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># command is a list of strings (command-line arguments). </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># The YAML language has two syntaxes for lists and you can use either of them. </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># Here we use the &#34;flow syntax&#34; - comma-separated strings inside square brackets.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">python3, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="c"># Path of the program inside the container</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">/pipelines/component/src/program.py,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">input1-path,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">inputPath</span><span class="p">:</span><span class="w"> </span><span class="l">input_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">param1, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">inputValue</span><span class="p">:</span><span class="w"> </span><span class="l">parameter_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>--<span class="l">output1-path, </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>{<span class="nt">outputPath</span><span class="p">:</span><span class="w"> </span><span class="l">output_1},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">]</span><span class="w">
</span></span></span></code></pre></div><h2 id="using-your-component-in-a-pipeline">Using your component in a pipeline</h2>
<p>You can use the Kubeflow Pipelines SDK to load your component using methods
such as the following:</p>
<ul>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.components.html#kfp.components.load_component_from_file"><code>kfp.components.load_component_from_file</code></a>:
Use this method to load your component from a <code>component.yaml</code> path.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.components.html#kfp.components.load_component_from_url"><code>kfp.components.load_component_from_url</code></a>:
Use this method to load a <code>component.yaml</code> from a URL.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.components.html#kfp.components.load_component_from_text"><code>kfp.components.load_component_from_text</code></a>:
Use this method to load your component specification YAML from a string.
This method is useful for rapidly iterating on your component
specification.</li>
</ul>
<p>These functions create a factory function that you can use to create
<a href="https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp"><code>ContainerOp</code></a> instances to use as steps in your pipeline.
This factory function&rsquo;s input arguments include your component&rsquo;s inputs and
the paths to your component&rsquo;s outputs. The function signature may be modified
in the following ways to ensure that it is valid and Pythonic.</p>
<ul>
<li>Inputs with default values will come after the inputs without default
values and outputs.</li>
<li>Input and output names are converted to Pythonic names (spaces and symbols
are replaced with underscores and letters are converted to lowercase). For
example, an input named <code>Input 1</code> is converted to <code>input_1</code>.</li>
</ul>
<p>The following example demonstrates how to load the text of your component
specification and run it in a single-step pipeline. Before you run this
example, update the component specification to use the component
specification you defined in the previous sections.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp.components</span> <span class="k">as</span> <span class="nn">comp</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">create_step_get_lines</span> <span class="o">=</span> <span class="n">comp</span><span class="o">.</span><span class="n">load_component_from_text</span><span class="p">(</span><span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">name: Get Lines
</span></span></span><span class="line"><span class="cl"><span class="s2">description: Gets the specified number of lines from the input file.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">inputs:
</span></span></span><span class="line"><span class="cl"><span class="s2">- {name: input_1, type: String, description: &#39;Data for input_1&#39;}
</span></span></span><span class="line"><span class="cl"><span class="s2">- {name: parameter_1, type: Integer, default: &#39;100&#39;, description: &#39;Number of lines to copy&#39;}
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">outputs:
</span></span></span><span class="line"><span class="cl"><span class="s2">- {name: output_1, type: String, description: &#39;output_1 data.&#39;}
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">implementation:
</span></span></span><span class="line"><span class="cl"><span class="s2">  container:
</span></span></span><span class="line"><span class="cl"><span class="s2">    image: gcr.io/my-org/my-image@sha256:a172..752f
</span></span></span><span class="line"><span class="cl"><span class="s2">    # command is a list of strings (command-line arguments). 
</span></span></span><span class="line"><span class="cl"><span class="s2">    # The YAML language has two syntaxes for lists and you can use either of them. 
</span></span></span><span class="line"><span class="cl"><span class="s2">    # Here we use the &#34;flow syntax&#34; - comma-separated strings inside square brackets.
</span></span></span><span class="line"><span class="cl"><span class="s2">    command: [
</span></span></span><span class="line"><span class="cl"><span class="s2">      python3, 
</span></span></span><span class="line"><span class="cl"><span class="s2">      # Path of the program inside the container
</span></span></span><span class="line"><span class="cl"><span class="s2">      /pipelines/component/src/program.py,
</span></span></span><span class="line"><span class="cl"><span class="s2">      --input1-path,
</span></span></span><span class="line"><span class="cl"><span class="s2">      {inputPath: input_1},
</span></span></span><span class="line"><span class="cl"><span class="s2">      --param1, 
</span></span></span><span class="line"><span class="cl"><span class="s2">      {inputValue: parameter_1},
</span></span></span><span class="line"><span class="cl"><span class="s2">      --output1-path, 
</span></span></span><span class="line"><span class="cl"><span class="s2">      {outputPath: output_1},
</span></span></span><span class="line"><span class="cl"><span class="s2">    ]&#34;&#34;&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># create_step_get_lines is a &#34;factory function&#34; that accepts the arguments</span>
</span></span><span class="line"><span class="cl"><span class="c1"># for the component&#39;s inputs and output paths and returns a pipeline step</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (ContainerOp instance).</span>
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl"><span class="c1"># To inspect the get_lines_op function in Jupyter Notebook, enter </span>
</span></span><span class="line"><span class="cl"><span class="c1"># &#34;get_lines_op(&#34; in a cell and press Shift+Tab.</span>
</span></span><span class="line"><span class="cl"><span class="c1"># You can also get help by entering `help(get_lines_op)`, `get_lines_op?`,</span>
</span></span><span class="line"><span class="cl"><span class="c1"># or `get_lines_op??`.</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define your pipeline</span>
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">pipeline_root</span><span class="o">=</span><span class="s1">&#39;gs://my-pipeline-root/example-pipeline&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span><span class="o">=</span><span class="s2">&#34;example-pipeline&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">get_lines_step</span> <span class="o">=</span> <span class="n">create_step_get_lines</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Input name &#34;Input 1&#34; is converted to pythonic parameter name &#34;input_1&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">input_1</span><span class="o">=</span><span class="s1">&#39;one</span><span class="se">\n</span><span class="s1">two</span><span class="se">\n</span><span class="s1">three</span><span class="se">\n</span><span class="s1">four</span><span class="se">\n</span><span class="s1">five</span><span class="se">\n</span><span class="s1">six</span><span class="se">\n</span><span class="s1">seven</span><span class="se">\n</span><span class="s1">eight</span><span class="se">\n</span><span class="s1">nine</span><span class="se">\n</span><span class="s1">ten&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">parameter_1</span><span class="o">=</span><span class="s1">&#39;5&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># If you run this command on a Jupyter notebook running on Kubeflow,</span>
</span></span><span class="line"><span class="cl"><span class="c1"># you can exclude the host parameter.</span>
</span></span><span class="line"><span class="cl"><span class="c1"># client = kfp.Client()</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;&lt;your-kubeflow-pipelines-host-name&gt;&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Compile, upload, and submit this pipeline for execution.</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="p">{},</span>
</span></span><span class="line"><span class="cl">    <span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="organizing-the-component-files">Organizing the component files</h2>
<p>This section provides a recommended way to organize a component&rsquo;s files. There
is no requirement that you must organize the files in this way. However, using
the standard organization makes it possible to reuse the same scripts for
testing, image building, and component versioning.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-zed" data-lang="zed"><span class="line"><span class="cl"><span class="nn">components/</span><span class="o">&lt;</span><span class="n">component</span><span class="w"> </span><span class="n">group</span><span class="o">&gt;/&lt;</span><span class="n">component</span><span class="w"> </span><span class="n">name</span><span class="o">&gt;/</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nn">src/</span><span class="o">*</span><span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Component</span><span class="w"> </span><span class="n">source</span><span class="w"> </span><span class="n">code</span><span class="w"> </span><span class="n">files</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nn">tests/</span><span class="o">*</span><span class="w">          </span><span class="err">#</span><span class="w"> </span><span class="n">Unit</span><span class="w"> </span><span class="n">tests</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">run_tests</span><span class="p">.</span><span class="n">sh</span><span class="w">     </span><span class="err">#</span><span class="w"> </span><span class="n">Small</span><span class="w"> </span><span class="n">script</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">runs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">tests</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">README</span><span class="p">.</span><span class="n">md</span><span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="n">Documentation</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">multiple</span><span class="w"> </span><span class="n">files</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">needed</span><span class="p">,</span><span class="w"> </span><span class="n">move</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="nn">docs/</span><span class="p">.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">Dockerfile</span><span class="w">       </span><span class="err">#</span><span class="w"> </span><span class="n">Dockerfile</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">build</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">component</span><span class="w"> </span><span class="n">container</span><span class="w"> </span><span class="n">image</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">build_image</span><span class="p">.</span><span class="n">sh</span><span class="w">   </span><span class="err">#</span><span class="w"> </span><span class="n">Small</span><span class="w"> </span><span class="n">script</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">runs</span><span class="w"> </span><span class="n">docker</span><span class="w"> </span><span class="n">build</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">docker</span><span class="w"> </span><span class="n">push</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">component</span><span class="p">.</span><span class="n">yaml</span><span class="w">   </span><span class="err">#</span><span class="w"> </span><span class="n">Component</span><span class="w"> </span><span class="kt">definition</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">YAML</span><span class="w"> </span><span class="n">format</span><span class="w">
</span></span></span></code></pre></div><p>See this <a href="https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/components/sample/keras/train_classifier">sample component</a> for a real-life component example.</p>
<h2 id="next-steps">Next steps</h2>
<ul>
<li>Consolidate what you&rsquo;ve learned by reading the
<a href="/docs/components/pipelines/sdk/best-practices">best practices</a> for designing and
writing components.</li>
<li>For quick iteration,
<a href="/docs/components/pipelines/sdk-v2/python-function-components/">build lightweight Python function-based components</a>
directly from Python functions.</li>
<li>Use SDK APIs to visualize pipeline result, follow
<a href="/docs/components/pipelines/sdk/output-viewer/#v2-visualization">Visualize Results in the Pipelines UI</a>
for various visualization types.</li>
<li>See how to <a href="/docs/components/pipelines/sdk/pipelines-metrics/">export metrics from your
pipeline</a>.</li>
<li>Visualize the output of your component by
<a href="/docs/components/pipelines/sdk/output-viewer/">adding metadata for an output
viewer</a>.</li>
<li>Explore the <a href="/docs/examples/shared-resources/">reusable components and other shared
resources</a>.</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-1b784a63be21dc3d677420b83ac1439e">6 - Building Python Function-based Components</h1>
    <div class="lead">Building your own lightweight pipelines components using the Pipelines SDK v2 and Python</div>
	<!--
AUTOGENERATED FROM content/en/docs/components/pipelines/sdk-v2/python-function-components.ipynb
PLEASE UPDATE THE JUPYTER NOTEBOOK AND REGENERATE THIS FILE USING scripts/nb_to_md.py.-->
<style>
.notebook-links {display: flex; margin: 1em 0;}
.notebook-links a {padding: .75em; margin-right: .75em; font-weight: bold;}
a.colab-link {
padding-left: 3.25em;
background-image: url(/docs/images/logos/colab.ico);
background-repeat: no-repeat;
background-size: contain;
}
a.github-link {
padding-left: 2.75em;
background-image: url(/docs/images/logos/github.png);
background-repeat: no-repeat;
background-size: auto 75%;
background-position: left center;
}
</style>
<div class="notebook-links">
<a class="colab-link" href="https://colab.research.google.com/github/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/python-function-components.ipynb">Run in Google Colab</a>
<a class="github-link" href="https://github.com/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/python-function-components.ipynb">View source on GitHub</a>
</div>
<p>A Kubeflow Pipelines component is a self-contained set of code that performs one step in your
ML workflow. A pipeline component is composed of:</p>
<ul>
<li>
<p>The component code, which implements the logic needed to perform a step in your ML workflow.</p>
</li>
<li>
<p>A component specification, which defines the following:</p>
<ul>
<li>The component&rsquo;s metadata, its name and description.</li>
<li>The component&rsquo;s interface, the component&rsquo;s inputs and outputs.</li>
<li>The component&rsquo;s implementation, the Docker container image
to run, how to pass inputs to your component code, and how
to get the component&rsquo;s outputs.</li>
</ul>
</li>
</ul>
<p>Python function-based components make it easier to iterate quickly by letting you build your
component code as a Python function and generating the <a href="https://www.kubeflow.org/docs/components/pipelines/reference/component-spec/">component specification</a> for you.
This document describes how to build Python function-based components and use them in your pipeline.</p>
<p><strong>Note:</strong> This guide demonstrates how to build components using the Pipelines SDK v2.
Currently, Kubeflow Pipelines v2 is in development. You can use this guide to start
building and running pipelines that are compatible with the Pipelines SDK v2.</p>
<p><a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/v2-compatibility/">Learn more about Pipelines SDK v2</a>.</p>
<h2 id="before-you-begin">Before you begin</h2>
<ol>
<li>Run the following command to install the Kubeflow Pipelines SDK v1.6.2 or higher. If you run this command in a Jupyter
notebook, restart the kernel after installing the SDK.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">kfp</span>
</span></span></code></pre></div><ol start="2">
<li>Import the <code>kfp</code>, <code>kfp.dsl</code>, and <code>kfp.v2.dsl</code> packages.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp.dsl</span> <span class="k">as</span> <span class="nn">dsl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2.dsl</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">component</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Input</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Output</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Metrics</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><ol start="3">
<li>Create an instance of the <a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client"><code>kfp.Client</code> class</a> following steps in <a href="https://www.kubeflow.org/docs/components/pipelines/sdk/connect-api">connecting to Kubeflow Pipelines using the SDK client</a>.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">kfp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span> <span class="c1"># change arguments accordingly</span>
</span></span></code></pre></div><p>For more information about the Kubeflow Pipelines SDK, see the <a href="https://kubeflow-pipelines.readthedocs.io/en/stable/index.html">SDK reference guide</a>.</p>
<h2 id="getting-started-with-python-function-based-components">Getting started with Python function-based components</h2>
<p>This section demonstrates how to get started building Python function-based components by walking
through the process of creating a simple component.</p>
<ol>
<li>Define your component&rsquo;s code as a <a href="#standalone">standalone python function</a>.
In this example, the function adds two floats and returns the sum of the two
arguments. Use the <code>kfp.v2.dsl.component</code> annotation to convert the function
into a factory function that you can use to create
<a href="https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.ContainerOp"><code>kfp.dsl.ContainerOp</code></a> class instances to use as steps in your pipeline.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;&#39;&#39;Calculates sum of two arguments&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
</span></span></code></pre></div><ol start="2">
<li>Create and run your pipeline. <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/build-pipeline/#compile-and-run-your-pipeline">Learn more about creating and running pipelines</a>.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp.dsl</span> <span class="k">as</span> <span class="nn">dsl</span>
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;addition-pipeline&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">description</span><span class="o">=</span><span class="s1">&#39;An example pipeline that performs addition calculations.&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">pipeline_root</span><span class="o">=</span><span class="s1">&#39;gs://my-pipeline-root/example-pipeline&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">add_pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># Passes a pipeline parameter and a constant value to the `add` factory</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># function.</span>
</span></span><span class="line"><span class="cl">  <span class="n">first_add_task</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># Passes an output reference from `first_add_task` and a pipeline parameter</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># to the `add` factory function. For operations with a single return</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># value, the output reference can be accessed as `task.output` or</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># `task.outputs[&#39;output_name&#39;]`.</span>
</span></span><span class="line"><span class="cl">  <span class="n">second_add_task</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">first_add_task</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Specify pipeline argument values</span>
</span></span><span class="line"><span class="cl"><span class="n">arguments</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
</span></span></code></pre></div><ol start="3">
<li>Compile and run your pipeline. <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/build-pipeline/#compile-and-run-your-pipeline">Learn more about compiling and running pipelines</a>.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Submit a pipeline run using the v2 compatible mode</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">arguments</span><span class="o">=</span><span class="n">arguments</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="building-python-function-based-components">Building Python function-based components</h2>
<p>Use the following instructions to build a Python function-based component:</p>
<p><a name="standalone"></a></p>
<ol>
<li>
<p>Define a standalone Python function. This function must meet the following
requirements:</p>
<ul>
<li>It should not use any code declared outside of the function definition.</li>
<li>Import statements must be added inside the function. <a href="#packages">Learn more about
using and installing Python packages in your component</a>.</li>
<li>Helper functions must be defined inside this function.</li>
</ul>
</li>
<li>
<p>Kubeflow Pipelines uses your function&rsquo;s inputs and outputs to define your
component&rsquo;s interface. <a href="#pass-data">Learn more about passing data between
components</a>. Your function&rsquo;s inputs and outputs must meet the
following requirements:</p>
<ul>
<li>All your function&rsquo;s arguments must have data type annotations.</li>
<li>If the function accepts or returns large amounts of data or complex
data types, you must annotate that argument as an <em>artifact</em>.
<a href="#pass-by-file">Learn more about using large amounts of data as inputs or outputs</a>.</li>
<li>If your component returns multiple outputs, you can annotate your
function with the <a href="https://docs.python.org/3/library/typing.html#typing.NamedTuple"><code>typing.NamedTuple</code></a> type hint
and use the <a href="https://docs.python.org/3/library/collections.html#collections.namedtuple"><code>collections.namedtuple</code></a> function return
your function&rsquo;s outputs as a new subclass of tuple. For an example, read
<a href="#pass-by-value">Passing parameters by value</a>.</li>
</ul>
</li>
<li>
<p>(Optional.) If your function has complex dependencies, choose or build a
container image for your Python function to run in. <a href="#containers">Learn more about
selecting or building your component&rsquo;s container image</a>.</p>
</li>
<li>
<p>Add the <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/v2/components/component_decorator.py"><code>kfp.v2.dsl.component</code></a> decorator to convert your function
into a pipeline component. You can specify the following arguments to the decorator:</p>
<ul>
<li><strong>base_image</strong>: (Optional.) Specify the Docker container image to run
this function in. <a href="#containers">Learn more about selecting or building a container
image</a>.</li>
<li><strong>output_component_file</strong>: (Optional.) Writes your component definition
to a file. You can use this file to share the component with colleagues
or reuse it in different pipelines.</li>
<li><strong>packages_to_install</strong>: (Optional.) A list of versioned Python
packages to install before running your function.</li>
</ul>
</li>
</ol>
<p><a name="packages"></a></p>
<h3 id="using-and-installing-python-packages">Using and installing Python packages</h3>
<p>When Kubeflow Pipelines runs your pipeline, each component runs within a Docker
container image on a Kubernetes Pod. To load the packages that your Python
function depends on, one of the following must be true:</p>
<ul>
<li>The package must be installed on the container image.</li>
<li>The package must be defined using the <code>packages_to_install</code> parameter of the
<a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/v2/components/component_decorator.py"><code>kfp.v2.dsl.component</code></a> decorator.</li>
<li>Your function must install the package. For example, your function can use
the <a href="https://docs.python.org/3/library/subprocess.html"><code>subprocess</code> module</a> to run a command like <code>pip install</code>
that installs a package.</li>
</ul>
<p><a name="containers"></a></p>
<h3 id="selecting-or-building-a-container-image">Selecting or building a container image</h3>
<p>Currently, if you do not specify a container image, your Python-function based
component uses the <a href="https://hub.docker.com/layers/python/library/python/3.7/images/sha256-7eef781ed825f3b95c99f03f4189a8e30e718726e8490651fa1b941c6c815ad1?context=explore"><code>python:3.7</code> container image</a>. If your function
has complex dependencies, you may benefit from using a container image that has
your dependencies preinstalled, or building a custom container image.
Preinstalling your dependencies reduces the amount of time that your component
runs in, since your component does not need to download and install packages
each time it runs.</p>
<p>Many frameworks, such as <a href="https://www.tensorflow.org/install/docker">TensorFlow</a> and <a href="https://hub.docker.com/r/pytorch/pytorch/tags">PyTorch</a>,
and cloud service providers offer prebuilt container images that have common
dependencies installed.</p>
<p>If a prebuilt container is not available, you can build a custom container
image with your Python function&rsquo;s dependencies. For more information about
building a custom container, read the <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile reference guide in the Docker
documentation</a>.</p>
<p>If you build or select a container image, instead of using the default
container image, the container image must use Python 3.5 or later.</p>
<p><a name="pass-data"></a></p>
<h3 id="understanding-how-data-is-passed-between-components">Understanding how data is passed between components</h3>
<p>When Kubeflow Pipelines runs your component, a container image is started in a
Kubernetes Pod and your component&rsquo;s inputs are passed in as command-line
arguments. When your component has finished, the component’s outputs are
returned as files.</p>
<p>Python function-based components make it easier to build pipeline components by
building the component specification for you. Python function-based components
also handle the complexity of passing inputs into your component and passing
your function&rsquo;s outputs back to your pipeline.</p>
<p>Component inputs and outputs are classified as either <em>parameters</em> or <em>artifacts</em>,
depending on their data type.</p>
<ul>
<li>
<p>Parameters typically represent settings that affect the behavior of your pipeline.
Parameters are passed into your component by value, and can be of any of
the following types: <code>int</code>, <code>double</code>, <code>float</code>, or <code>str</code>. Since parameters are
passed by value, the quantity of data passed in a parameter must be appropriate
to pass as a command-line argument.</p>
</li>
<li>
<p>Artifacts represent large or complex data structures like datasets or models, and
are passed into components as a reference to a file path.</p>
<p>If you have large amounts of string data to pass to your component, such as a JSON
file, annotate that input or output as a type of <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Artifact</code></a>, such
as <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Dataset</code></a>, to let Kubeflow Pipelines know to pass this to
your component as a file.</p>
<p>In addition to the artifact’s data, you can also read and write the artifact&rsquo;s
metadata. For output artifacts, you can record metadata as key-value pairs, such
as the accuracy of a trained model. For input artifacts, you can read the
artifact&rsquo;s metadata — for example, you could use metadata to decide if a
model is accurate enough to deploy for predictions.</p>
</li>
</ul>
<p>All outputs are returned as files, using the the paths that Kubeflow Pipelines
provides.</p>
<p>The following sections describe how to pass parameters and artifacts to your function.</p>
<p><a name="pass-by-value"></a></p>
<h4 id="passing-parameters-by-value">Passing parameters by value</h4>
<p>Python function-based components make it easier to pass parameters between
components by value (such as numbers, booleans, and short strings), by letting
you define your component’s interface by annotating your Python function.
Parameters can be of any type that is appropriate to pass as a command-line argument, such as <code>int</code>, <code>float</code>, <code>double</code>, or <code>str</code>.</p>
<p>If your component returns multiple outputs by value, annotate your function
with the <a href="https://docs.python.org/3/library/typing.html#typing.NamedTuple"><code>typing.NamedTuple</code></a> type hint and use the
<a href="https://docs.python.org/3/library/collections.html#collections.namedtuple"><code>collections.namedtuple</code></a> function to return your function&rsquo;s
outputs as a new subclass of <code>tuple</code>.</p>
<p>The following example demonstrates how to return multiple outputs by value.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">multiple_return_values_example</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="s1">&#39;ExampleOutputs&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s1">&#39;product&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">]):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Example function that demonstrates how to return multiple values.&#34;&#34;&#34;</span>  
</span></span><span class="line"><span class="cl">  <span class="n">sum_value</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">  <span class="n">product_value</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
</span></span><span class="line"><span class="cl">  <span class="n">example_output</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;ExampleOutputs&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;product&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">example_output</span><span class="p">(</span><span class="n">sum_value</span><span class="p">,</span> <span class="n">product_value</span><span class="p">)</span>
</span></span></code></pre></div><p><a name="pass-by-file"></a></p>
<h4 id="passing-artifacts-by-file">Passing artifacts by file</h4>
<p>Python function-based components make it easier to pass files to your
component, or to return files from your component, by letting you annotate
your Python function&rsquo;s arguments as <em>artifacts</em>.
Artifacts represent large or complex data structures like datasets or models, and are passed into components as a reference to a file path.</p>
<p>In addition to the artifact’s data, you can also read and write the artifact&rsquo;s metadata. For output artifacts, you can record metadata as key-value pairs, such as the accuracy of a trained model. For input artifacts, you can read the artifact&rsquo;s metadata — for example, you could use metadata to decide if a model is accurate enough to deploy for predictions.</p>
<p>If your artifact is an output file, Kubeflow Pipelines passes your function a
path or stream that you can use to store your output file. This path is a
location within your pipeline&rsquo;s <code>pipeline_root</code> that your component can write to.</p>
<p>The following example accepts a file as an input and returns two files as outputs.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@component</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">split_text_lines</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">source</span><span class="p">:</span> <span class="n">Input</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">odd_lines</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">even_lines_path</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Splits a text file into two files, with even lines going to one file
</span></span></span><span class="line"><span class="cl"><span class="s2">    and odd lines to the other.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">odd_lines</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">odd_writer</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">even_lines_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">even_writer</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">line</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">line</span> <span class="o">==</span> <span class="s2">&#34;&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="k">break</span>
</span></span><span class="line"><span class="cl">                    <span class="n">odd_writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">line</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">line</span> <span class="o">==</span> <span class="s2">&#34;&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="k">break</span>
</span></span><span class="line"><span class="cl">                    <span class="n">even_writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</span></span></code></pre></div><p>In this example, the inputs and outputs are defined as arguments of the
<code>split_text_lines</code> function. This lets Kubeflow Pipelines pass the path to the
source data file and the paths to the output data files into the function.</p>
<p>To accept a file as an input parameter, use one of the following type annotations:</p>
<ul>
<li><a href="https://github.com/kubeflow/pipelines/blob/c5daa7532d18687b180badfca8d750c801805712/sdk/python/kfp/dsl/io_types.py"><code>kfp.dsl.Input</code></a>: Use this generic type hint to specify that your
function expects this argument to be an <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Artifact</code></a>. Your
function can use the argument&rsquo;s <code>path</code> property to get the
artifact&rsquo;s path, and the <code>metadata</code> property to read its key/value metadata.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.InputBinaryFile"><code>kfp.components.InputBinaryFile</code></a>: Use this annotation to
specify that your function expects an argument to be an
<a href="https://docs.python.org/3/library/io.html#io.BytesIO"><code>io.BytesIO</code></a> instance that this function can read.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.InputPath"><code>kfp.components.InputPath</code></a>: Use this annotation to specify that
your function expects an argument to be the path to the input file as
a <code>string</code>.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.InputTextFile"><code>kfp.components.InputTextFile</code></a>: Use this annotation to specify
that your function expects an argument to be an
<a href="https://docs.python.org/3/library/io.html#io.TextIOWrapper"><code>io.TextIOWrapper</code></a> instance that this function can read.</li>
</ul>
<p>To return a file as an output, use one of the following type annotations:</p>
<ul>
<li><a href="https://github.com/kubeflow/pipelines/blob/c5daa7532d18687b180badfca8d750c801805712/sdk/python/kfp/dsl/io_types.py"><code>kfp.dsl.Output</code></a>: Use this generic type hin to specify that your
function expects this argument to be an <a href="https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/dsl/io_types.py"><code>Artifact</code></a>. Your
function can use the argument&rsquo;s <code>path</code> property to get the
artifact path to write to, and the <code>metadata</code> property to log key/value metadata.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.OutputBinaryFile"><code>kfp.components.OutputBinaryFile</code></a>: Use this annotation to
specify that your function expects an argument to be an
<a href="https://docs.python.org/3/library/io.html#io.BytesIO"><code>io.BytesIO</code></a> instance that this function can write to.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.OutputPath"><code>kfp.components.OutputPath</code></a>: Use this annotation to specify that
your function expects an argument to be the path to store the output file at
as a <code>string</code>.</li>
<li><a href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.OutputTextFile"><code>kfp.components.OutputTextFile</code></a>: Use this annotation to specify
that your function expects an argument to be an
<a href="https://docs.python.org/3/library/io.html#io.TextIOWrapper"><code>io.TextIOWrapper</code></a> that this function can write to.</li>
</ul>
<h2 id="example-python-function-based-component">Example Python function-based component</h2>
<p>This section demonstrates how to build a Python function-based component that uses imports,
helper functions, and produces multiple outputs.</p>
<ol>
<li>
<p>Define your function. This example function uses the <code>numpy</code> package to calculate the
quotient and remainder for a given dividend and divisor in a helper function. In
addition to the quotient and remainder, the function also returns two metrics.</p>
<p>By adding the <code>@component</code> annotation, you convert your function into a factory function
that creates pipeline steps that execute this function. This example also specifies the
base container image to run you component in.</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">NamedTuple</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@component</span><span class="p">(</span><span class="n">base_image</span><span class="o">=</span><span class="s1">&#39;tensorflow/tensorflow:1.11.0-py3&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_divmod</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">dividend</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">divisor</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">metrics</span><span class="p">:</span> <span class="n">Output</span><span class="p">[</span><span class="n">Metrics</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NamedTuple</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;MyDivmodOutput&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span>
</span></span><span class="line"><span class="cl">      <span class="p">(</span><span class="s1">&#39;quotient&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">      <span class="p">(</span><span class="s1">&#39;remainder&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;&#39;&#39;Divides two numbers and calculate  the quotient and remainder&#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Import the numpy package inside the component function</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Define a helper function</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">divmod_helper</span><span class="p">(</span><span class="n">dividend</span><span class="p">,</span> <span class="n">divisor</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">divmod</span><span class="p">(</span><span class="n">dividend</span><span class="p">,</span> <span class="n">divisor</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="n">quotient</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span> <span class="o">=</span> <span class="n">divmod_helper</span><span class="p">(</span><span class="n">dividend</span><span class="p">,</span> <span class="n">divisor</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Export two metrics</span>
</span></span><span class="line"><span class="cl">    <span class="n">metrics</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;quotient&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">quotient</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">metrics</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;remainder&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">remainder</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
</span></span><span class="line"><span class="cl">    <span class="n">divmod_output</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;MyDivmodOutput&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="s1">&#39;quotient&#39;</span><span class="p">,</span> <span class="s1">&#39;remainder&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">divmod_output</span><span class="p">(</span><span class="n">quotient</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
</span></span></code></pre></div><ol start="2">
<li>Define your pipeline. This example pipeline uses the <code>my_divmod</code> factory
function and the <code>add</code> factory function from an earlier example.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">kfp.dsl</span> <span class="k">as</span> <span class="nn">dsl</span>
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">   <span class="n">name</span><span class="o">=</span><span class="s1">&#39;calculation-pipeline&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">   <span class="n">description</span><span class="o">=</span><span class="s1">&#39;An example pipeline that performs arithmetic calculations.&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">   <span class="n">pipeline_root</span><span class="o">=</span><span class="s1">&#39;gs://my-pipeline-root/example-pipeline&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">calc_pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">   <span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">   <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">   <span class="n">c</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">17</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Passes a pipeline parameter and a constant value as operation arguments.</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_task</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># The add_op factory function returns</span>
</span></span><span class="line"><span class="cl">                            <span class="c1"># a dsl.ContainerOp class instance. </span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Passes the output of the add_task and a pipeline parameter as operation</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># arguments. For an operation with a single return value, the output</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># reference is accessed using `task.output` or</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># `task.outputs[&#39;output_name&#39;]`.</span>
</span></span><span class="line"><span class="cl">    <span class="n">divmod_task</span> <span class="o">=</span> <span class="n">my_divmod</span><span class="p">(</span><span class="n">add_task</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># For an operation with multiple return values, output references are</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># accessed as `task.outputs[&#39;output_name&#39;]`.</span>
</span></span><span class="line"><span class="cl">    <span class="n">result_task</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">divmod_task</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;quotient&#39;</span><span class="p">],</span> <span class="n">c</span><span class="p">)</span>
</span></span></code></pre></div><ol start="3">
<li>Compile and run your pipeline. <a href="https://www.kubeflow.org/docs/components/pipelines/sdk-v2/build-pipeline/#compile-and-run-your-pipeline">Learn more about compiling and running pipelines</a>.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Specify pipeline argument values</span>
</span></span><span class="line"><span class="cl"><span class="n">arguments</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Submit a pipeline run</span>
</span></span><span class="line"><span class="cl"><span class="n">client</span><span class="o">.</span><span class="n">create_run_from_pipeline_func</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">calc_pipeline</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">arguments</span><span class="o">=</span><span class="n">arguments</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">mode</span><span class="o">=</span><span class="n">kfp</span><span class="o">.</span><span class="n">dsl</span><span class="o">.</span><span class="n">PipelineExecutionMode</span><span class="o">.</span><span class="n">V2_COMPATIBLE</span><span class="p">)</span>
</span></span></code></pre></div><div class="notebook-links">
<a class="colab-link" href="https://colab.research.google.com/github/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/python-function-components.ipynb">Run in Google Colab</a>
<a class="github-link" href="https://github.com/kubeflow/website/blob/master/content/en/docs/components/pipelines/sdk-v2/python-function-components.ipynb">View source on GitHub</a>
</div>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-469c8de604213a6de88b276eeb473f1b">7 - Importer component</h1>
    <div class="lead">Use an importer component to import artifacts from remote storage</div>
	<p>The KFP SDK v2 provides an importer component as a pre-baked component for a specific use case: importing a machine learning from remote storage to machine learning metadata (MLMD).</p>
<p>Typically, the input artifact to a task is an output from an upstream task. In this case, the artifact can be easily accessed from the upstream task using <code>my_task.outputs['artifact_name']</code>. The artifact is also registered in MLMD when it is created by the upstream task.</p>
<p>If you wish to use an existing artifact that is not generated by a task in the current pipeline <em>or</em> wish to use as an artifact an external file that was not generated by a pipeline at all, you can use an importer component to load an artifact from its URI.</p>
<p>You do not need to write an importer component; it can be imported from the <code>dsl</code> module and used directly:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kfp.v2</span> <span class="kn">import</span> <span class="n">dsl</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dsl</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;pipeline-with-importer&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">my_pipeline</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">task</span> <span class="o">=</span> <span class="n">get_date_string</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">importer_task</span> <span class="o">=</span> <span class="n">dsl</span><span class="o">.</span><span class="n">importer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">artifact_uri</span><span class="o">=</span><span class="s1">&#39;gs://ml-pipeline-playground/shakespeare1.txt&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">artifact_class</span><span class="o">=</span><span class="n">dsl</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">reimport</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">task</span><span class="o">.</span><span class="n">output</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">    <span class="n">other_component</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">importer_task</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></div><p>In addition to the <code>artifact_uri</code>, you must provide an <code>artifact_class</code>, indicating the type of the artifact.</p>
<p>The <code>importer</code> component permits setting artifact metadata via the <code>metadata</code> argument. Metadata can be constructed with outputs from upstream tasks, as is done for the <code>'date'</code> value in the example pipeline.</p>
<p>You may also specify a boolean <code>reimport</code> argument. If <code>reimport</code> is <code>False</code>, KFP will use an existing MLMD artifact if it already exists from an earlier importer execution. If <code>reimport</code> is <code>True</code>, KFP will reimport the artifact as a new artifact, irrespective of whether it was previously imported.</p>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark pt-3 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Kubeflow mailing list" aria-label="Kubeflow mailing list">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-mailing-list" aria-label="Kubeflow mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/kubeflow" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" rel="noopener" href="https://stackoverflow.com/questions/tagged/kubeflow" aria-label="Stack Overflow">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/kubeflow-distribution" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.kubeflow.org/docs/about/community/#kubeflow-slack" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-5 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022 Google | Documentation Distributed under CC BY 4.0</small>
        <p><small class="ml-1"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">Privacy Policy</a></small></p>
	
		<p class="mt-2"><a href="/kubeflow-docs/docs/about/">About</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="/kubeflow-docs/js/main.min.301c0110334bec1b4445867d27dc7dd69b2df859154ccf252005508bc860cc5a.js" integrity="sha256-MBwBEDNL7BtERYZ9J9x91pst&#43;FkVTM8lIAVQi8hgzFo=" crossorigin="anonymous"></script>
<script src='/kubeflow-docs/js/tabpane-persist.js'></script>

  </body>
</html>
