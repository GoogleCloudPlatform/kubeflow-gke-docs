<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubeflow on Google Cloud Platform â€“ Samples and Tutorials</title>
    <link>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/</link>
    <description>Recent content in Samples and Tutorials on Kubeflow on Google Cloud Platform</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Using the Kubeflow Pipelines Benchmark Scripts</title>
      <link>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/benchmark-examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/benchmark-examples/</guid>
      <description>
        
        
        &lt;p&gt;This guide explains the Kubeflow Pipelines &lt;a href=&#34;https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/tools/benchmarks&#34;&gt;benchmark scripts&lt;/a&gt;
and demonstrates how to use them to collect basic performance data of a given
Kubeflow Pipelines instance.&lt;/p&gt;
&lt;h2 id=&#34;about-the-kubeflow-pipelines-benchmark-script&#34;&gt;About the Kubeflow Pipelines benchmark script&lt;/h2&gt;
&lt;p&gt;The Kubeflow Pipelines benchmark scripts simulate typical workloads and record
performance metrics, such as server latencies and pipeline run durations. To simulate a typical workload, the benchmark script uploads a pipeline
manifest file to a Kubeflow Pipelines instance as a pipeline or
a pipeline version, and creates multiple runs simultaneously.&lt;/p&gt;
&lt;p&gt;You can specify the pipelines manifest used in the benchmark script, or you can
use one of the preloaded samples pipelines. For example, the preloaded samples
in Kubeflow pipelines can be used.
Moreover, it is also a good practice to use a pipeline manifest that is representative of your particular use case. For example, if your Kubeflow Pipelines cluster is mainly used for pipelines of image recognition tasks, then it would be desirable to use an image recognition pipeline in the benchmark scripts.&lt;/p&gt;
&lt;p&gt;After a proper pipeline is chosen, the benchmark scripts will run it multiple
times simultaneously as mentioned before. Among all the operations that the Kubeflow
Pipelines can perform, running a pipeline is arguably the most unpredictable and
costly one. Other operations, such as creating a pipeline (version) or creating an
experiment, usually induce a predictable and moderate cost. For example, creating a
pipeline version will introduce a new row in the pipeline versions table and a new
file in minio server. The new file&amp;rsquo;s size depends on the pipeline version&amp;rsquo;s
manifest. If we exclude the rare case of an extremely large manifest and assume
an average sized manifest for each created pipeline version, the total cost of
creating a pipeline version grows linearly with the number of pipeline versions.
However, on the other hand, the cost of running a pipeline or a pipeline version
involves much more uncertainty and sometimes quite a high cost. A pipeline or a
pipeline version can have arbitrary components and hence running a pipeline or a
pipeline version can incur arbitrary time and space complexities. For example, a step
in a pipeline can use a customized container image which performs a super
expensive training task. In addition, the runs in a Kubeflow Pipelines instance
also consume more DB space than pipelines, pipeline versions, experiments, etc.
Therefore, in order to understand the performance and scalability pain points in
a Kubeflow Pipelines instance, it is more effective to focus on the run operation
in workloads.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites-for-running-benchmark-scripts&#34;&gt;Prerequisites for running benchmark scripts&lt;/h2&gt;
&lt;p&gt;To run the provided benchmark scripts, you need the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Jupyter notebook environment with access to the Kubeflow Pipelines API on
your Kubeflow Pipelines cluster. For example, you must be able to call the
&lt;code&gt;CREATE&lt;/code&gt;, &lt;code&gt;GET&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;, and &lt;code&gt;LIST&lt;/code&gt; methods of the pipeline, pipeline version,
run, job, and experiment services from your Jupyter notebook environment.&lt;/li&gt;
&lt;li&gt;A Kubeflow Pipelines cluster. If you do not have a Kubeflow Pipelines
cluster, learn more about your &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/installation/overview/&#34;&gt;options for installing Kubeflow
Pipelines&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A pipeline manifest. For example, this guide uses the
&lt;a href=&#34;https://storage.googleapis.com/ml-pipeline/sample-benchmark/taxi_updated_pool.yaml&#34;&gt;taxi_updated_pool.yaml&lt;/a&gt;
pipeline manifest file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One way of setting up everything and running a benchmark script is shown below
as an example.&lt;/p&gt;
&lt;h2 id=&#34;running-the-benchmark-scripts&#34;&gt;Running the benchmark scripts&lt;/h2&gt;
&lt;p&gt;Use the following instructions to run the benchmark script on your Kubeflow
Pipelines cluster.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download the &lt;a href=&#34;https://storage.googleapis.com/ml-pipeline/sample-benchmark/run_service_api.ipynb&#34;&gt;&lt;code&gt;run_service_api.ipynb&lt;/code&gt;&lt;/a&gt;
benchmark script in your Jupyter notebook environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open &lt;a href=&#34;https://storage.googleapis.com/ml-pipeline/sample-benchmark/run_service_api.ipynb&#34;&gt;&lt;code&gt;run_service_api.ipynb&lt;/code&gt;&lt;/a&gt;
in the local Jupyter notebook. This benchmark script:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Creates a new pipeline.&lt;/li&gt;
&lt;li&gt;Uses the default pipeline version of this pipeline to create multiple runs.&lt;/li&gt;
&lt;li&gt;Records the number of successful runs.&lt;/li&gt;
&lt;li&gt;Records the duration of each of the successful runs.&lt;/li&gt;
&lt;li&gt;Records the latency of &lt;code&gt;CREATE&lt;/code&gt;, &lt;code&gt;GET&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Cleans up the pipeline and its default pipeline version, the experiment and the runs.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the benchmark script, enter the correct values for host,
&lt;code&gt;pipeline_file_url&lt;/code&gt;, &lt;code&gt;num_runs&lt;/code&gt;, &lt;code&gt;run_status_polling_interval_sec&lt;/code&gt; in the
benchmark script.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;host&lt;/strong&gt;: The URL of the API server in your Kubeflow Pipelines cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;pipeline_file_url&lt;/strong&gt;: The URL of the pipeline manifest file to use in
your benchmark.
&lt;a href=&#34;https://storage.googleapis.com/ml-pipeline/sample-benchmark/taxi_updated_pool.yaml&#34;&gt;&lt;code&gt;taxi_updated_pool.yaml&lt;/code&gt;&lt;/a&gt;
is used in this example. This example pipeline makes use of
&lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector&#34;&gt;nodeSelector&lt;/a&gt;
to explicitly schedule the runs of this pipeline onto the node pool named &lt;code&gt;pool-1&lt;/code&gt;. If you use the taxi_updated_pool.yaml pipeline manifest in your benchmarks, ensure that a node pool named &lt;code&gt;pool-1&lt;/code&gt; exists in your cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Do not use the value &lt;code&gt;https://storage.cloud.google.com/ml-pipeline/sample-benchmark/taxi_updated_pool.yaml&lt;/code&gt;
when running your benchmarks. Addresses that start with
&lt;code&gt;storage.cloud.google.com&lt;/code&gt; incur a redirect that doesn&amp;rsquo;t work well with
Kubeflow Pipelines.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;num_runs&lt;/strong&gt;: Specifies how many runs will be created in the benchmark script,
and is a direct indicator of the simulated workload.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Running the benchmark script on a cloud
service incurs charges due to the consumption of cloud resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;run_status_polling_interval_sec&lt;/strong&gt;: Sets the time interval between two
adjacent pollings of the run status. When a run reaches the success status, the
run duration is recorded. Only the durations of successful runs are recorded.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After the parameters are properly set, you can run the
benchmark script in the notebook.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following snapshot shows the results of running the benchmark script
&lt;a href=&#34;https://storage.googleapis.com/ml-pipeline/sample-benchmark/run_service_api.ipynb&#34;&gt;&lt;code&gt;run_service_api.ipynb&lt;/code&gt;&lt;/a&gt;
using the &lt;a href=&#34;https://storage.googleapis.com/ml-pipeline/sample-benchmark/taxi_updated_pool.yaml&#34;&gt;&lt;code&gt;taxi_updated_pool.yaml&lt;/code&gt;&lt;/a&gt;
pipeline manifest for 50 runs on a Kubernetes cluster with two node pools.
Each node pool has three nodes of machine type &lt;code&gt;n1-standard-8&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gkcalat.github.io/kubeflow-docs/docs/images/benchmark-snapshot-1.png&#34;
alt=&#34;Benchmark Sample Output Plots&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;interpreting-the-results&#34;&gt;Interpreting the results&lt;/h2&gt;
&lt;p&gt;In the above example output, there are two types of plots. One is the
distribution plot, for latency and duration measurement; the other is the count
plot, for counting succeeded and failed runs. The reading of those plots is in
general straightforward.&lt;/p&gt;
&lt;p&gt;In a count plot, the x-axis represents the possible run status: success or fail;
and the y-axis shows how many runs fall into certain status respectively.&lt;/p&gt;
&lt;p&gt;In a distribution plot, both histogram plot and rug plot are shown. In addition,
it is also possible to show a KDE (Kernel Density Estimate) plot. If the KDE plot is
desirable, use &lt;code&gt;kde=True&lt;/code&gt; in the &lt;code&gt;distplot()&lt;/code&gt; method.&lt;/p&gt;
&lt;h2 id=&#34;tuning-with-different-configurations&#34;&gt;Tuning with different configurations&lt;/h2&gt;
&lt;p&gt;The above example shows one performance report via running the benchmark script.
In fact, there are multiple ways of tuning the pipeline and/or the Kubernetes
clusters to acquire performance reports. The common ways are trying with&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Different cluster sizes/zones, different numbers of pools in a cluster,
different numbers of nodes in each pool, different node configurations (for
example, RAM and disk configuration for each node, CPU or GPU configuration for
each node)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Different number of runs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Different sizes/complexities of a pipeline, for example, the number of steps
in a pipeline&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Different running configurations, for example, specifying the node pools for
running components or pipelines&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitations-and-future-work&#34;&gt;Limitations and future work&lt;/h2&gt;
&lt;p&gt;When the benchmark script is tuned to generate a moderate workload, for example, 50
runs in the above example, the latency and run duration measurements can be
made properly. However, it is also interesting to see how a Kubeflow Pipelines
instance behaves or breaks under some extremely heavy workloads, or in
other words, to probe the Kubeflow Pipelines instance. The example benchmark
script can be used for that purpose as well. In that case, the measurement plots
of the benchmark script are no longer the expected output. Instead, the errors
and error logs provide information on the performance and scalability of the
Kubeflow Pipelines deployment. With them, bugs and pain points can be discovered and then fixed. Moreover, when probing the
Kubeflow Pipelines instance with extreme workloads, it will be really helpful
to add internal monitoring to the server code to track server performance.
For example, in the future, it would be desirable to use &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;
to track and visualize metrics for Kubeflow Pipelines servers.&lt;/p&gt;
&lt;p&gt;The internal performance monitoring inside the servers is complementary to the
performance measurement from the client-side. When the example benchmark script
measures the latencies from the client-side, the resulting measurements depend
on both the Kubeflow Pipelines instance and the network transmission. On the
other hand, the internal monitoring focuses on the actual processing cost inside
the server given certain requests. Therefore, having both the client-side
measurements and server side monitoring are useful in profiling accurately the
performance and scalability of Kubeflow Pipelines.&lt;/p&gt;
&lt;h2 id=&#34;contact&#34;&gt;Contact&lt;/h2&gt;
&lt;p&gt;If you run into any issues with the benchmark script and have any suggestions in
profiling the performance and scalability of Kubeflow Pipelines, &lt;a href=&#34;https://github.com/kubeflow/pipelines/issues/new&#34;&gt;open an
issue&lt;/a&gt; with us.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Using the Kubeflow Pipelines SDK</title>
      <link>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/sdk-examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/sdk-examples/</guid>
      <description>
        
        
        &lt;p&gt;This guide provides examples that demonstrate how to use the Kubeflow Pipelines SDK.&lt;/p&gt;
&lt;h2 id=&#34;before-you-start&#34;&gt;Before you start&lt;/h2&gt;
&lt;p&gt;To follow the examples in this guide, you must have Kubeflow Pipelines SDK
version 0.2.5 or higher installed. Use the following instructions to install
the Kubeflow Pipelines SDK and check the SDK version.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/install-sdk/&#34;&gt;Kubeflow Pipelines SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Run the following command to check the version of the SDK
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip list | grep kfp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;The response should be something like this:
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kfp                      0.2.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kfp-server-api           0.2.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;p&gt;Use the following examples to learn more about the Kubeflow Pipelines SDK.&lt;/p&gt;
&lt;h3 id=&#34;example-1-creating-a-pipeline-and-a-pipeline-version-using-the-sdk&#34;&gt;Example 1: Creating a pipeline and a pipeline version using the SDK&lt;/h3&gt;
&lt;p&gt;The following example demonstrates how to use the Kubeflow Pipelines SDK to
create a pipeline and a pipeline version.&lt;/p&gt;
&lt;p&gt;In this example, you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;kfp.Client&lt;/code&gt; to create a pipeline from a local file. When the pipeline
is created, a default pipeline version is automatically created.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;kfp.Client&lt;/code&gt; to add a pipeline version to the pipeline that was created
in the previous step.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;kfp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;host&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_file_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version_file_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;version&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version_name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;version&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kfp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Client&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_file_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_uploads&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;upload_pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version_file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version_file_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_uploads&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;upload_pipeline_version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version_file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                   &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_version_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                                                   &lt;span class=&#34;n&#34;&gt;pipelineid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;host&lt;/strong&gt;: Your Kubeflow Pipelines cluster&amp;rsquo;s host name.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;path to pipeline file&lt;/strong&gt;: The path to the directory where your pipeline YAML
is stored.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pipeline name&lt;/strong&gt;: Your pipeline&amp;rsquo;s file name.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;path to pipeline version file&lt;/strong&gt;: The path to the directory where the new
version of your pipeline YAML is stored.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pipeline version name&lt;/strong&gt;: Your pipeline version&amp;rsquo;s file name.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Pipeline names need to be unique across your Kubeflow Pipelines
cluster. Pipeline version names need to be unique within each pipeline.&lt;/p&gt;
&lt;h4 id=&#34;adding-a-version-to-an-existing-pipeline-using-the-sdk&#34;&gt;Adding a version to an existing pipeline using the SDK&lt;/h4&gt;
&lt;p&gt;To add a pipeline version for an existing pipeline, you must find the
pipeline&amp;rsquo;s ID and use it with the &lt;code&gt;upload_pipeline_version&lt;/code&gt; method. To
find a pipeline&amp;rsquo;s ID:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open the Kubeflow Pipelines UI. A list of your pipelines appears.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;name of your pipeline&lt;/strong&gt;. The pipeline details page appears.&lt;/li&gt;
&lt;li&gt;The pipeline ID is listed in the summary card, as shown below.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://gkcalat.github.io/kubeflow-docs/docs/images/sdk-examples-snapshot-1.png&#34;
alt=&#34;Pipeline ID in Summary Card&#34;
class=&#34;mt-3 mb-3 border border-info rounded&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;example-2-listing-pipelines-with-a-filter&#34;&gt;Example 2: Listing pipelines with a filter&lt;/h3&gt;
&lt;p&gt;The following example demonstrates how to use the Kubeflow Pipelines SDK to
list pipelines with a particular pipeline name. If list_pipelines method is
called without any input parameters, it will list all the pipelines. However,
you can specify a filter as an input parameter to list pipelines with a
particular name. Given that Kubeflow Pipelines requires pipeline names to be
unique, listing pipelines with a particular name returns at most one pipeline.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;kfp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;json&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# &amp;#39;host&amp;#39; is your Kubeflow Pipelines API server&amp;#39;s host address.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;host&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# &amp;#39;pipeline_name&amp;#39; is the name of the pipeline you want to list.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipeline_name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kfp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Client&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# To filter on pipeline name, you can use a predicate indicating that the pipeline&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# name is equal to the given name.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# A predicate includes &amp;#39;key&amp;#39;, &amp;#39;op&amp;#39; and &amp;#39;string_value&amp;#39; fields.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# The &amp;#39;key&amp;#39; specifies the property you want to apply the filter to. For example,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# if you want to filter on the pipeline name, then &amp;#39;key&amp;#39; is set to &amp;#39;name&amp;#39; as&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# shown below.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# The &amp;#39;op&amp;#39; specifies the operator used in a predicate. The operator can be&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# EQUALS, NOT_EQUALS, GREATER_THAN, etc. The complete list is at [filter.proto](https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/backend/api/filter.proto#L32)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# When using the operator in a string-typed predicate, you need to use the&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# corresponding integer value of the enum. For Example, you can use the integer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# value 1 to indicate EQUALS as shown below.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# The &amp;#39;string_value&amp;#39; specifies the value you want to filter with.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;filter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dumps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;predicates&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;key&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;op&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;string_value&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipeline_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)}]})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipelines&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipelines&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;list_pipelines&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# The pipeline with the given pipeline_name, if exists, is in pipelines.pipelines[0].&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;example-3-creating-a-run-using-a-pipeline-version&#34;&gt;Example 3: Creating a run using a pipeline version&lt;/h3&gt;
&lt;p&gt;Examine the run_service_api.ipynb notebook to &lt;a href=&#34;https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/tools/benchmarks/run_service_api.ipynb&#34;&gt;learn more about creating a run using a pipeline version&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Experiment with the Kubeflow Pipelines API</title>
      <link>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/api-pipelines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/api-pipelines/</guid>
      <description>
        
        
        &lt;p&gt;This tutorial demonstrates how to use the Kubeflow Pipelines API to build, run, and manage pipelines. This guide is recommended for users who would like to learn how to manage Kubeflow Pipelines using the REST API.&lt;/p&gt;
&lt;h2 id=&#34;before-you-start&#34;&gt;Before you start&lt;/h2&gt;
&lt;p&gt;This tutorial assumes that you have access to the &lt;code&gt;ml-pipeline&lt;/code&gt; service. If Kubeflow is not configured to use an identity provider, use port-forwarding to directly access the service.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SVC_PORT=$(kubectl -n kubeflow get svc/ml-pipeline -o json | jq &amp;#34;.spec.ports[0].port&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl port-forward -n kubeflow svc/ml-pipeline ${SVC_PORT}:8888
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This tutorial assumes that the service is accessible on localhost.&lt;/p&gt;
&lt;p&gt;You also need to install &lt;a href=&#34;https://stedolan.github.io/jq/download/&#34;&gt;jq&lt;/a&gt;, and the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/install-sdk/&#34;&gt;Kubeflow Pipelines SDK&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;building-and-running-a-pipeline&#34;&gt;Building and running a pipeline&lt;/h2&gt;
&lt;p&gt;Follow this guide to download, compile, and run the &lt;a href=&#34;https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/core/sequential/sequential.py&#34;&gt;&lt;code&gt;sequential.py&lt;/code&gt; sample pipeline&lt;/a&gt;. To learn how to compile and run pipelines using the Kubeflow Pipelines SDK or a Jupyter notebook, follow the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/tutorials/build-pipeline/&#34;&gt;experimenting with Kubeflow Pipelines samples tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;PIPELINE_URL=https://raw.githubusercontent.com/kubeflow/pipelines/master/samples/core/sequential/sequential.py
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;PIPELINE_FILE=${PIPELINE_URL##*/}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;PIPELINE_NAME=${PIPELINE_FILE%.*}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -O ${PIPELINE_FILE} ${PIPELINE_URL}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dsl-compile --py ${PIPELINE_FILE} --output ${PIPELINE_NAME}.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After running the commands above, you should get two files in your current directory: &lt;code&gt;sequential.py&lt;/code&gt; and &lt;code&gt;sequential.tar.gz&lt;/code&gt;. Run the following command to deploy the generated &lt;code&gt;.tar.gz&lt;/code&gt; file as you would do using the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/build-component/#deploy-the-pipeline&#34;&gt;Kubeflow Pipelines UI&lt;/a&gt;, but this time using the REST API.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SVC=localhost:8888
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;PIPELINE_ID=$(curl -F &amp;#34;uploadfile=@${PIPELINE_NAME}.tar.gz&amp;#34; ${SVC}/apis/v1beta1/pipelines/upload | jq -r .id)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the operation was successful, you should see the pipeline in the central dashboard. You can also get the details using the &lt;code&gt;PIPELINE_ID&lt;/code&gt; with the following API call.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl ${SVC}/apis/v1beta1/pipelines/${PIPELINE_ID} | jq
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be similar to the following one:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;id&amp;#34;: &amp;#34;d30d28d7-0bfc-4f0c-8a57-6844a8ec9742&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;created_at&amp;#34;: &amp;#34;2020-02-20T16:15:02Z&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;name&amp;#34;: &amp;#34;sequential.tar.gz&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;parameters&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;#34;name&amp;#34;: &amp;#34;url&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;#34;value&amp;#34;: &amp;#34;gs://ml-pipeline-playground/shakespeare1.txt&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;default_version&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;id&amp;#34;: &amp;#34;d30d28d7-0bfc-4f0c-8a57-6844a8ec9742&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;name&amp;#34;: &amp;#34;sequential.tar.gz&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;created_at&amp;#34;: &amp;#34;2020-02-20T16:15:02Z&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;parameters&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;name&amp;#34;: &amp;#34;url&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;value&amp;#34;: &amp;#34;gs://ml-pipeline-playground/shakespeare1.txt&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;resource_references&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;key&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &amp;#34;type&amp;#34;: &amp;#34;PIPELINE&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &amp;#34;id&amp;#34;: &amp;#34;d30d28d7-0bfc-4f0c-8a57-6844a8ec9742&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;relationship&amp;#34;: &amp;#34;OWNER&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, use the &lt;code&gt;PIPELINE_ID&lt;/code&gt; to trigger a run of your pipeline.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RUN_ID=$((
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -H &amp;#34;Content-Type: application/json&amp;#34; -X POST ${SVC}/apis/v1beta1/runs \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-d @- &amp;lt;&amp;lt; EOF
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &amp;#34;name&amp;#34;:&amp;#34;${PIPELINE_NAME}_run&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &amp;#34;pipeline_spec&amp;#34;:{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;#34;pipeline_id&amp;#34;:&amp;#34;${PIPELINE_ID}&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;EOF
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;) | jq -r .run.id)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run the following command occasionally to see how the status of your run changes. After a while, the status of your pipeline should change to &lt;strong&gt;Succeeded&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl ${SVC}/apis/v1beta1/runs/${RUN_ID} | jq
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The response should be similar to the following one:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;run&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;id&amp;#34;: &amp;#34;4ff0debd-d6d7-4681-8593-21ec002e6e0c&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;name&amp;#34;: &amp;#34;sequential_run&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pipeline_spec&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;#34;pipeline_id&amp;#34;: &amp;#34;d30d28d7-0bfc-4f0c-8a57-6844a8ec9742&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;#34;pipeline_name&amp;#34;: &amp;#34;sequential.tar.gz&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;#34;workflow_manifest&amp;#34;: &amp;#34;{...}&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;resource_references&amp;#34;: [
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;key&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &amp;#34;type&amp;#34;: &amp;#34;EXPERIMENT&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &amp;#34;id&amp;#34;: &amp;#34;27af7eee-ce0a-44ba-a44d-07142abfc83c&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;name&amp;#34;: &amp;#34;Default&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &amp;#34;relationship&amp;#34;: &amp;#34;OWNER&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;created_at&amp;#34;: &amp;#34;2020-02-20T16:18:58Z&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;scheduled_at&amp;#34;: &amp;#34;1970-01-01T00:00:00Z&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;finished_at&amp;#34;: &amp;#34;1970-01-01T00:00:00Z&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;status&amp;#34;: &amp;#34;Succeeded&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;pipeline_runtime&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;workflow_manifest&amp;#34;: &amp;#34;{...}&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Read &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/reference/api/kubeflow-pipeline-api-spec/&#34;&gt;Kubeflow Pipelines API Reference&lt;/a&gt; to learn more about how to use the API.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Experiment with the Pipelines Samples</title>
      <link>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/build-pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/build-pipeline/</guid>
      <description>
        
        
        &lt;p&gt;You can learn how to build and deploy pipelines by running the samples
provided in the Kubeflow Pipelines repository or by walking through a
Jupyter notebook that describes the process.&lt;/p&gt;
&lt;h2 id=&#34;compiling-the-samples-on-the-command-line&#34;&gt;Compiling the samples on the command line&lt;/h2&gt;
&lt;p&gt;This section shows you how to compile the
&lt;a href=&#34;https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/samples&#34;&gt;Kubeflow Pipelines samples&lt;/a&gt;
and deploy them using the Kubeflow Pipelines UI.&lt;/p&gt;
&lt;h3 id=&#34;before-you-start&#34;&gt;Before you start&lt;/h3&gt;
&lt;p&gt;Set up your environment:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone or download the
&lt;a href=&#34;https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/samples&#34;&gt;Kubeflow Pipelines samples&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/install-sdk/&#34;&gt;Kubeflow Pipelines SDK&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Activate your Python 3 environment if you haven&amp;rsquo;t done so already:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;source activate &amp;lt;YOUR-PYTHON-ENVIRONMENT-NAME&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;source activate mlpipeline
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;choose-and-compile-a-pipeline&#34;&gt;Choose and compile a pipeline&lt;/h3&gt;
&lt;p&gt;Examine the pipeline samples that you downloaded and choose one to work with.
The
&lt;a href=&#34;https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/core/sequential/sequential.py&#34;&gt;&lt;code&gt;sequential.py&lt;/code&gt; sample pipeline&lt;/a&gt;:
is a good one to start with.&lt;/p&gt;
&lt;p&gt;Each pipeline is defined as a Python program. Before you can submit a pipeline
to the Kubeflow Pipelines service, you must compile the
pipeline to an intermediate representation. The intermediate representation
takes the form of a YAML file compressed into a
&lt;code&gt;.tar.gz&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;Use the &lt;code&gt;dsl-compile&lt;/code&gt; command to compile the pipeline that you chose:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dsl-compile --py &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;path/to/python/file&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; --output &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;path/to/output/tar.gz&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For example, to compile the
&lt;a href=&#34;https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/core/sequential/sequential.py&#34;&gt;&lt;code&gt;sequential.py&lt;/code&gt; sample pipeline&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;DIR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=[&lt;/span&gt;YOUR PIPELINES REPO DIRECTORY&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;/samples/core/sequential
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dsl-compile --py &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;DIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/sequential.py --output &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;DIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/sequential.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;deploy-the-pipeline&#34;&gt;Deploy the pipeline&lt;/h3&gt;
&lt;p&gt;Upload the generated &lt;code&gt;.tar.gz&lt;/code&gt; file through the Kubeflow Pipelines UI. See the
guide to &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/overview/quickstart&#34;&gt;getting started with the UI&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;building-a-pipeline-in-a-jupyter-notebook&#34;&gt;Building a pipeline in a Jupyter notebook&lt;/h2&gt;
&lt;p&gt;You can choose to build your pipeline in a Jupyter notebook. The
&lt;a href=&#34;https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/samples/core&#34;&gt;sample notebooks&lt;/a&gt;
walk you through the process.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s easiest to use the Jupyter services that are installed in the same cluster as
the Kubeflow Pipelines system.&lt;/p&gt;
&lt;p&gt;Note: The notebook samples don&amp;rsquo;t work on Jupyter notebooks outside the same
cluster, because the Python library communicates with the Kubeflow Pipelines
system through in-cluster service names.&lt;/p&gt;
&lt;p&gt;Follow these steps to start a notebook:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Deploy Kubeflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Follow the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/gke/deploy/&#34;&gt;GCP deployment guide&lt;/a&gt;, including the step
to deploy Kubeflow using the
&lt;a href=&#34;https://deploy.kubeflow.cloud/&#34;&gt;Kubeflow deployment UI&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When Kubeflow is running, access the Kubeflow UI at a URL of the form
&lt;code&gt;https://&amp;lt;deployment-name&amp;gt;.endpoints.&amp;lt;project&amp;gt;.cloud.goog/&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/notebooks/setup/&#34;&gt;Kubeflow notebooks setup guide&lt;/a&gt; to
create a Jupyter notebook server and open the Jupyter UI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the sample notebooks from
&lt;a href=&#34;https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/samples/core&#34;&gt;https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/samples/core&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upload these notebooks from the Jupyter UI: In Jupyter, go to the tree view
and find the &lt;strong&gt;upload&lt;/strong&gt; button in the top right-hand area of the screen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open one of the uploaded notebooks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure the notebook kernel is set to Python 3. The Python version is at
the top right-hand corner in the Jupyter notebook view.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the instructions in the notebook.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following notebooks are available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/core/tfx-oss/TFX%20Example.ipynb&#34;&gt;KubeFlow pipeline using TFX OSS components&lt;/a&gt;:
This notebook demonstrates how to build a machine learning pipeline based on
&lt;a href=&#34;https://www.tensorflow.org/tfx/&#34;&gt;TensorFlow Extended (TFX)&lt;/a&gt; components.
The pipeline includes a TFDV step to infer the schema, a TFT preprocessor, a
TensorFlow trainer, a TFMA analyzer, and a model deployer which deploys the
trained model to &lt;code&gt;tf-serving&lt;/code&gt; in the same cluster. The notebook also
demonstrates how to build a component based on Python 3 inside the notebook,
including how to build a Docker container.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/core/lightweight_component/lightweight_component.ipynb&#34;&gt;Lightweight Python components&lt;/a&gt;:
This notebook demonstrates how to build simple Python components based on
Python 3 and use them in a pipeline with fast iterations. If you use this
technique, you don&amp;rsquo;t need to build a Docker container when you build a
component. Note that the container image may not be self contained because the
source code is not built into the container.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn the various ways to use the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/sdk-overview/&#34;&gt;Kubeflow Pipelines
SDK&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;See how to
&lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/build-component/&#34;&gt;build your own pipeline components&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Read more about
&lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/sdk/lightweight-python-components/&#34;&gt;building lightweight components&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Run a Cloud-specific Pipelines Tutorial</title>
      <link>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/cloud-tutorials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gkcalat.github.io/kubeflow-docs/docs/components/pipelines/v1/tutorials/cloud-tutorials/</guid>
      <description>
        
        
        

&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Opportunity to add cloud tutorials&lt;/h4&gt;

    &lt;b&gt;Invitation:&lt;/b&gt; Create a cloud-specific tutorial and link it here.
See the &lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/about/style-guide/&#34;&gt;style guide for the Kubeflow docs&lt;/a&gt;.

&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gkcalat.github.io/kubeflow-docs/docs/azure/azureendtoend/&#34;&gt;Pipelines End-to-end on Azure&lt;/a&gt;: An end-to-end tutorial for Kubeflow Pipelines on Microsoft Azure.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://g.co/codelabs/kfp-gis&#34;&gt;Pipelines on Google Cloud Platform&lt;/a&gt; : This GCP tutorial walks through a Kubeflow Pipelines example that shows training a Tensor2Tensor model for GitHub issue summarization, both via the Pipelines Dashboard UI, and from a Jupyter notebook&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
